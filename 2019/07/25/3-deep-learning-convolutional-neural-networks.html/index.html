<!DOCTYPE html>
<html>
<head>

  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="https://lourisxu.github.io">
  <title>(3) Deep Learning: Convolutional Neural Networks | Louris&#39; Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="卷积神经网络 二维卷积层二维互相关计算12345678910111213141516from mxnet import autograd, ndfrom mxnet.gluon import nndef corr2d(X, K):    h, w &#x3D; K.shape    Y &#x3D; nd.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))    for">
<meta property="og:type" content="article">
<meta property="og:title" content="(3) Deep Learning: Convolutional Neural Networks">
<meta property="og:url" content="https://lourisxu.github.io/2019/07/25/3-deep-learning-convolutional-neural-networks.html/index.html">
<meta property="og:site_name" content="Louris&#39; Blog">
<meta property="og:description" content="卷积神经网络 二维卷积层二维互相关计算12345678910111213141516from mxnet import autograd, ndfrom mxnet.gluon import nndef corr2d(X, K):    h, w &#x3D; K.shape    Y &#x3D; nd.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))    for">
<meta property="og:image" content="https://lourisxu.github.io/assets/img/deep_learning/deep_learning_01.png">
<meta property="og:image" content="https://lourisxu.github.io/assets/img/deep_learning/deep_learning_02.png">
<meta property="article:published_time" content="2019-07-25T02:55:20.000Z">
<meta property="article:modified_time" content="2024-01-19T02:20:51.961Z">
<meta property="article:author" content="Louris">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="DL">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lourisxu.github.io/assets/img/deep_learning/deep_learning_01.png">
  
    <link rel="alternative" href="/atom.xml" title="Louris&#39; Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/assets/img/blog/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.e8862b.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

<meta name="generator" content="Hexo 4.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #00BFFF"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="/assets/img/blog/userpic.jpg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">Louris</a></h1>
		</hgroup>
		
		<p class="header-subtitle">Do what I can</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">Home</a></li>
	        
				<li><a href="/categories/DS/">DS</a></li>
	        
				<li><a href="/tags/ML/">ML&amp;DL</a></li>
	        
				<li><a href="/tags/Tech/">Tech</a></li>
	        
				<li><a href="/tags/Algorithm/">Algorithm</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">All articles</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">Friends</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">About me</a>
    			
            
		</nav>
		<nav>
		 <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=230 height=86 src="//music.163.com/outchain/player?type=2&id=2080322&auto=1&height=66"></iframe>
		 <!--<div id="aplayer_home" class="aplayer" style="margin-bottom: 20px;width:100%;"></div>
		 <script type="text/javascript" src="\assets\js\APlayer.min.js"> </script>
 			<script>
   			new APlayer({
     		element: document.getElementById("aplayer_home"),
     		narrow: false,
     		autoplay: false,
     		showlrc: 0,
     		music: {
       		title: "What Are Words",
       		author: "Chris Media",
       		url: "https://coding.net/u/LourisXu/p/LourisXu/attachment/4532287/preview/4533847",
       		pic: "http://ov4otygyd.bkt.clouddn.com/What_Are_Words.jpg",
   			}
 			});
			</script>-->
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/LourisXu" title="github"><i class="icon-github"></i></a>
		        
					<a class="weibo" target="_blank" href="http://weibo.com/5634881238/profile?rightmod=1&wvr=6&mod=personinfo" title="weibo"><i class="icon-weibo"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:louris@csu.edu.cn" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #00BFFF"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/assets/img/blog/userpic.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">Louris</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>Do what I can<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
				
			
				
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/LourisXu" title="github"><i class="icon-github"></i></a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/5634881238/profile?rightmod=1&wvr=6&mod=personinfo" title="weibo"><i class="icon-weibo"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:louris@csu.edu.cn" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 70%">
				
				
					<li style="width: 20%"><a href="/">Home</a></li>
		        
					<li style="width: 20%"><a href="/categories/DS/">DS</a></li>
		        
					<li style="width: 20%"><a href="/tags/ML/">ML&amp;DL</a></li>
		        
					<li style="width: 20%"><a href="/tags/Tech/">Tech</a></li>
		        
					<li style="width: 20%"><a href="/tags/Algorithm/">Algorithm</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            <article id="post-DL/3_Deep-Learning-Convolutional-Neural-Networks" class="article article-type-post " itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      (3) Deep Learning: Convolutional Neural Networks
    </h1>
  


        
        <a href="/2019/07/25/3-deep-learning-convolutional-neural-networks.html/" class="archive-article-date">
  	<time datetime="2019-07-25T02:55:20.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-07-25</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><blockquote>
<h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1></blockquote>
<h2 id="二维卷积层"><a href="#二维卷积层" class="headerlink" title="二维卷积层"></a>二维卷积层</h2><h3 id="二维互相关计算"><a href="#二维互相关计算" class="headerlink" title="二维互相关计算"></a>二维互相关计算</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = nd.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = nd.array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">K = nd.array([[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line">print(corr2d(X, K))</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Outputs:</span><br><span class="line">[[<span class="number">19.</span> <span class="number">25.</span>]</span><br><span class="line"> [<span class="number">37.</span> <span class="number">43.</span>]]</span><br><span class="line">&lt;NDArray <span class="number">2</span>x2 @cpu(<span class="number">0</span>)&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="二维卷积层-1"><a href="#二维卷积层-1" class="headerlink" title="二维卷积层"></a>二维卷积层</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conv2D</span><span class="params">(nn.Block)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kernel_size, **kwargs)</span>:</span></span><br><span class="line">        super(Conv2D, self).__init__(**kwargs)</span><br><span class="line">        self.weight = self.params.get(<span class="string">'weight'</span>, shape=kernel_size)</span><br><span class="line">        self.bias = self.params.get(<span class="string">'bias'</span>, shape=(<span class="number">1</span>,))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> corr2d(x, self.weight.data()) + self.bias.data()</span><br></pre></td></tr></tbody></table></figure>
<h3 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = nd.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line">X = nd.ones((<span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">X[:, <span class="number">2</span>:<span class="number">6</span>] = <span class="number">0</span></span><br><span class="line">print(X)</span><br><span class="line"></span><br><span class="line">K = nd.array([[<span class="number">1</span>, <span class="number">-1</span>]])</span><br><span class="line">Y = corr2d(X, K)</span><br><span class="line">print(Y)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Outputs:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">1.</span>]]</span><br><span class="line">&lt;NDArray <span class="number">6</span>x8 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line">[[ <span class="number">0.</span>  <span class="number">1.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span> <span class="number">-1.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">1.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span> <span class="number">-1.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">1.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span> <span class="number">-1.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">1.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span> <span class="number">-1.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">1.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span> <span class="number">-1.</span>  <span class="number">0.</span>]</span><br><span class="line"> [ <span class="number">0.</span>  <span class="number">1.</span>  <span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span> <span class="number">-1.</span>  <span class="number">0.</span>]]</span><br><span class="line">&lt;NDArray <span class="number">6</span>x7 @cpu(<span class="number">0</span>)&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="通过数据学习核数组"><a href="#通过数据学习核数组" class="headerlink" title="通过数据学习核数组"></a>通过数据学习核数组</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = nd.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = nd.ones((<span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">X[:, <span class="number">2</span>:<span class="number">6</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">K = nd.array([[<span class="number">1</span>, <span class="number">-1</span>]])</span><br><span class="line">Y = corr2d(X, K)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造一个输出输出通道数为1，核数组形状是(1,2)的二维卷积层</span></span><br><span class="line">conv2d = nn.Conv2D(<span class="number">1</span>, kernel_size=(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">conv2d.initialize()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二维卷积层使用4维输入输出，格式为（样本，通道，高，宽），这里批量大小和通道数均为1</span></span><br><span class="line">X = X.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">Y = Y.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">with</span> autograd.record():</span><br><span class="line">        Y_hat = conv2d(X)</span><br><span class="line">        l = (Y_hat - Y) ** <span class="number">2</span></span><br><span class="line">    l.backward()</span><br><span class="line">    conv2d.weight.data()[:] -= <span class="number">3e-2</span> * conv2d.weight.grad()</span><br><span class="line">    <span class="comment"># conv2d.bias.data()[:] -= 3e-2 * conv2d.bias.grad()</span></span><br><span class="line">    <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'batch %d, loss %.3f'</span> % (i + <span class="number">1</span>, l.sum().asscalar()))</span><br><span class="line"></span><br><span class="line">print(conv2d.weight.data().reshape((<span class="number">1</span>, <span class="number">2</span>)))</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">batch <span class="number">2</span>, loss <span class="number">4.949</span></span><br><span class="line">batch <span class="number">4</span>, loss <span class="number">0.831</span></span><br><span class="line">batch <span class="number">6</span>, loss <span class="number">0.140</span></span><br><span class="line">batch <span class="number">8</span>, loss <span class="number">0.024</span></span><br><span class="line">batch <span class="number">10</span>, loss <span class="number">0.004</span></span><br><span class="line"></span><br><span class="line">[[ <span class="number">0.9895</span>    <span class="number">-0.9873705</span>]]</span><br><span class="line">&lt;NDArray <span class="number">1</span>x2 @cpu(<span class="number">0</span>)&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="互相关运算和卷积运算"><a href="#互相关运算和卷积运算" class="headerlink" title="互相关运算和卷积运算"></a>互相关运算和卷积运算</h3><ul>
<li>二者类似。为了得到卷积运算的输出，只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算。</li>
<li>深度学习中核数组都是学出来的：卷积层使用互相关运算或卷积运算都不影响模型预测时的输出。<h3 id="特征图和感受野"><a href="#特征图和感受野" class="headerlink" title="特征图和感受野"></a>特征图和感受野</h3></li>
<li>二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）</li>
<li>影响元素x的前向计算的所有输入区域（可能大于输入的实际尺寸）叫做x的感受野（receptive field）</li>
<li>可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。</li>
</ul>
<h3 id="练习：自定义互相关计算类的自动求梯度"><a href="#练习：自定义互相关计算类的自动求梯度" class="headerlink" title="练习：自定义互相关计算类的自动求梯度"></a>练习：自定义互相关计算类的自动求梯度</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = nd.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conv2D</span><span class="params">(nn.Block)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, batch_size, channels, kernel_size, **kwargs)</span>:</span></span><br><span class="line">        super(Conv2D, self).__init__(**kwargs)</span><br><span class="line">        self.num_filter = channels</span><br><span class="line">        self.kernel_size = kernel_size</span><br><span class="line">        self.weight = self.params.get(<span class="string">'weight'</span>, shape=(batch_size, channels, kernel_size[<span class="number">0</span>], kernel_size[<span class="number">1</span>]))</span><br><span class="line">        self.bias = self.params.get(<span class="string">'bias'</span>, shape=(channels,))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># result = corr2d(x, self.weight.data()) + self.bias.data()</span></span><br><span class="line">        result = nd.Convolution(x, self.weight.data(), self.bias.data(), num_filter=self.num_filter,</span><br><span class="line">                                kernel=self.kernel_size)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">conv2d = Conv2D(<span class="number">1</span>, <span class="number">1</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">X = nd.ones((<span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">conv2d.initialize()</span><br><span class="line">X = X.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line"><span class="keyword">with</span> autograd.record():</span><br><span class="line">    Y = conv2d(X)</span><br><span class="line"></span><br><span class="line">Y.backward()</span><br><span class="line">print(Y)</span><br><span class="line">print(conv2d.weight.grad())</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Outputs:</span><br><span class="line">[[[[<span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span></span><br><span class="line">    <span class="number">0.11254273</span>]</span><br><span class="line">   [<span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span></span><br><span class="line">    <span class="number">0.11254273</span>]</span><br><span class="line">   [<span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span></span><br><span class="line">    <span class="number">0.11254273</span>]</span><br><span class="line">   [<span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span></span><br><span class="line">    <span class="number">0.11254273</span>]</span><br><span class="line">   [<span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span> <span class="number">0.11254273</span></span><br><span class="line">    <span class="number">0.11254273</span>]]]]</span><br><span class="line">&lt;NDArray <span class="number">1</span>x1x5x7 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line">[[[[<span class="number">35.</span> <span class="number">35.</span>]</span><br><span class="line">   [<span class="number">35.</span> <span class="number">35.</span>]]]]</span><br><span class="line">&lt;NDArray <span class="number">1</span>x1x2x2 @cpu(<span class="number">0</span>)&gt;</span><br></pre></td></tr></tbody></table></figure>
<h2 id="填充和步幅"><a href="#填充和步幅" class="headerlink" title="填充和步幅"></a>填充和步幅</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数来计算卷积层</span></span><br><span class="line"><span class="comment"># 初始化卷积层权重，并对输入和输出做相应的升维和降维</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">comp_conv2d</span><span class="params">(conv2d, X)</span>:</span></span><br><span class="line">    conv2d.initialize()</span><br><span class="line">    <span class="comment"># (1,1)代表批量大小和通道数</span></span><br><span class="line">    X = X.reshape((<span class="number">1</span>, <span class="number">1</span>) + X.shape)</span><br><span class="line">    Y = conv2d(X)</span><br><span class="line">    <span class="keyword">return</span> Y.reshape(Y.shape[<span class="number">2</span>:])  <span class="comment"># 剔除前两维：批量和通道</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># padding决定两侧各填充1行或列</span></span><br><span class="line">conv2d = nn.Conv2D(<span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">X = nd.random.uniform(shape=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">print(comp_conv2d(conv2d, X).shape)</span><br><span class="line"></span><br><span class="line">conv2d = nn.Conv2D(<span class="number">1</span>, kernel_size=(<span class="number">5</span>, <span class="number">3</span>), padding=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">print(comp_conv2d(conv2d, X).shape)</span><br><span class="line"></span><br><span class="line">conv2d = nn.Conv2D(<span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, strides=<span class="number">2</span>)</span><br><span class="line">print(comp_conv2d(conv2d, X).shape)</span><br><span class="line"></span><br><span class="line">conv2d = nn.Conv2D(<span class="number">1</span>, kernel_size=(<span class="number">3</span>, <span class="number">5</span>), padding=(<span class="number">0</span>, <span class="number">1</span>), strides=(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">print(comp_conv2d(conv2d, X).shape)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Outputs:</span><br><span class="line">(<span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">(<span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="多输入通道和多输出通道"><a href="#多输入通道和多输出通道" class="headerlink" title="多输入通道和多输出通道"></a>多输入通道和多输出通道</h2><h3 id="多输入和多输出通道"><a href="#多输入和多输出通道" class="headerlink" title="多输入和多输出通道"></a>多输入和多输出通道</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = nd.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d_multi_in</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> nd.add_n(*[corr2d(x, k) <span class="keyword">for</span> x, k <span class="keyword">in</span> zip(X, K)])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d_multi_in_out</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> nd.stack(*[corr2d_multi_in(X, k) <span class="keyword">for</span> k <span class="keyword">in</span> K])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = nd.array([[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">               [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">               [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]],</span><br><span class="line">              [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">               [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">               [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]])</span><br><span class="line">print(X.shape)</span><br><span class="line">K = nd.array([[[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">               [<span class="number">2</span>, <span class="number">3</span>]],</span><br><span class="line">              [[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">               [<span class="number">3</span>, <span class="number">4</span>]]])</span><br><span class="line">print(corr2d_multi_in(X, K))</span><br><span class="line"></span><br><span class="line">K = nd.stack(K, K + <span class="number">1</span>, K + <span class="number">2</span>)</span><br><span class="line">print(K.shape)</span><br><span class="line"></span><br><span class="line">print(corr2d_multi_in_out(X, K))</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Outputs:</span><br><span class="line">(<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">[[ <span class="number">56.</span>  <span class="number">72.</span>]</span><br><span class="line"> [<span class="number">104.</span> <span class="number">120.</span>]]</span><br><span class="line">&lt;NDArray <span class="number">2</span>x2 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line">(<span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">[[[ <span class="number">56.</span>  <span class="number">72.</span>]</span><br><span class="line">  [<span class="number">104.</span> <span class="number">120.</span>]]</span><br><span class="line"></span><br><span class="line"> [[ <span class="number">76.</span> <span class="number">100.</span>]</span><br><span class="line">  [<span class="number">148.</span> <span class="number">172.</span>]]</span><br><span class="line"></span><br><span class="line"> [[ <span class="number">96.</span> <span class="number">128.</span>]</span><br><span class="line">  [<span class="number">192.</span> <span class="number">224.</span>]]]</span><br><span class="line">&lt;NDArray <span class="number">3</span>x2x2 @cpu(<span class="number">0</span>)&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="1×1卷积层"><a href="#1×1卷积层" class="headerlink" title="1×1卷积层"></a>1×1卷积层</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = nd.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d_multi_in</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> nd.add_n(*[corr2d(x, k) <span class="keyword">for</span> x, k <span class="keyword">in</span> zip(X, K)])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d_multi_in_out</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> nd.stack(*[corr2d_multi_in(X, k) <span class="keyword">for</span> k <span class="keyword">in</span> K])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">corr2d_multi_in_out_1x1</span><span class="params">(X, K)</span>:</span></span><br><span class="line">    c_i, h, w = X.shape</span><br><span class="line">    c_o = K.shape[<span class="number">0</span>]</span><br><span class="line">    X = X.reshape((c_i, h * w))</span><br><span class="line">    K = K.reshape((c_o, c_i))</span><br><span class="line">    Y = nd.dot(K, X)</span><br><span class="line">    <span class="keyword">return</span> Y.reshape((c_o, h, w))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = nd.random.uniform(shape=(<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">K = nd.random.uniform(shape=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">Y1 = corr2d_multi_in_out_1x1(X, K)</span><br><span class="line">Y2 = corr2d_multi_in_out(X, K)</span><br><span class="line">Z = (Y1 - Y2).norm().asscalar() &lt; <span class="number">1e-6</span></span><br><span class="line">print(Z)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Outputs:</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><h3 id="二维最大池化和平均池化"><a href="#二维最大池化和平均池化" class="headerlink" title="二维最大池化和平均池化"></a>二维最大池化和平均池化</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pool2d</span><span class="params">(X, pool_size, mode=<span class="string">'max'</span>)</span>:</span></span><br><span class="line">    p_h, p_w = pool_size</span><br><span class="line">    Y = nd.zeros((X.shape[<span class="number">0</span>] - p_h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - p_w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">'max'</span>:</span><br><span class="line">                Y[i, j] = X[i:i + p_h, j:j + p_w].max()</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">'avg'</span>:</span><br><span class="line">                Y[i, j] = X[i:i + p_h, j:j + p_w].mean()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = nd.array([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">print(pool2d(X, (<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">print(pool2d(X, (<span class="number">2</span>, <span class="number">2</span>), <span class="string">'avg'</span>))</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Output:</span><br><span class="line">[[<span class="number">4.</span> <span class="number">5.</span>]</span><br><span class="line"> [<span class="number">7.</span> <span class="number">8.</span>]]</span><br><span class="line">&lt;NDArray <span class="number">2</span>x2 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line">[[<span class="number">2.</span> <span class="number">3.</span>]</span><br><span class="line"> [<span class="number">5.</span> <span class="number">6.</span>]]</span><br><span class="line">&lt;NDArray <span class="number">2</span>x2 @cpu(<span class="number">0</span>)&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="填充和步幅、多通道"><a href="#填充和步幅、多通道" class="headerlink" title="填充和步幅、多通道"></a>填充和步幅、多通道</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line">X = nd.arange(<span class="number">16</span>).reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">print(X)</span><br><span class="line"></span><br><span class="line">pool2d = nn.MaxPool2D(pool_size=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 池化层没有模型参数，故不需要初始化</span></span><br><span class="line">print(pool2d(X))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定填充和步幅</span></span><br><span class="line">pool2d = nn.MaxPool2D(pool_size=<span class="number">3</span>, padding=<span class="number">1</span>, strides=<span class="number">2</span>)</span><br><span class="line">print(pool2d(X))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定非正方形的池化窗口，并分别指定高和宽上的填充和步幅</span></span><br><span class="line">pool2d = nn.MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">3</span>), padding=(<span class="number">1</span>, <span class="number">2</span>), strides=(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">print(pool2d(X))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多通道计算</span></span><br><span class="line"><span class="comment"># 构造通道数为2的输入</span></span><br><span class="line">X = nd.concat(X, X + <span class="number">1</span>, dim=<span class="number">1</span>)</span><br><span class="line">print(X)</span><br><span class="line"></span><br><span class="line">pool2d = nn.MaxPool2D(pool_size=<span class="number">3</span>, padding=<span class="number">1</span>, strides=<span class="number">2</span>)</span><br><span class="line">print(pool2d(X))</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">Outputs:</span><br><span class="line">[[[[ <span class="number">0.</span>  <span class="number">1.</span>  <span class="number">2.</span>  <span class="number">3.</span>]</span><br><span class="line">   [ <span class="number">4.</span>  <span class="number">5.</span>  <span class="number">6.</span>  <span class="number">7.</span>]</span><br><span class="line">   [ <span class="number">8.</span>  <span class="number">9.</span> <span class="number">10.</span> <span class="number">11.</span>]</span><br><span class="line">   [<span class="number">12.</span> <span class="number">13.</span> <span class="number">14.</span> <span class="number">15.</span>]]]]</span><br><span class="line">&lt;NDArray <span class="number">1</span>x1x4x4 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line">[[[[<span class="number">10.</span>]]]]</span><br><span class="line">&lt;NDArray <span class="number">1</span>x1x1x1 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line">[[[[ <span class="number">5.</span>  <span class="number">7.</span>]</span><br><span class="line">   [<span class="number">13.</span> <span class="number">15.</span>]]]]</span><br><span class="line">&lt;NDArray <span class="number">1</span>x1x2x2 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line">[[[[ <span class="number">0.</span>  <span class="number">3.</span>]</span><br><span class="line">   [ <span class="number">8.</span> <span class="number">11.</span>]</span><br><span class="line">   [<span class="number">12.</span> <span class="number">15.</span>]]]]</span><br><span class="line">&lt;NDArray <span class="number">1</span>x1x3x2 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line">[[[[ <span class="number">0.</span>  <span class="number">1.</span>  <span class="number">2.</span>  <span class="number">3.</span>]</span><br><span class="line">   [ <span class="number">4.</span>  <span class="number">5.</span>  <span class="number">6.</span>  <span class="number">7.</span>]</span><br><span class="line">   [ <span class="number">8.</span>  <span class="number">9.</span> <span class="number">10.</span> <span class="number">11.</span>]</span><br><span class="line">   [<span class="number">12.</span> <span class="number">13.</span> <span class="number">14.</span> <span class="number">15.</span>]]</span><br><span class="line"></span><br><span class="line">  [[ <span class="number">1.</span>  <span class="number">2.</span>  <span class="number">3.</span>  <span class="number">4.</span>]</span><br><span class="line">   [ <span class="number">5.</span>  <span class="number">6.</span>  <span class="number">7.</span>  <span class="number">8.</span>]</span><br><span class="line">   [ <span class="number">9.</span> <span class="number">10.</span> <span class="number">11.</span> <span class="number">12.</span>]</span><br><span class="line">   [<span class="number">13.</span> <span class="number">14.</span> <span class="number">15.</span> <span class="number">16.</span>]]]]</span><br><span class="line">&lt;NDArray <span class="number">1</span>x2x4x4 @cpu(<span class="number">0</span>)&gt;</span><br><span class="line"></span><br><span class="line">[[[[ <span class="number">5.</span>  <span class="number">7.</span>]</span><br><span class="line">   [<span class="number">13.</span> <span class="number">15.</span>]]</span><br><span class="line"></span><br><span class="line">  [[ <span class="number">6.</span>  <span class="number">8.</span>]</span><br><span class="line">   [<span class="number">14.</span> <span class="number">16.</span>]]]]</span><br><span class="line">&lt;NDArray <span class="number">1</span>x2x2x2 @cpu(<span class="number">0</span>)&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="卷积层和池化层"><a href="#卷积层和池化层" class="headerlink" title="卷积层和池化层"></a>卷积层和池化层</h3><table>
<thead>
<tr>
<th align="center">类型</th>
<th align="left">特点</th>
</tr>
</thead>
<tbody><tr>
<td align="center">卷积层</td>
<td align="left">①互相关运算<br>②对应通道的卷积核与对应的输入互相关运算，结果累加成单通道<br>③躲通道输出需要多输出卷积核，1×1卷积可以通过调整网络层之间的通道数控制模型复杂度<br>④每个通道的卷积核大小一致(不一致行不行？)，参数可不同，需要初始化</td>
</tr>
<tr>
<td align="center">池化层</td>
<td align="left">①最大池化和平均池化<br>②对应通道的输入与池化窗口做池化运算，结果不累加，与输入通道数相同<br>③每个通道的池化窗口一致，没有参数，也不需要初始化<br>④池化步幅默认与窗口大小相同</td>
</tr>
</tbody></table>
<h2 id="卷积神经网络（LeNet）"><a href="#卷积神经网络（LeNet）" class="headerlink" title="卷积神经网络（LeNet）"></a>卷积神经网络（LeNet）</h2><table>
<thead>
<tr>
<th align="center">名称</th>
<th align="left">结构</th>
</tr>
</thead>
<tbody><tr>
<td align="center">LeNet</td>
<td align="left">①卷积层：通道数6，核大小5，激活函数sigmoid<br>②最大池化层：窗口大小2，步幅2<br>③卷积层：通道数16，核大小5，激活函数sigmoid<br>④最大池化层：窗口大小2，步幅2<br>⑤全连接层：输出个数120，激活函数sigmoid<br>⑥全连接层：输出个数84，激活函数sigmoid<br>⑦全连接层：输出个数10</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, gluon, init, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> loss <span class="keyword">as</span> gloss, data <span class="keyword">as</span> gdata, nn</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line">net = nn.Sequential()</span><br><span class="line">net.add(</span><br><span class="line">    <span class="comment"># LeNet包含卷积层块和全连接层块</span></span><br><span class="line">    <span class="comment"># 卷积层块：</span></span><br><span class="line">    <span class="comment"># 卷积层块包含两个基本单位：每个基本单位包含一个卷积层和一个最大池化层</span></span><br><span class="line">    <span class="comment"># 第一个卷积层输出通道数为6，第二个为16</span></span><br><span class="line">    <span class="comment"># 池化层窗口大小2×2，步幅均为2</span></span><br><span class="line">    nn.Conv2D(channels=<span class="number">6</span>, kernel_size=<span class="number">5</span>, activation=<span class="string">'sigmoid'</span>),</span><br><span class="line">    nn.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>),</span><br><span class="line">    nn.Conv2D(channels=<span class="number">16</span>, kernel_size=<span class="number">5</span>, activation=<span class="string">'sigmoid'</span>),</span><br><span class="line">    nn.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># 全连接层块：</span></span><br><span class="line">    <span class="comment"># 全连接层块包含三个全连接层</span></span><br><span class="line">    <span class="comment"># 输出分别是120，84,10(此10为类别个数)</span></span><br><span class="line">    <span class="comment"># 卷积层输出形状为(batch_size, channels, height, width)，</span></span><br><span class="line">    <span class="comment"># 全连接层输入将卷积层输出flatten为形状(batch_size, channels*height*width)</span></span><br><span class="line">    nn.Dense(<span class="number">120</span>, activation=<span class="string">'sigmoid'</span>),</span><br><span class="line">    nn.Dense(<span class="number">84</span>, activation=<span class="string">'sigmoid'</span>),</span><br><span class="line">    nn.Dense(<span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># # 样例输出</span></span><br><span class="line"><span class="comment"># X = nd.random.uniform(shape=(1, 1, 28, 26))</span></span><br><span class="line"><span class="comment"># net.initialize()</span></span><br><span class="line"><span class="comment"># for layer in net:</span></span><br><span class="line"><span class="comment">#     X = layer(X)</span></span><br><span class="line"><span class="comment">#     print(layer.name, 'output shape:\t', X.shape)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span><span class="params">(batch_size)</span>:</span></span><br><span class="line">    mnist_train = gdata.vision.FashionMNIST(train=<span class="literal">True</span>)</span><br><span class="line">    mnist_test = gdata.vision.FashionMNIST(train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ToTensor将图像数据从unit8格式变换成32位浮点数格式，并除以255使得所有像素的数值均在0到1之间。</span></span><br><span class="line">    <span class="comment"># ToTensor还将图像通道的最后一维移动到最前一维来方便后面卷积神经网络计算</span></span><br><span class="line">    transformer = gdata.vision.transforms.ToTensor()</span><br><span class="line">    <span class="comment"># Gluon的DataLoader中一个很方便的共鞥是允许使用多进程来加速数据读取</span></span><br><span class="line">    <span class="comment"># 暂不支持Windows操作系统</span></span><br><span class="line">    <span class="comment"># 通过参数num_workers来设置4个进程读取数据</span></span><br><span class="line">    <span class="keyword">if</span> sys.platform.startswith(<span class="string">'win'</span>):</span><br><span class="line">        num_workers = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        num_workers = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),</span><br><span class="line">                                  batch_size,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  num_workers=num_workers)</span><br><span class="line">    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),</span><br><span class="line">                                 batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=num_workers)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 尝试使用gpu(0)计算，否则仍然使用CPU</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ctx = mx.gpu()</span><br><span class="line">        _ = nd.zeros((<span class="number">1</span>,), ctx=ctx)</span><br><span class="line">    <span class="keyword">except</span> mx.base.MXNetError:</span><br><span class="line">        ctx = mx.cpu()</span><br><span class="line">    <span class="keyword">return</span> ctx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ctx = try_gpu()</span><br><span class="line">print(ctx)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(data_iter, net, ctx)</span>:</span></span><br><span class="line">    acc_sum, n = nd.array([<span class="number">0</span>], ctx=ctx), <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype(<span class="string">'float32'</span>)</span><br><span class="line">        acc_sum += (net(X).argmax(axis=<span class="number">1</span>) == y).sum()</span><br><span class="line">        n += y.size</span><br><span class="line">    <span class="keyword">return</span> acc_sum.asscalar() / n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch5</span><span class="params">(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span>:</span></span><br><span class="line">    print(<span class="string">'training on'</span>, ctx)</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X, y = X.as_in_context(ctx), y.as_in_context(ctx)</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            trainer.step(batch_size)</span><br><span class="line">            y = y.astype(<span class="string">'float32'</span>)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net, ctx)</span><br><span class="line">        print(<span class="string">'epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr, num_epochs = <span class="number">0.9</span>, <span class="number">5</span></span><br><span class="line">net.initialize(force_reinit=<span class="literal">True</span>, ctx=ctx, init=init.Xavier())</span><br><span class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">'sgd'</span>, {<span class="string">'learning_rate'</span>: lr})</span><br><span class="line">train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各层输出形状：</span></span><br><span class="line">conv0 output shape: (<span class="number">1</span>, <span class="number">6</span>, <span class="number">24</span>, <span class="number">24</span>)</span><br><span class="line">pool0 output shape: (<span class="number">1</span>, <span class="number">6</span>, <span class="number">12</span>, <span class="number">12</span>)</span><br><span class="line">conv1 output shape: (<span class="number">1</span>, <span class="number">16</span>, <span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line">pool1 output shape: (<span class="number">1</span>, <span class="number">16</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">dense0 output shape: (<span class="number">1</span>, <span class="number">120</span>)</span><br><span class="line">dense1 output shape: (<span class="number">1</span>, <span class="number">84</span>)</span><br><span class="line">dense2 output shape: (<span class="number">1</span>, <span class="number">10</span>)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br></pre></td><td class="code"><pre><span class="line">Outputs:</span><br><span class="line">cpu(<span class="number">0</span>)</span><br><span class="line">[<span class="number">16</span>:<span class="number">29</span>:<span class="number">43</span>] c:\jenkins\workspace\mxnet-tag\mxnet\src\imperative\./imperative_utils.h:<span class="number">90</span>: GPU support <span class="keyword">is</span> disabled. Compile MXNet <span class="keyword">with</span> USE_CUDA=<span class="number">1</span> to enable GPU support.</span><br><span class="line">training on cpu(<span class="number">0</span>)</span><br><span class="line">epoch <span class="number">1</span>, loss <span class="number">2.3188</span>, train acc <span class="number">0.104</span>, test acc <span class="number">0.157</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">1.4223</span>, train acc <span class="number">0.444</span>, test acc <span class="number">0.650</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">0.8582</span>, train acc <span class="number">0.667</span>, test acc <span class="number">0.717</span>, time <span class="number">28.0</span> sec</span><br><span class="line">epoch <span class="number">4</span>, loss <span class="number">0.7174</span>, train acc <span class="number">0.718</span>, test acc <span class="number">0.737</span>, time <span class="number">27.9</span> sec</span><br><span class="line">epoch <span class="number">5</span>, loss <span class="number">0.6413</span>, train acc <span class="number">0.746</span>, test acc <span class="number">0.766</span>, time <span class="number">28.2</span> sec</span><br><span class="line"><span class="comment"># epochs = 5</span></span><br><span class="line"><span class="comment"># batch_size = 256</span></span><br><span class="line">training on gpu(<span class="number">3</span>)</span><br><span class="line">epoch <span class="number">1</span>, loss <span class="number">2.3165</span>, train acc <span class="number">0.106</span>, test acc <span class="number">0.167</span>, time <span class="number">2.9</span> sec</span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">1.3538</span>, train acc <span class="number">0.474</span>, test acc <span class="number">0.645</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">0.8535</span>, train acc <span class="number">0.670</span>, test acc <span class="number">0.712</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">4</span>, loss <span class="number">0.7151</span>, train acc <span class="number">0.719</span>, test acc <span class="number">0.745</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">5</span>, loss <span class="number">0.6347</span>, train acc <span class="number">0.750</span>, test acc <span class="number">0.740</span>, time <span class="number">2.7</span> sec</span><br><span class="line"><span class="comment"># batch_size = 512</span></span><br><span class="line">epoch <span class="number">1</span>, loss <span class="number">2.3295</span>, train acc <span class="number">0.102</span>, test acc <span class="number">0.100</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">2.2298</span>, train acc <span class="number">0.146</span>, test acc <span class="number">0.401</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">1.2869</span>, train acc <span class="number">0.488</span>, test acc <span class="number">0.614</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">4</span>, loss <span class="number">0.9708</span>, train acc <span class="number">0.615</span>, test acc <span class="number">0.680</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">5</span>, loss <span class="number">0.8490</span>, train acc <span class="number">0.671</span>, test acc <span class="number">0.693</span>, time <span class="number">1.8</span> sec</span><br><span class="line"><span class="comment"># batch_size = 1024</span></span><br><span class="line">epoch <span class="number">1</span>, loss <span class="number">2.3391</span>, train acc <span class="number">0.102</span>, test acc <span class="number">0.100</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">2.3078</span>, train acc <span class="number">0.105</span>, test acc <span class="number">0.100</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">2.2920</span>, train acc <span class="number">0.120</span>, test acc <span class="number">0.243</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">4</span>, loss <span class="number">1.9696</span>, train acc <span class="number">0.246</span>, test acc <span class="number">0.446</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">5</span>, loss <span class="number">1.2872</span>, train acc <span class="number">0.489</span>, test acc <span class="number">0.620</span>, time <span class="number">1.7</span> sec</span><br><span class="line"><span class="comment"># epochs = 10</span></span><br><span class="line"><span class="comment"># batch_size = 256</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">2.3176</span>, train acc <span class="number">0.106</span>, test acc <span class="number">0.149</span>, time <span class="number">2.9</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">1.3815</span>, train acc <span class="number">0.460</span>, test acc <span class="number">0.675</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">0.8556</span>, train acc <span class="number">0.668</span>, test acc <span class="number">0.716</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.7171</span>, train acc <span class="number">0.717</span>, test acc <span class="number">0.742</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.6438</span>, train acc <span class="number">0.745</span>, test acc <span class="number">0.764</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.5867</span>, train acc <span class="number">0.768</span>, test acc <span class="number">0.784</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.5418</span>, train acc <span class="number">0.788</span>, test acc <span class="number">0.791</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.5050</span>, train acc <span class="number">0.803</span>, test acc <span class="number">0.825</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.4802</span>, train acc <span class="number">0.816</span>, test acc <span class="number">0.818</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.4574</span>, train acc <span class="number">0.827</span>, test acc <span class="number">0.841</span>, time <span class="number">2.4</span> sec</span><br><span class="line"><span class="comment"># batch_size = 512</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">2.3272</span>, train acc <span class="number">0.102</span>, test acc <span class="number">0.100</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">2.2300</span>, train acc <span class="number">0.163</span>, test acc <span class="number">0.401</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">1.2864</span>, train acc <span class="number">0.488</span>, test acc <span class="number">0.588</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.9699</span>, train acc <span class="number">0.619</span>, test acc <span class="number">0.648</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.8427</span>, train acc <span class="number">0.673</span>, test acc <span class="number">0.689</span>, time <span class="number">1.9</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.7629</span>, train acc <span class="number">0.702</span>, test acc <span class="number">0.726</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.7022</span>, train acc <span class="number">0.722</span>, test acc <span class="number">0.743</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.6629</span>, train acc <span class="number">0.737</span>, test acc <span class="number">0.754</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.6332</span>, train acc <span class="number">0.747</span>, test acc <span class="number">0.764</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.6008</span>, train acc <span class="number">0.762</span>, test acc <span class="number">0.784</span>, time <span class="number">1.8</span> sec</span><br><span class="line"><span class="comment"># batch_size = 1024</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">2.3383</span>, train acc <span class="number">0.097</span>, test acc <span class="number">0.100</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">2.3079</span>, train acc <span class="number">0.103</span>, test acc <span class="number">0.100</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">2.2941</span>, train acc <span class="number">0.117</span>, test acc <span class="number">0.184</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">1.9952</span>, train acc <span class="number">0.246</span>, test acc <span class="number">0.527</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">1.3037</span>, train acc <span class="number">0.486</span>, test acc <span class="number">0.578</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">1.0575</span>, train acc <span class="number">0.576</span>, test acc <span class="number">0.626</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.9905</span>, train acc <span class="number">0.609</span>, test acc <span class="number">0.653</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.9006</span>, train acc <span class="number">0.647</span>, test acc <span class="number">0.685</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.8429</span>, train acc <span class="number">0.674</span>, test acc <span class="number">0.699</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.7996</span>, train acc <span class="number">0.689</span>, test acc <span class="number">0.714</span>, time <span class="number">1.7</span> sec</span><br><span class="line"><span class="comment"># epochs = 20</span></span><br><span class="line"><span class="comment"># batch_size = 256</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">2.3147</span>, train acc <span class="number">0.110</span>, test acc <span class="number">0.264</span>, time <span class="number">2.8</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">1.3204</span>, train acc <span class="number">0.484</span>, test acc <span class="number">0.644</span>, time <span class="number">2.6</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">0.8441</span>, train acc <span class="number">0.671</span>, test acc <span class="number">0.720</span>, time <span class="number">2.6</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.7153</span>, train acc <span class="number">0.721</span>, test acc <span class="number">0.741</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.6394</span>, train acc <span class="number">0.746</span>, test acc <span class="number">0.770</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.5798</span>, train acc <span class="number">0.772</span>, test acc <span class="number">0.793</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.5389</span>, train acc <span class="number">0.789</span>, test acc <span class="number">0.811</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.5021</span>, train acc <span class="number">0.805</span>, test acc <span class="number">0.818</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.4809</span>, train acc <span class="number">0.815</span>, test acc <span class="number">0.831</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.4605</span>, train acc <span class="number">0.825</span>, test acc <span class="number">0.835</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch <span class="number">11</span>, loss <span class="number">0.4407</span>, train acc <span class="number">0.835</span>, test acc <span class="number">0.838</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch <span class="number">12</span>, loss <span class="number">0.4235</span>, train acc <span class="number">0.841</span>, test acc <span class="number">0.853</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch <span class="number">13</span>, loss <span class="number">0.4078</span>, train acc <span class="number">0.849</span>, test acc <span class="number">0.856</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">14</span>, loss <span class="number">0.3919</span>, train acc <span class="number">0.855</span>, test acc <span class="number">0.860</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">15</span>, loss <span class="number">0.3824</span>, train acc <span class="number">0.859</span>, test acc <span class="number">0.866</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">16</span>, loss <span class="number">0.3705</span>, train acc <span class="number">0.863</span>, test acc <span class="number">0.866</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">17</span>, loss <span class="number">0.3645</span>, train acc <span class="number">0.865</span>, test acc <span class="number">0.867</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">18</span>, loss <span class="number">0.3579</span>, train acc <span class="number">0.868</span>, test acc <span class="number">0.867</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">19</span>, loss <span class="number">0.3495</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.874</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">20</span>, loss <span class="number">0.3418</span>, train acc <span class="number">0.873</span>, test acc <span class="number">0.876</span>, time <span class="number">2.1</span> sec</span><br><span class="line"><span class="comment"># batch_size = 512</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">2.3305</span>, train acc <span class="number">0.101</span>, test acc <span class="number">0.100</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">2.2568</span>, train acc <span class="number">0.136</span>, test acc <span class="number">0.381</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">1.3262</span>, train acc <span class="number">0.484</span>, test acc <span class="number">0.587</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.9825</span>, train acc <span class="number">0.614</span>, test acc <span class="number">0.625</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.8471</span>, train acc <span class="number">0.670</span>, test acc <span class="number">0.702</span>, time <span class="number">1.9</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.7621</span>, train acc <span class="number">0.703</span>, test acc <span class="number">0.725</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.7077</span>, train acc <span class="number">0.720</span>, test acc <span class="number">0.732</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.6625</span>, train acc <span class="number">0.736</span>, test acc <span class="number">0.750</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.6435</span>, train acc <span class="number">0.745</span>, test acc <span class="number">0.757</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.6052</span>, train acc <span class="number">0.760</span>, test acc <span class="number">0.765</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">11</span>, loss <span class="number">0.5793</span>, train acc <span class="number">0.770</span>, test acc <span class="number">0.784</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">12</span>, loss <span class="number">0.5517</span>, train acc <span class="number">0.783</span>, test acc <span class="number">0.770</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">13</span>, loss <span class="number">0.5368</span>, train acc <span class="number">0.790</span>, test acc <span class="number">0.806</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">14</span>, loss <span class="number">0.5189</span>, train acc <span class="number">0.798</span>, test acc <span class="number">0.816</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">15</span>, loss <span class="number">0.4984</span>, train acc <span class="number">0.809</span>, test acc <span class="number">0.820</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">16</span>, loss <span class="number">0.4854</span>, train acc <span class="number">0.815</span>, test acc <span class="number">0.829</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">17</span>, loss <span class="number">0.4692</span>, train acc <span class="number">0.821</span>, test acc <span class="number">0.821</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">18</span>, loss <span class="number">0.4575</span>, train acc <span class="number">0.828</span>, test acc <span class="number">0.829</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">19</span>, loss <span class="number">0.4466</span>, train acc <span class="number">0.833</span>, test acc <span class="number">0.846</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">20</span>, loss <span class="number">0.4357</span>, train acc <span class="number">0.838</span>, test acc <span class="number">0.849</span>, time <span class="number">1.7</span> sec</span><br><span class="line"><span class="comment"># batch_size = 1024</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">2.3384</span>, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">2.3075</span>, train acc <span class="number">0.105</span>, test acc <span class="number">0.100</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">2.2947</span>, train acc <span class="number">0.120</span>, test acc <span class="number">0.122</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">1.9894</span>, train acc <span class="number">0.244</span>, test acc <span class="number">0.497</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">1.3034</span>, train acc <span class="number">0.490</span>, test acc <span class="number">0.578</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">1.0575</span>, train acc <span class="number">0.575</span>, test acc <span class="number">0.626</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.9918</span>, train acc <span class="number">0.608</span>, test acc <span class="number">0.650</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.9057</span>, train acc <span class="number">0.646</span>, test acc <span class="number">0.692</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.8458</span>, train acc <span class="number">0.672</span>, test acc <span class="number">0.703</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.7975</span>, train acc <span class="number">0.688</span>, test acc <span class="number">0.716</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">11</span>, loss <span class="number">0.7521</span>, train acc <span class="number">0.704</span>, test acc <span class="number">0.725</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">12</span>, loss <span class="number">0.7178</span>, train acc <span class="number">0.716</span>, test acc <span class="number">0.734</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">13</span>, loss <span class="number">0.7151</span>, train acc <span class="number">0.718</span>, test acc <span class="number">0.725</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">14</span>, loss <span class="number">0.6748</span>, train acc <span class="number">0.732</span>, test acc <span class="number">0.744</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">15</span>, loss <span class="number">0.6631</span>, train acc <span class="number">0.736</span>, test acc <span class="number">0.746</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">16</span>, loss <span class="number">0.6458</span>, train acc <span class="number">0.745</span>, test acc <span class="number">0.758</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">17</span>, loss <span class="number">0.6266</span>, train acc <span class="number">0.753</span>, test acc <span class="number">0.766</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">18</span>, loss <span class="number">0.6254</span>, train acc <span class="number">0.750</span>, test acc <span class="number">0.767</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">19</span>, loss <span class="number">0.5947</span>, train acc <span class="number">0.765</span>, test acc <span class="number">0.776</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">20</span>, loss <span class="number">0.5896</span>, train acc <span class="number">0.769</span>, test acc <span class="number">0.781</span>, time <span class="number">1.7</span> sec</span><br><span class="line"><span class="comment"># epochs = 40</span></span><br><span class="line"><span class="comment"># batch_size = 256</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">2.3149</span>, train acc <span class="number">0.110</span>, test acc <span class="number">0.171</span>, time <span class="number">2.8</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">1.3295</span>, train acc <span class="number">0.478</span>, test acc <span class="number">0.649</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">0.8467</span>, train acc <span class="number">0.671</span>, test acc <span class="number">0.717</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.7095</span>, train acc <span class="number">0.719</span>, test acc <span class="number">0.745</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.6438</span>, train acc <span class="number">0.744</span>, test acc <span class="number">0.769</span>, time <span class="number">2.6</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.5793</span>, train acc <span class="number">0.772</span>, test acc <span class="number">0.789</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.5436</span>, train acc <span class="number">0.787</span>, test acc <span class="number">0.804</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.5068</span>, train acc <span class="number">0.804</span>, test acc <span class="number">0.818</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.4820</span>, train acc <span class="number">0.815</span>, test acc <span class="number">0.832</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.4575</span>, train acc <span class="number">0.828</span>, test acc <span class="number">0.835</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">11</span>, loss <span class="number">0.4414</span>, train acc <span class="number">0.836</span>, test acc <span class="number">0.849</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">12</span>, loss <span class="number">0.4188</span>, train acc <span class="number">0.844</span>, test acc <span class="number">0.848</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch <span class="number">13</span>, loss <span class="number">0.4047</span>, train acc <span class="number">0.850</span>, test acc <span class="number">0.861</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch <span class="number">14</span>, loss <span class="number">0.3909</span>, train acc <span class="number">0.857</span>, test acc <span class="number">0.860</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">15</span>, loss <span class="number">0.3811</span>, train acc <span class="number">0.860</span>, test acc <span class="number">0.864</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">16</span>, loss <span class="number">0.3710</span>, train acc <span class="number">0.863</span>, test acc <span class="number">0.864</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">17</span>, loss <span class="number">0.3644</span>, train acc <span class="number">0.864</span>, test acc <span class="number">0.863</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">18</span>, loss <span class="number">0.3553</span>, train acc <span class="number">0.869</span>, test acc <span class="number">0.866</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">19</span>, loss <span class="number">0.3480</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.871</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">20</span>, loss <span class="number">0.3414</span>, train acc <span class="number">0.874</span>, test acc <span class="number">0.872</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">21</span>, loss <span class="number">0.3373</span>, train acc <span class="number">0.875</span>, test acc <span class="number">0.874</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch <span class="number">22</span>, loss <span class="number">0.3331</span>, train acc <span class="number">0.877</span>, test acc <span class="number">0.878</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">23</span>, loss <span class="number">0.3271</span>, train acc <span class="number">0.879</span>, test acc <span class="number">0.878</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">24</span>, loss <span class="number">0.3232</span>, train acc <span class="number">0.880</span>, test acc <span class="number">0.883</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch <span class="number">25</span>, loss <span class="number">0.3195</span>, train acc <span class="number">0.882</span>, test acc <span class="number">0.884</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">26</span>, loss <span class="number">0.3138</span>, train acc <span class="number">0.885</span>, test acc <span class="number">0.876</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">27</span>, loss <span class="number">0.3103</span>, train acc <span class="number">0.886</span>, test acc <span class="number">0.883</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">28</span>, loss <span class="number">0.3086</span>, train acc <span class="number">0.886</span>, test acc <span class="number">0.889</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">29</span>, loss <span class="number">0.3034</span>, train acc <span class="number">0.889</span>, test acc <span class="number">0.884</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">30</span>, loss <span class="number">0.3006</span>, train acc <span class="number">0.888</span>, test acc <span class="number">0.884</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">31</span>, loss <span class="number">0.2970</span>, train acc <span class="number">0.890</span>, test acc <span class="number">0.888</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">32</span>, loss <span class="number">0.2948</span>, train acc <span class="number">0.891</span>, test acc <span class="number">0.886</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">33</span>, loss <span class="number">0.2901</span>, train acc <span class="number">0.893</span>, test acc <span class="number">0.889</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">34</span>, loss <span class="number">0.2929</span>, train acc <span class="number">0.891</span>, test acc <span class="number">0.886</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch <span class="number">35</span>, loss <span class="number">0.2832</span>, train acc <span class="number">0.895</span>, test acc <span class="number">0.891</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">36</span>, loss <span class="number">0.2823</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.892</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">37</span>, loss <span class="number">0.2813</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.891</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">38</span>, loss <span class="number">0.2790</span>, train acc <span class="number">0.897</span>, test acc <span class="number">0.892</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch <span class="number">39</span>, loss <span class="number">0.2780</span>, train acc <span class="number">0.897</span>, test acc <span class="number">0.894</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch <span class="number">40</span>, loss <span class="number">0.2747</span>, train acc <span class="number">0.898</span>, test acc <span class="number">0.892</span>, time <span class="number">2.5</span> sec</span><br><span class="line"><span class="comment"># batch_size = 512</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">2.3291</span>, train acc <span class="number">0.099</span>, test acc <span class="number">0.100</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">2.2411</span>, train acc <span class="number">0.150</span>, test acc <span class="number">0.330</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">1.3067</span>, train acc <span class="number">0.483</span>, test acc <span class="number">0.583</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.9740</span>, train acc <span class="number">0.617</span>, test acc <span class="number">0.667</span>, time <span class="number">1.9</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.8470</span>, train acc <span class="number">0.673</span>, test acc <span class="number">0.689</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.7576</span>, train acc <span class="number">0.704</span>, test acc <span class="number">0.729</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.7027</span>, train acc <span class="number">0.722</span>, test acc <span class="number">0.741</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.6632</span>, train acc <span class="number">0.735</span>, test acc <span class="number">0.752</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.6385</span>, train acc <span class="number">0.747</span>, test acc <span class="number">0.765</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.6045</span>, train acc <span class="number">0.759</span>, test acc <span class="number">0.778</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">11</span>, loss <span class="number">0.5783</span>, train acc <span class="number">0.773</span>, test acc <span class="number">0.795</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">12</span>, loss <span class="number">0.5545</span>, train acc <span class="number">0.783</span>, test acc <span class="number">0.790</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">13</span>, loss <span class="number">0.5340</span>, train acc <span class="number">0.791</span>, test acc <span class="number">0.813</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">14</span>, loss <span class="number">0.5177</span>, train acc <span class="number">0.800</span>, test acc <span class="number">0.821</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">15</span>, loss <span class="number">0.4989</span>, train acc <span class="number">0.808</span>, test acc <span class="number">0.823</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">16</span>, loss <span class="number">0.4881</span>, train acc <span class="number">0.813</span>, test acc <span class="number">0.834</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">17</span>, loss <span class="number">0.4726</span>, train acc <span class="number">0.820</span>, test acc <span class="number">0.834</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">18</span>, loss <span class="number">0.4563</span>, train acc <span class="number">0.829</span>, test acc <span class="number">0.827</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">19</span>, loss <span class="number">0.4477</span>, train acc <span class="number">0.831</span>, test acc <span class="number">0.843</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">20</span>, loss <span class="number">0.4345</span>, train acc <span class="number">0.837</span>, test acc <span class="number">0.824</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">21</span>, loss <span class="number">0.4364</span>, train acc <span class="number">0.839</span>, test acc <span class="number">0.852</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">22</span>, loss <span class="number">0.4186</span>, train acc <span class="number">0.845</span>, test acc <span class="number">0.855</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">23</span>, loss <span class="number">0.4088</span>, train acc <span class="number">0.848</span>, test acc <span class="number">0.852</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">24</span>, loss <span class="number">0.3993</span>, train acc <span class="number">0.854</span>, test acc <span class="number">0.855</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">25</span>, loss <span class="number">0.3914</span>, train acc <span class="number">0.856</span>, test acc <span class="number">0.863</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">26</span>, loss <span class="number">0.3887</span>, train acc <span class="number">0.857</span>, test acc <span class="number">0.858</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">27</span>, loss <span class="number">0.3837</span>, train acc <span class="number">0.859</span>, test acc <span class="number">0.865</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">28</span>, loss <span class="number">0.3756</span>, train acc <span class="number">0.862</span>, test acc <span class="number">0.865</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">29</span>, loss <span class="number">0.3738</span>, train acc <span class="number">0.862</span>, test acc <span class="number">0.869</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">30</span>, loss <span class="number">0.3656</span>, train acc <span class="number">0.866</span>, test acc <span class="number">0.869</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">31</span>, loss <span class="number">0.3608</span>, train acc <span class="number">0.867</span>, test acc <span class="number">0.864</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">32</span>, loss <span class="number">0.3571</span>, train acc <span class="number">0.867</span>, test acc <span class="number">0.869</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">33</span>, loss <span class="number">0.3538</span>, train acc <span class="number">0.869</span>, test acc <span class="number">0.875</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">34</span>, loss <span class="number">0.3485</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.876</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">35</span>, loss <span class="number">0.3461</span>, train acc <span class="number">0.873</span>, test acc <span class="number">0.873</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">36</span>, loss <span class="number">0.3478</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.869</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">37</span>, loss <span class="number">0.3358</span>, train acc <span class="number">0.876</span>, test acc <span class="number">0.876</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">38</span>, loss <span class="number">0.3395</span>, train acc <span class="number">0.874</span>, test acc <span class="number">0.874</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">39</span>, loss <span class="number">0.3320</span>, train acc <span class="number">0.878</span>, test acc <span class="number">0.877</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">40</span>, loss <span class="number">0.3325</span>, train acc <span class="number">0.878</span>, test acc <span class="number">0.880</span>, time <span class="number">1.6</span> sec</span><br><span class="line"><span class="comment"># batch_size = 1024</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">2.3394</span>, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">2.3087</span>, train acc <span class="number">0.102</span>, test acc <span class="number">0.100</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">2.2945</span>, train acc <span class="number">0.127</span>, test acc <span class="number">0.213</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">2.0130</span>, train acc <span class="number">0.241</span>, test acc <span class="number">0.472</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">1.3173</span>, train acc <span class="number">0.474</span>, test acc <span class="number">0.586</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">1.0651</span>, train acc <span class="number">0.577</span>, test acc <span class="number">0.639</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.9873</span>, train acc <span class="number">0.608</span>, test acc <span class="number">0.676</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.9044</span>, train acc <span class="number">0.645</span>, test acc <span class="number">0.670</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.8432</span>, train acc <span class="number">0.671</span>, test acc <span class="number">0.706</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.7979</span>, train acc <span class="number">0.689</span>, test acc <span class="number">0.711</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">11</span>, loss <span class="number">0.7482</span>, train acc <span class="number">0.707</span>, test acc <span class="number">0.722</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">12</span>, loss <span class="number">0.7326</span>, train acc <span class="number">0.710</span>, test acc <span class="number">0.726</span>, time <span class="number">1.5</span> sec</span><br><span class="line">epoch <span class="number">13</span>, loss <span class="number">0.6976</span>, train acc <span class="number">0.721</span>, test acc <span class="number">0.738</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">14</span>, loss <span class="number">0.6774</span>, train acc <span class="number">0.730</span>, test acc <span class="number">0.741</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">15</span>, loss <span class="number">0.6664</span>, train acc <span class="number">0.735</span>, test acc <span class="number">0.749</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">16</span>, loss <span class="number">0.6353</span>, train acc <span class="number">0.748</span>, test acc <span class="number">0.754</span>, time <span class="number">1.5</span> sec</span><br><span class="line">epoch <span class="number">17</span>, loss <span class="number">0.6288</span>, train acc <span class="number">0.748</span>, test acc <span class="number">0.770</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">18</span>, loss <span class="number">0.5929</span>, train acc <span class="number">0.765</span>, test acc <span class="number">0.774</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">19</span>, loss <span class="number">0.6011</span>, train acc <span class="number">0.761</span>, test acc <span class="number">0.778</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">20</span>, loss <span class="number">0.5695</span>, train acc <span class="number">0.776</span>, test acc <span class="number">0.791</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">21</span>, loss <span class="number">0.5669</span>, train acc <span class="number">0.777</span>, test acc <span class="number">0.795</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">22</span>, loss <span class="number">0.5462</span>, train acc <span class="number">0.786</span>, test acc <span class="number">0.802</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">23</span>, loss <span class="number">0.5312</span>, train acc <span class="number">0.793</span>, test acc <span class="number">0.810</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">24</span>, loss <span class="number">0.5282</span>, train acc <span class="number">0.792</span>, test acc <span class="number">0.815</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">25</span>, loss <span class="number">0.5105</span>, train acc <span class="number">0.801</span>, test acc <span class="number">0.808</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">26</span>, loss <span class="number">0.5104</span>, train acc <span class="number">0.802</span>, test acc <span class="number">0.820</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">27</span>, loss <span class="number">0.4950</span>, train acc <span class="number">0.809</span>, test acc <span class="number">0.826</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">28</span>, loss <span class="number">0.4860</span>, train acc <span class="number">0.812</span>, test acc <span class="number">0.828</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">29</span>, loss <span class="number">0.4832</span>, train acc <span class="number">0.816</span>, test acc <span class="number">0.832</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">30</span>, loss <span class="number">0.4737</span>, train acc <span class="number">0.817</span>, test acc <span class="number">0.836</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">31</span>, loss <span class="number">0.4655</span>, train acc <span class="number">0.824</span>, test acc <span class="number">0.838</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">32</span>, loss <span class="number">0.4579</span>, train acc <span class="number">0.828</span>, test acc <span class="number">0.845</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">33</span>, loss <span class="number">0.4535</span>, train acc <span class="number">0.828</span>, test acc <span class="number">0.843</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch <span class="number">34</span>, loss <span class="number">0.4400</span>, train acc <span class="number">0.834</span>, test acc <span class="number">0.848</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">35</span>, loss <span class="number">0.4346</span>, train acc <span class="number">0.838</span>, test acc <span class="number">0.847</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">36</span>, loss <span class="number">0.4364</span>, train acc <span class="number">0.836</span>, test acc <span class="number">0.851</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">37</span>, loss <span class="number">0.4240</span>, train acc <span class="number">0.844</span>, test acc <span class="number">0.853</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">38</span>, loss <span class="number">0.4236</span>, train acc <span class="number">0.842</span>, test acc <span class="number">0.854</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch <span class="number">39</span>, loss <span class="number">0.4159</span>, train acc <span class="number">0.848</span>, test acc <span class="number">0.853</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">40</span>, loss <span class="number">0.4125</span>, train acc <span class="number">0.848</span>, test acc <span class="number">0.856</span>, time <span class="number">1.8</span> sec</span><br><span class="line"><span class="comment"># epochs = 100</span></span><br><span class="line"><span class="comment"># batch_size = 256</span></span><br><span class="line">epoch   <span class="number">1</span>, loss <span class="number">2.3139</span>, train acc <span class="number">0.111</span>, test acc <span class="number">0.190</span>, time <span class="number">2.9</span> sec</span><br><span class="line">epoch   <span class="number">2</span>, loss <span class="number">1.3241</span>, train acc <span class="number">0.484</span>, test acc <span class="number">0.660</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch   <span class="number">3</span>, loss <span class="number">0.8509</span>, train acc <span class="number">0.671</span>, test acc <span class="number">0.695</span>, time <span class="number">2.5</span> sec</span><br><span class="line">epoch   <span class="number">4</span>, loss <span class="number">0.7113</span>, train acc <span class="number">0.719</span>, test acc <span class="number">0.731</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch   <span class="number">5</span>, loss <span class="number">0.6368</span>, train acc <span class="number">0.748</span>, test acc <span class="number">0.759</span>, time <span class="number">2.7</span> sec</span><br><span class="line">epoch   <span class="number">6</span>, loss <span class="number">0.5802</span>, train acc <span class="number">0.770</span>, test acc <span class="number">0.794</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch   <span class="number">7</span>, loss <span class="number">0.5416</span>, train acc <span class="number">0.786</span>, test acc <span class="number">0.802</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch   <span class="number">8</span>, loss <span class="number">0.5086</span>, train acc <span class="number">0.803</span>, test acc <span class="number">0.815</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch   <span class="number">9</span>, loss <span class="number">0.4788</span>, train acc <span class="number">0.815</span>, test acc <span class="number">0.830</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">10</span>, loss <span class="number">0.4565</span>, train acc <span class="number">0.828</span>, test acc <span class="number">0.844</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">11</span>, loss <span class="number">0.4373</span>, train acc <span class="number">0.836</span>, test acc <span class="number">0.840</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">12</span>, loss <span class="number">0.4221</span>, train acc <span class="number">0.842</span>, test acc <span class="number">0.854</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">13</span>, loss <span class="number">0.4052</span>, train acc <span class="number">0.848</span>, test acc <span class="number">0.856</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">14</span>, loss <span class="number">0.3922</span>, train acc <span class="number">0.855</span>, test acc <span class="number">0.861</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">15</span>, loss <span class="number">0.3788</span>, train acc <span class="number">0.861</span>, test acc <span class="number">0.863</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch  <span class="number">16</span>, loss <span class="number">0.3720</span>, train acc <span class="number">0.863</span>, test acc <span class="number">0.864</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">17</span>, loss <span class="number">0.3634</span>, train acc <span class="number">0.866</span>, test acc <span class="number">0.865</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">18</span>, loss <span class="number">0.3560</span>, train acc <span class="number">0.870</span>, test acc <span class="number">0.866</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">19</span>, loss <span class="number">0.3486</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.873</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">20</span>, loss <span class="number">0.3446</span>, train acc <span class="number">0.873</span>, test acc <span class="number">0.873</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">21</span>, loss <span class="number">0.3357</span>, train acc <span class="number">0.876</span>, test acc <span class="number">0.879</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch  <span class="number">22</span>, loss <span class="number">0.3321</span>, train acc <span class="number">0.878</span>, test acc <span class="number">0.877</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">23</span>, loss <span class="number">0.3285</span>, train acc <span class="number">0.879</span>, test acc <span class="number">0.882</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">24</span>, loss <span class="number">0.3220</span>, train acc <span class="number">0.880</span>, test acc <span class="number">0.883</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">25</span>, loss <span class="number">0.3202</span>, train acc <span class="number">0.882</span>, test acc <span class="number">0.874</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">26</span>, loss <span class="number">0.3130</span>, train acc <span class="number">0.885</span>, test acc <span class="number">0.883</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">27</span>, loss <span class="number">0.3119</span>, train acc <span class="number">0.886</span>, test acc <span class="number">0.885</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">28</span>, loss <span class="number">0.3069</span>, train acc <span class="number">0.886</span>, test acc <span class="number">0.881</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">29</span>, loss <span class="number">0.3026</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.883</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">30</span>, loss <span class="number">0.3002</span>, train acc <span class="number">0.888</span>, test acc <span class="number">0.889</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">31</span>, loss <span class="number">0.2979</span>, train acc <span class="number">0.891</span>, test acc <span class="number">0.890</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">32</span>, loss <span class="number">0.2943</span>, train acc <span class="number">0.891</span>, test acc <span class="number">0.882</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">33</span>, loss <span class="number">0.2922</span>, train acc <span class="number">0.892</span>, test acc <span class="number">0.893</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">34</span>, loss <span class="number">0.2896</span>, train acc <span class="number">0.893</span>, test acc <span class="number">0.893</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">35</span>, loss <span class="number">0.2838</span>, train acc <span class="number">0.895</span>, test acc <span class="number">0.892</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">36</span>, loss <span class="number">0.2832</span>, train acc <span class="number">0.895</span>, test acc <span class="number">0.892</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">37</span>, loss <span class="number">0.2825</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.891</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">38</span>, loss <span class="number">0.2774</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.888</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">39</span>, loss <span class="number">0.2758</span>, train acc <span class="number">0.897</span>, test acc <span class="number">0.894</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">40</span>, loss <span class="number">0.2732</span>, train acc <span class="number">0.898</span>, test acc <span class="number">0.894</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">41</span>, loss <span class="number">0.2714</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.892</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">42</span>, loss <span class="number">0.2676</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.892</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">43</span>, loss <span class="number">0.2670</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.896</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">44</span>, loss <span class="number">0.2650</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.896</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">45</span>, loss <span class="number">0.2643</span>, train acc <span class="number">0.900</span>, test acc <span class="number">0.894</span>, time <span class="number">2.0</span> sec</span><br><span class="line">epoch  <span class="number">46</span>, loss <span class="number">0.2613</span>, train acc <span class="number">0.903</span>, test acc <span class="number">0.896</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">47</span>, loss <span class="number">0.2587</span>, train acc <span class="number">0.903</span>, test acc <span class="number">0.897</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">48</span>, loss <span class="number">0.2592</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.888</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">49</span>, loss <span class="number">0.2544</span>, train acc <span class="number">0.906</span>, test acc <span class="number">0.895</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">50</span>, loss <span class="number">0.2567</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.897</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">51</span>, loss <span class="number">0.2531</span>, train acc <span class="number">0.905</span>, test acc <span class="number">0.897</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">52</span>, loss <span class="number">0.2507</span>, train acc <span class="number">0.907</span>, test acc <span class="number">0.896</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">53</span>, loss <span class="number">0.2495</span>, train acc <span class="number">0.907</span>, test acc <span class="number">0.896</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">54</span>, loss <span class="number">0.2480</span>, train acc <span class="number">0.908</span>, test acc <span class="number">0.899</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">55</span>, loss <span class="number">0.2473</span>, train acc <span class="number">0.907</span>, test acc <span class="number">0.899</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">56</span>, loss <span class="number">0.2458</span>, train acc <span class="number">0.909</span>, test acc <span class="number">0.897</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">57</span>, loss <span class="number">0.2430</span>, train acc <span class="number">0.909</span>, test acc <span class="number">0.899</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">58</span>, loss <span class="number">0.2413</span>, train acc <span class="number">0.910</span>, test acc <span class="number">0.895</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch  <span class="number">59</span>, loss <span class="number">0.2386</span>, train acc <span class="number">0.911</span>, test acc <span class="number">0.901</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">60</span>, loss <span class="number">0.2375</span>, train acc <span class="number">0.911</span>, test acc <span class="number">0.901</span>, time <span class="number">2.4</span> sec</span><br><span class="line">epoch  <span class="number">61</span>, loss <span class="number">0.2358</span>, train acc <span class="number">0.912</span>, test acc <span class="number">0.901</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">62</span>, loss <span class="number">0.2346</span>, train acc <span class="number">0.912</span>, test acc <span class="number">0.901</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">63</span>, loss <span class="number">0.2344</span>, train acc <span class="number">0.912</span>, test acc <span class="number">0.896</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">64</span>, loss <span class="number">0.2328</span>, train acc <span class="number">0.913</span>, test acc <span class="number">0.903</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">65</span>, loss <span class="number">0.2303</span>, train acc <span class="number">0.913</span>, test acc <span class="number">0.903</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">66</span>, loss <span class="number">0.2286</span>, train acc <span class="number">0.914</span>, test acc <span class="number">0.902</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">67</span>, loss <span class="number">0.2273</span>, train acc <span class="number">0.914</span>, test acc <span class="number">0.902</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">68</span>, loss <span class="number">0.2263</span>, train acc <span class="number">0.916</span>, test acc <span class="number">0.904</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">69</span>, loss <span class="number">0.2244</span>, train acc <span class="number">0.916</span>, test acc <span class="number">0.903</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">70</span>, loss <span class="number">0.2233</span>, train acc <span class="number">0.916</span>, test acc <span class="number">0.904</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">71</span>, loss <span class="number">0.2229</span>, train acc <span class="number">0.917</span>, test acc <span class="number">0.900</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">72</span>, loss <span class="number">0.2206</span>, train acc <span class="number">0.917</span>, test acc <span class="number">0.901</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">73</span>, loss <span class="number">0.2183</span>, train acc <span class="number">0.918</span>, test acc <span class="number">0.905</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">74</span>, loss <span class="number">0.2200</span>, train acc <span class="number">0.919</span>, test acc <span class="number">0.903</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">75</span>, loss <span class="number">0.2173</span>, train acc <span class="number">0.919</span>, test acc <span class="number">0.895</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">76</span>, loss <span class="number">0.2166</span>, train acc <span class="number">0.918</span>, test acc <span class="number">0.903</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">77</span>, loss <span class="number">0.2141</span>, train acc <span class="number">0.920</span>, test acc <span class="number">0.904</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">78</span>, loss <span class="number">0.2134</span>, train acc <span class="number">0.919</span>, test acc <span class="number">0.905</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">79</span>, loss <span class="number">0.2116</span>, train acc <span class="number">0.920</span>, test acc <span class="number">0.906</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">80</span>, loss <span class="number">0.2084</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.906</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">81</span>, loss <span class="number">0.2095</span>, train acc <span class="number">0.921</span>, test acc <span class="number">0.903</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">82</span>, loss <span class="number">0.2069</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.903</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">83</span>, loss <span class="number">0.2074</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.902</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">84</span>, loss <span class="number">0.2041</span>, train acc <span class="number">0.924</span>, test acc <span class="number">0.907</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">85</span>, loss <span class="number">0.2058</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.903</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">86</span>, loss <span class="number">0.2034</span>, train acc <span class="number">0.923</span>, test acc <span class="number">0.901</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">87</span>, loss <span class="number">0.2018</span>, train acc <span class="number">0.923</span>, test acc <span class="number">0.899</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">88</span>, loss <span class="number">0.1987</span>, train acc <span class="number">0.926</span>, test acc <span class="number">0.902</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">89</span>, loss <span class="number">0.1997</span>, train acc <span class="number">0.925</span>, test acc <span class="number">0.902</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">90</span>, loss <span class="number">0.1987</span>, train acc <span class="number">0.925</span>, test acc <span class="number">0.904</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">91</span>, loss <span class="number">0.1981</span>, train acc <span class="number">0.925</span>, test acc <span class="number">0.904</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">92</span>, loss <span class="number">0.1982</span>, train acc <span class="number">0.926</span>, test acc <span class="number">0.904</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch  <span class="number">93</span>, loss <span class="number">0.1954</span>, train acc <span class="number">0.926</span>, test acc <span class="number">0.905</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">94</span>, loss <span class="number">0.1931</span>, train acc <span class="number">0.927</span>, test acc <span class="number">0.903</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">95</span>, loss <span class="number">0.1932</span>, train acc <span class="number">0.928</span>, test acc <span class="number">0.902</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">96</span>, loss <span class="number">0.1911</span>, train acc <span class="number">0.928</span>, test acc <span class="number">0.903</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">97</span>, loss <span class="number">0.1901</span>, train acc <span class="number">0.929</span>, test acc <span class="number">0.894</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch  <span class="number">98</span>, loss <span class="number">0.1885</span>, train acc <span class="number">0.930</span>, test acc <span class="number">0.900</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch  <span class="number">99</span>, loss <span class="number">0.1883</span>, train acc <span class="number">0.930</span>, test acc <span class="number">0.899</span>, time <span class="number">2.1</span> sec</span><br><span class="line">epoch <span class="number">100</span>, loss <span class="number">0.1876</span>, train acc <span class="number">0.929</span>, test acc <span class="number">0.906</span>, time <span class="number">2.1</span> sec</span><br><span class="line"><span class="comment"># batch_size = 512</span></span><br><span class="line">epoch   <span class="number">1</span>, loss <span class="number">2.3279</span>, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">2.2</span> sec</span><br><span class="line">epoch   <span class="number">2</span>, loss <span class="number">2.2510</span>, train acc <span class="number">0.138</span>, test acc <span class="number">0.325</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch   <span class="number">3</span>, loss <span class="number">1.3155</span>, train acc <span class="number">0.480</span>, test acc <span class="number">0.540</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch   <span class="number">4</span>, loss <span class="number">0.9752</span>, train acc <span class="number">0.613</span>, test acc <span class="number">0.665</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch   <span class="number">5</span>, loss <span class="number">0.8506</span>, train acc <span class="number">0.670</span>, test acc <span class="number">0.710</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch   <span class="number">6</span>, loss <span class="number">0.7536</span>, train acc <span class="number">0.707</span>, test acc <span class="number">0.729</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch   <span class="number">7</span>, loss <span class="number">0.6988</span>, train acc <span class="number">0.723</span>, test acc <span class="number">0.741</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch   <span class="number">8</span>, loss <span class="number">0.6548</span>, train acc <span class="number">0.738</span>, test acc <span class="number">0.752</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch   <span class="number">9</span>, loss <span class="number">0.6272</span>, train acc <span class="number">0.752</span>, test acc <span class="number">0.772</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">10</span>, loss <span class="number">0.5857</span>, train acc <span class="number">0.767</span>, test acc <span class="number">0.777</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">11</span>, loss <span class="number">0.5685</span>, train acc <span class="number">0.775</span>, test acc <span class="number">0.790</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">12</span>, loss <span class="number">0.5419</span>, train acc <span class="number">0.786</span>, test acc <span class="number">0.792</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">13</span>, loss <span class="number">0.5149</span>, train acc <span class="number">0.800</span>, test acc <span class="number">0.810</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">14</span>, loss <span class="number">0.4998</span>, train acc <span class="number">0.807</span>, test acc <span class="number">0.823</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">15</span>, loss <span class="number">0.4857</span>, train acc <span class="number">0.813</span>, test acc <span class="number">0.833</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">16</span>, loss <span class="number">0.4787</span>, train acc <span class="number">0.816</span>, test acc <span class="number">0.816</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">17</span>, loss <span class="number">0.4559</span>, train acc <span class="number">0.828</span>, test acc <span class="number">0.840</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">18</span>, loss <span class="number">0.4437</span>, train acc <span class="number">0.834</span>, test acc <span class="number">0.843</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">19</span>, loss <span class="number">0.4368</span>, train acc <span class="number">0.836</span>, test acc <span class="number">0.836</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">20</span>, loss <span class="number">0.4254</span>, train acc <span class="number">0.843</span>, test acc <span class="number">0.857</span>, time <span class="number">1.9</span> sec</span><br><span class="line">epoch  <span class="number">21</span>, loss <span class="number">0.4097</span>, train acc <span class="number">0.849</span>, test acc <span class="number">0.848</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">22</span>, loss <span class="number">0.4058</span>, train acc <span class="number">0.850</span>, test acc <span class="number">0.863</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">23</span>, loss <span class="number">0.3972</span>, train acc <span class="number">0.854</span>, test acc <span class="number">0.857</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">24</span>, loss <span class="number">0.3909</span>, train acc <span class="number">0.857</span>, test acc <span class="number">0.862</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">25</span>, loss <span class="number">0.3825</span>, train acc <span class="number">0.860</span>, test acc <span class="number">0.863</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">26</span>, loss <span class="number">0.3772</span>, train acc <span class="number">0.860</span>, test acc <span class="number">0.859</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">27</span>, loss <span class="number">0.3758</span>, train acc <span class="number">0.861</span>, test acc <span class="number">0.867</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">28</span>, loss <span class="number">0.3680</span>, train acc <span class="number">0.865</span>, test acc <span class="number">0.867</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">29</span>, loss <span class="number">0.3627</span>, train acc <span class="number">0.867</span>, test acc <span class="number">0.869</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">30</span>, loss <span class="number">0.3592</span>, train acc <span class="number">0.868</span>, test acc <span class="number">0.874</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">31</span>, loss <span class="number">0.3561</span>, train acc <span class="number">0.869</span>, test acc <span class="number">0.871</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">32</span>, loss <span class="number">0.3526</span>, train acc <span class="number">0.870</span>, test acc <span class="number">0.871</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">33</span>, loss <span class="number">0.3475</span>, train acc <span class="number">0.872</span>, test acc <span class="number">0.875</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">34</span>, loss <span class="number">0.3486</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.876</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">35</span>, loss <span class="number">0.3385</span>, train acc <span class="number">0.876</span>, test acc <span class="number">0.875</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">36</span>, loss <span class="number">0.3418</span>, train acc <span class="number">0.874</span>, test acc <span class="number">0.877</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">37</span>, loss <span class="number">0.3364</span>, train acc <span class="number">0.876</span>, test acc <span class="number">0.869</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">38</span>, loss <span class="number">0.3316</span>, train acc <span class="number">0.878</span>, test acc <span class="number">0.878</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">39</span>, loss <span class="number">0.3313</span>, train acc <span class="number">0.878</span>, test acc <span class="number">0.877</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">40</span>, loss <span class="number">0.3280</span>, train acc <span class="number">0.878</span>, test acc <span class="number">0.873</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">41</span>, loss <span class="number">0.3261</span>, train acc <span class="number">0.879</span>, test acc <span class="number">0.883</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">42</span>, loss <span class="number">0.3213</span>, train acc <span class="number">0.883</span>, test acc <span class="number">0.877</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">43</span>, loss <span class="number">0.3203</span>, train acc <span class="number">0.882</span>, test acc <span class="number">0.885</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">44</span>, loss <span class="number">0.3173</span>, train acc <span class="number">0.883</span>, test acc <span class="number">0.867</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">45</span>, loss <span class="number">0.3145</span>, train acc <span class="number">0.884</span>, test acc <span class="number">0.879</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">46</span>, loss <span class="number">0.3141</span>, train acc <span class="number">0.883</span>, test acc <span class="number">0.880</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">47</span>, loss <span class="number">0.3110</span>, train acc <span class="number">0.886</span>, test acc <span class="number">0.880</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">48</span>, loss <span class="number">0.3085</span>, train acc <span class="number">0.886</span>, test acc <span class="number">0.881</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">49</span>, loss <span class="number">0.3054</span>, train acc <span class="number">0.888</span>, test acc <span class="number">0.882</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">50</span>, loss <span class="number">0.3058</span>, train acc <span class="number">0.886</span>, test acc <span class="number">0.887</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">51</span>, loss <span class="number">0.3023</span>, train acc <span class="number">0.888</span>, test acc <span class="number">0.883</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">52</span>, loss <span class="number">0.3015</span>, train acc <span class="number">0.889</span>, test acc <span class="number">0.887</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">53</span>, loss <span class="number">0.3005</span>, train acc <span class="number">0.890</span>, test acc <span class="number">0.887</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">54</span>, loss <span class="number">0.2979</span>, train acc <span class="number">0.890</span>, test acc <span class="number">0.886</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">55</span>, loss <span class="number">0.2988</span>, train acc <span class="number">0.889</span>, test acc <span class="number">0.887</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">56</span>, loss <span class="number">0.2939</span>, train acc <span class="number">0.892</span>, test acc <span class="number">0.887</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">57</span>, loss <span class="number">0.2929</span>, train acc <span class="number">0.892</span>, test acc <span class="number">0.881</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">58</span>, loss <span class="number">0.2940</span>, train acc <span class="number">0.892</span>, test acc <span class="number">0.887</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">59</span>, loss <span class="number">0.2891</span>, train acc <span class="number">0.893</span>, test acc <span class="number">0.890</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">60</span>, loss <span class="number">0.2904</span>, train acc <span class="number">0.892</span>, test acc <span class="number">0.892</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">61</span>, loss <span class="number">0.2859</span>, train acc <span class="number">0.895</span>, test acc <span class="number">0.890</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">62</span>, loss <span class="number">0.2870</span>, train acc <span class="number">0.893</span>, test acc <span class="number">0.891</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">63</span>, loss <span class="number">0.2851</span>, train acc <span class="number">0.894</span>, test acc <span class="number">0.893</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">64</span>, loss <span class="number">0.2813</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.894</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">65</span>, loss <span class="number">0.2842</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.892</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">66</span>, loss <span class="number">0.2797</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.883</span>, time <span class="number">1.5</span> sec</span><br><span class="line">epoch  <span class="number">67</span>, loss <span class="number">0.2745</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.893</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">68</span>, loss <span class="number">0.2766</span>, train acc <span class="number">0.897</span>, test acc <span class="number">0.894</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">69</span>, loss <span class="number">0.2766</span>, train acc <span class="number">0.898</span>, test acc <span class="number">0.893</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">70</span>, loss <span class="number">0.2731</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.896</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">71</span>, loss <span class="number">0.2737</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.894</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">72</span>, loss <span class="number">0.2692</span>, train acc <span class="number">0.900</span>, test acc <span class="number">0.897</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">73</span>, loss <span class="number">0.2724</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.894</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">74</span>, loss <span class="number">0.2686</span>, train acc <span class="number">0.900</span>, test acc <span class="number">0.896</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">75</span>, loss <span class="number">0.2698</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.881</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">76</span>, loss <span class="number">0.2676</span>, train acc <span class="number">0.902</span>, test acc <span class="number">0.895</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">77</span>, loss <span class="number">0.2678</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.895</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">78</span>, loss <span class="number">0.2659</span>, train acc <span class="number">0.902</span>, test acc <span class="number">0.897</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">79</span>, loss <span class="number">0.2625</span>, train acc <span class="number">0.903</span>, test acc <span class="number">0.899</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">80</span>, loss <span class="number">0.2628</span>, train acc <span class="number">0.903</span>, test acc <span class="number">0.888</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">81</span>, loss <span class="number">0.2610</span>, train acc <span class="number">0.903</span>, test acc <span class="number">0.897</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">82</span>, loss <span class="number">0.2613</span>, train acc <span class="number">0.902</span>, test acc <span class="number">0.888</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">83</span>, loss <span class="number">0.2579</span>, train acc <span class="number">0.905</span>, test acc <span class="number">0.892</span>, time <span class="number">1.5</span> sec</span><br><span class="line">epoch  <span class="number">84</span>, loss <span class="number">0.2578</span>, train acc <span class="number">0.905</span>, test acc <span class="number">0.896</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">85</span>, loss <span class="number">0.2553</span>, train acc <span class="number">0.905</span>, test acc <span class="number">0.898</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">86</span>, loss <span class="number">0.2569</span>, train acc <span class="number">0.906</span>, test acc <span class="number">0.894</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">87</span>, loss <span class="number">0.2536</span>, train acc <span class="number">0.906</span>, test acc <span class="number">0.899</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">88</span>, loss <span class="number">0.2552</span>, train acc <span class="number">0.905</span>, test acc <span class="number">0.896</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">89</span>, loss <span class="number">0.2528</span>, train acc <span class="number">0.906</span>, test acc <span class="number">0.898</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">90</span>, loss <span class="number">0.2515</span>, train acc <span class="number">0.906</span>, test acc <span class="number">0.899</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">91</span>, loss <span class="number">0.2510</span>, train acc <span class="number">0.907</span>, test acc <span class="number">0.898</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">92</span>, loss <span class="number">0.2507</span>, train acc <span class="number">0.907</span>, test acc <span class="number">0.897</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">93</span>, loss <span class="number">0.2487</span>, train acc <span class="number">0.908</span>, test acc <span class="number">0.896</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">94</span>, loss <span class="number">0.2459</span>, train acc <span class="number">0.909</span>, test acc <span class="number">0.893</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">95</span>, loss <span class="number">0.2466</span>, train acc <span class="number">0.907</span>, test acc <span class="number">0.894</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">96</span>, loss <span class="number">0.2463</span>, train acc <span class="number">0.908</span>, test acc <span class="number">0.898</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">97</span>, loss <span class="number">0.2444</span>, train acc <span class="number">0.910</span>, test acc <span class="number">0.897</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">98</span>, loss <span class="number">0.2431</span>, train acc <span class="number">0.908</span>, test acc <span class="number">0.899</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">99</span>, loss <span class="number">0.2448</span>, train acc <span class="number">0.909</span>, test acc <span class="number">0.899</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">100</span>, loss <span class="number">0.2451</span>, train acc <span class="number">0.908</span>, test acc <span class="number">0.901</span>, time <span class="number">1.6</span> sec</span><br><span class="line"><span class="comment"># batch_size = 1024</span></span><br><span class="line">epoch   <span class="number">1</span>, loss <span class="number">2.3388</span>, train acc <span class="number">0.102</span>, test acc <span class="number">0.100</span>, time <span class="number">2.3</span> sec</span><br><span class="line">epoch   <span class="number">2</span>, loss <span class="number">2.3074</span>, train acc <span class="number">0.102</span>, test acc <span class="number">0.100</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch   <span class="number">3</span>, loss <span class="number">2.2954</span>, train acc <span class="number">0.117</span>, test acc <span class="number">0.186</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch   <span class="number">4</span>, loss <span class="number">2.0140</span>, train acc <span class="number">0.236</span>, test acc <span class="number">0.492</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch   <span class="number">5</span>, loss <span class="number">1.3084</span>, train acc <span class="number">0.487</span>, test acc <span class="number">0.572</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch   <span class="number">6</span>, loss <span class="number">1.0673</span>, train acc <span class="number">0.577</span>, test acc <span class="number">0.655</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch   <span class="number">7</span>, loss <span class="number">0.9726</span>, train acc <span class="number">0.610</span>, test acc <span class="number">0.671</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch   <span class="number">8</span>, loss <span class="number">0.9058</span>, train acc <span class="number">0.644</span>, test acc <span class="number">0.691</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch   <span class="number">9</span>, loss <span class="number">0.8334</span>, train acc <span class="number">0.679</span>, test acc <span class="number">0.706</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">10</span>, loss <span class="number">0.7990</span>, train acc <span class="number">0.688</span>, test acc <span class="number">0.710</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">11</span>, loss <span class="number">0.7526</span>, train acc <span class="number">0.706</span>, test acc <span class="number">0.729</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">12</span>, loss <span class="number">0.7190</span>, train acc <span class="number">0.716</span>, test acc <span class="number">0.737</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">13</span>, loss <span class="number">0.7077</span>, train acc <span class="number">0.719</span>, test acc <span class="number">0.736</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">14</span>, loss <span class="number">0.6746</span>, train acc <span class="number">0.730</span>, test acc <span class="number">0.739</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">15</span>, loss <span class="number">0.6566</span>, train acc <span class="number">0.739</span>, test acc <span class="number">0.744</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">16</span>, loss <span class="number">0.6449</span>, train acc <span class="number">0.743</span>, test acc <span class="number">0.754</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">17</span>, loss <span class="number">0.6136</span>, train acc <span class="number">0.756</span>, test acc <span class="number">0.768</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">18</span>, loss <span class="number">0.6059</span>, train acc <span class="number">0.759</span>, test acc <span class="number">0.773</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">19</span>, loss <span class="number">0.5866</span>, train acc <span class="number">0.767</span>, test acc <span class="number">0.777</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">20</span>, loss <span class="number">0.5743</span>, train acc <span class="number">0.773</span>, test acc <span class="number">0.785</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">21</span>, loss <span class="number">0.5619</span>, train acc <span class="number">0.778</span>, test acc <span class="number">0.799</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">22</span>, loss <span class="number">0.5425</span>, train acc <span class="number">0.789</span>, test acc <span class="number">0.801</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">23</span>, loss <span class="number">0.5313</span>, train acc <span class="number">0.793</span>, test acc <span class="number">0.803</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">24</span>, loss <span class="number">0.5206</span>, train acc <span class="number">0.797</span>, test acc <span class="number">0.805</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">25</span>, loss <span class="number">0.5181</span>, train acc <span class="number">0.796</span>, test acc <span class="number">0.815</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">26</span>, loss <span class="number">0.5035</span>, train acc <span class="number">0.805</span>, test acc <span class="number">0.819</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">27</span>, loss <span class="number">0.4959</span>, train acc <span class="number">0.808</span>, test acc <span class="number">0.822</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">28</span>, loss <span class="number">0.4895</span>, train acc <span class="number">0.812</span>, test acc <span class="number">0.828</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">29</span>, loss <span class="number">0.4759</span>, train acc <span class="number">0.818</span>, test acc <span class="number">0.830</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">30</span>, loss <span class="number">0.4777</span>, train acc <span class="number">0.817</span>, test acc <span class="number">0.833</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">31</span>, loss <span class="number">0.4664</span>, train acc <span class="number">0.823</span>, test acc <span class="number">0.840</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">32</span>, loss <span class="number">0.4556</span>, train acc <span class="number">0.829</span>, test acc <span class="number">0.841</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">33</span>, loss <span class="number">0.4521</span>, train acc <span class="number">0.829</span>, test acc <span class="number">0.844</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">34</span>, loss <span class="number">0.4439</span>, train acc <span class="number">0.833</span>, test acc <span class="number">0.846</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">35</span>, loss <span class="number">0.4362</span>, train acc <span class="number">0.837</span>, test acc <span class="number">0.852</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">36</span>, loss <span class="number">0.4341</span>, train acc <span class="number">0.838</span>, test acc <span class="number">0.853</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">37</span>, loss <span class="number">0.4217</span>, train acc <span class="number">0.844</span>, test acc <span class="number">0.852</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">38</span>, loss <span class="number">0.4198</span>, train acc <span class="number">0.845</span>, test acc <span class="number">0.855</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">39</span>, loss <span class="number">0.4129</span>, train acc <span class="number">0.847</span>, test acc <span class="number">0.847</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">40</span>, loss <span class="number">0.4105</span>, train acc <span class="number">0.849</span>, test acc <span class="number">0.859</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">41</span>, loss <span class="number">0.4044</span>, train acc <span class="number">0.851</span>, test acc <span class="number">0.859</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">42</span>, loss <span class="number">0.4080</span>, train acc <span class="number">0.850</span>, test acc <span class="number">0.856</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">43</span>, loss <span class="number">0.3935</span>, train acc <span class="number">0.855</span>, test acc <span class="number">0.859</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">44</span>, loss <span class="number">0.3964</span>, train acc <span class="number">0.854</span>, test acc <span class="number">0.862</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">45</span>, loss <span class="number">0.3944</span>, train acc <span class="number">0.855</span>, test acc <span class="number">0.864</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">46</span>, loss <span class="number">0.3809</span>, train acc <span class="number">0.860</span>, test acc <span class="number">0.861</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">47</span>, loss <span class="number">0.3863</span>, train acc <span class="number">0.858</span>, test acc <span class="number">0.867</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">48</span>, loss <span class="number">0.3814</span>, train acc <span class="number">0.860</span>, test acc <span class="number">0.866</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">49</span>, loss <span class="number">0.3713</span>, train acc <span class="number">0.864</span>, test acc <span class="number">0.868</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">50</span>, loss <span class="number">0.3725</span>, train acc <span class="number">0.862</span>, test acc <span class="number">0.869</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">51</span>, loss <span class="number">0.3724</span>, train acc <span class="number">0.863</span>, test acc <span class="number">0.870</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">52</span>, loss <span class="number">0.3660</span>, train acc <span class="number">0.866</span>, test acc <span class="number">0.868</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">53</span>, loss <span class="number">0.3639</span>, train acc <span class="number">0.865</span>, test acc <span class="number">0.868</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">54</span>, loss <span class="number">0.3662</span>, train acc <span class="number">0.865</span>, test acc <span class="number">0.867</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">55</span>, loss <span class="number">0.3595</span>, train acc <span class="number">0.869</span>, test acc <span class="number">0.871</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">56</span>, loss <span class="number">0.3604</span>, train acc <span class="number">0.867</span>, test acc <span class="number">0.870</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">57</span>, loss <span class="number">0.3602</span>, train acc <span class="number">0.867</span>, test acc <span class="number">0.873</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">58</span>, loss <span class="number">0.3534</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.870</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">59</span>, loss <span class="number">0.3519</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.873</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">60</span>, loss <span class="number">0.3499</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.875</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">61</span>, loss <span class="number">0.3444</span>, train acc <span class="number">0.874</span>, test acc <span class="number">0.869</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">62</span>, loss <span class="number">0.3483</span>, train acc <span class="number">0.873</span>, test acc <span class="number">0.876</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">63</span>, loss <span class="number">0.3436</span>, train acc <span class="number">0.873</span>, test acc <span class="number">0.876</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">64</span>, loss <span class="number">0.3428</span>, train acc <span class="number">0.875</span>, test acc <span class="number">0.876</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">65</span>, loss <span class="number">0.3452</span>, train acc <span class="number">0.873</span>, test acc <span class="number">0.877</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">66</span>, loss <span class="number">0.3373</span>, train acc <span class="number">0.876</span>, test acc <span class="number">0.879</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">67</span>, loss <span class="number">0.3377</span>, train acc <span class="number">0.876</span>, test acc <span class="number">0.878</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">68</span>, loss <span class="number">0.3362</span>, train acc <span class="number">0.877</span>, test acc <span class="number">0.874</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">69</span>, loss <span class="number">0.3338</span>, train acc <span class="number">0.877</span>, test acc <span class="number">0.876</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">70</span>, loss <span class="number">0.3320</span>, train acc <span class="number">0.879</span>, test acc <span class="number">0.880</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">71</span>, loss <span class="number">0.3363</span>, train acc <span class="number">0.876</span>, test acc <span class="number">0.875</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">72</span>, loss <span class="number">0.3333</span>, train acc <span class="number">0.878</span>, test acc <span class="number">0.880</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">73</span>, loss <span class="number">0.3251</span>, train acc <span class="number">0.881</span>, test acc <span class="number">0.881</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">74</span>, loss <span class="number">0.3289</span>, train acc <span class="number">0.879</span>, test acc <span class="number">0.883</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">75</span>, loss <span class="number">0.3252</span>, train acc <span class="number">0.881</span>, test acc <span class="number">0.883</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">76</span>, loss <span class="number">0.3224</span>, train acc <span class="number">0.882</span>, test acc <span class="number">0.883</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">77</span>, loss <span class="number">0.3228</span>, train acc <span class="number">0.881</span>, test acc <span class="number">0.884</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">78</span>, loss <span class="number">0.3251</span>, train acc <span class="number">0.879</span>, test acc <span class="number">0.882</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">79</span>, loss <span class="number">0.3244</span>, train acc <span class="number">0.880</span>, test acc <span class="number">0.884</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">80</span>, loss <span class="number">0.3187</span>, train acc <span class="number">0.882</span>, test acc <span class="number">0.880</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">81</span>, loss <span class="number">0.3166</span>, train acc <span class="number">0.883</span>, test acc <span class="number">0.884</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">82</span>, loss <span class="number">0.3147</span>, train acc <span class="number">0.884</span>, test acc <span class="number">0.884</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">83</span>, loss <span class="number">0.3137</span>, train acc <span class="number">0.884</span>, test acc <span class="number">0.880</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">84</span>, loss <span class="number">0.3144</span>, train acc <span class="number">0.884</span>, test acc <span class="number">0.881</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">85</span>, loss <span class="number">0.3132</span>, train acc <span class="number">0.884</span>, test acc <span class="number">0.882</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">86</span>, loss <span class="number">0.3144</span>, train acc <span class="number">0.884</span>, test acc <span class="number">0.882</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">87</span>, loss <span class="number">0.3113</span>, train acc <span class="number">0.884</span>, test acc <span class="number">0.884</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">88</span>, loss <span class="number">0.3085</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.884</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">89</span>, loss <span class="number">0.3065</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.886</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">90</span>, loss <span class="number">0.3063</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.885</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">91</span>, loss <span class="number">0.3051</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.888</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">92</span>, loss <span class="number">0.3016</span>, train acc <span class="number">0.889</span>, test acc <span class="number">0.891</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">93</span>, loss <span class="number">0.3039</span>, train acc <span class="number">0.888</span>, test acc <span class="number">0.887</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">94</span>, loss <span class="number">0.3037</span>, train acc <span class="number">0.888</span>, test acc <span class="number">0.888</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">95</span>, loss <span class="number">0.3038</span>, train acc <span class="number">0.888</span>, test acc <span class="number">0.888</span>, time <span class="number">1.6</span> sec</span><br><span class="line">epoch  <span class="number">96</span>, loss <span class="number">0.3000</span>, train acc <span class="number">0.890</span>, test acc <span class="number">0.883</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">97</span>, loss <span class="number">0.3032</span>, train acc <span class="number">0.888</span>, test acc <span class="number">0.886</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch  <span class="number">98</span>, loss <span class="number">0.2968</span>, train acc <span class="number">0.891</span>, test acc <span class="number">0.885</span>, time <span class="number">1.8</span> sec</span><br><span class="line">epoch  <span class="number">99</span>, loss <span class="number">0.2991</span>, train acc <span class="number">0.890</span>, test acc <span class="number">0.891</span>, time <span class="number">1.7</span> sec</span><br><span class="line">epoch <span class="number">100</span>, loss <span class="number">0.2949</span>, train acc <span class="number">0.892</span>, test acc <span class="number">0.890</span>, time <span class="number">1.6</span> sec</span><br></pre></td></tr></tbody></table></figure>
<p><strong>注意：<br>这里发现一个问题：<br>获取的数据集mnist_train是(height,width,channel)的形状，LoadData后是(batch_size, channels, height, width)，而Dense计算后的是(batch_size，channels*height*width)，之前的Softmax回归等的原生实现和简洁实现注意数据的形状转换。</strong><br>MXNet API中的Conv2D的输入说明<br><code>Inputs:
data: 4D input tensor with shape (batch_size, in_channels, height, width) when layout is NCHW. For other layouts shape is permuted accordingly.</code></p>
<h2 id="深度卷积神经网络（AlexNet）"><a href="#深度卷积神经网络（AlexNet）" class="headerlink" title="深度卷积神经网络（AlexNet）"></a>深度卷积神经网络（AlexNet）</h2><table>
<thead>
<tr>
<th align="center">名称</th>
<th align="left">结构</th>
</tr>
</thead>
<tbody><tr>
<td align="center">AlexNet</td>
<td align="left">①卷积层：通道数96，核大小11，步幅4，激活函数ReLU<br>②最大池化层：窗口大小3，步幅2<br>③卷积层：通道数256，核大小5，填充2，激活函数ReLU<br>④最大池化层：窗口大小3，步幅2<br>⑤卷积层：通道数384， 核大小3，填充1，激活函数ReLU<br>⑥卷积层：通道数384， 核大小3，填充1，激活函数ReLU<br>⑦卷积层：通道数256，核大小3，填充1，激活函数ReLU<br>⑧最大池化层：窗口大小3，步幅2<br>⑨全连接层：输出个数4096，激活函数ReLU<br>⑩丢弃层：丢弃概率0.5<br>⑪全连接层：输出个数4096，激活函数ReLU<br>⑫丢弃层：丢弃概率0.5<br>⑬全连接层：输出个数10</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> gluon, init, nd, autograd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> data <span class="keyword">as</span> gdata, loss <span class="keyword">as</span> gloss, nn</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"></span><br><span class="line">net = nn.Sequential()</span><br><span class="line">net.add(</span><br><span class="line">    nn.Conv2D(<span class="number">96</span>, kernel_size=<span class="number">11</span>, strides=<span class="number">4</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span></span><br><span class="line">    nn.Conv2D(<span class="number">256</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数</span></span><br><span class="line">    <span class="comment"># 前两个卷积层后不使用池化层来减小输入的高和宽</span></span><br><span class="line">    nn.Conv2D(<span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    nn.Conv2D(<span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    nn.Conv2D(<span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>),</span><br><span class="line">    <span class="comment"># 使用丢弃层缓解过拟合</span></span><br><span class="line">    nn.Dense(<span class="number">4096</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    nn.Dense(<span class="number">4096</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># 输出层。由于这里使用Fashion-MNIST数据集，所以类别数为10，而非论文中的1000</span></span><br><span class="line">    nn.Dense(<span class="number">10</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">X = nd.random.uniform(shape=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">net.initialize()</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    print(layer.name, <span class="string">'output shape:\t'</span>, X.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span><span class="params">(batch_size, resize=None, root=os.path.join<span class="params">(<span class="string">'-'</span>, <span class="string">'mxnet'</span>, <span class="string">'datasets'</span>, <span class="string">'fashion-mnist'</span>)</span>)</span>:</span></span><br><span class="line">    root = os.path.expanduser(root)  <span class="comment"># 展开用户路径</span></span><br><span class="line">    transformer = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        transformer += [gdata.vision.transforms.Resize(resize)]</span><br><span class="line">    transformer += [gdata.vision.transforms.ToTensor()]</span><br><span class="line">    transformer = gdata.vision.transforms.Compose(transformer)</span><br><span class="line"></span><br><span class="line">    mnist_train = gdata.vision.FashionMNIST(root=root, train=<span class="literal">True</span>)</span><br><span class="line">    mnist_test = gdata.vision.FashionMNIST(root=root, train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    num_workers = <span class="number">0</span> <span class="keyword">if</span> sys.platform.startswith(<span class="string">'win'</span>) <span class="keyword">else</span> <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),</span><br><span class="line">                                  batch_size=batch_size,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  num_workers=num_workers)</span><br><span class="line">    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),</span><br><span class="line">                                 batch_size=batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=num_workers)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 尝试使用gpu(0)计算，否则仍然使用CPU</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ctx = mx.gpu(<span class="number">1</span>)</span><br><span class="line">        _ = nd.zeros((<span class="number">1</span>,), ctx=ctx)</span><br><span class="line">    <span class="keyword">except</span> mx.base.MXNetError:</span><br><span class="line">        ctx = mx.cpu()</span><br><span class="line">    <span class="keyword">return</span> ctx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(data_iter, net, ctx)</span>:</span></span><br><span class="line">    acc_sum, n = nd.array([<span class="number">0</span>], ctx=ctx), <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype(<span class="string">'float32'</span>)</span><br><span class="line">        acc_sum += (net(X).argmax(axis=<span class="number">1</span>) == y).sum()</span><br><span class="line">        n += y.size</span><br><span class="line">    <span class="keyword">return</span> acc_sum.asscalar() / n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_ch5</span><span class="params">(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span>:</span></span><br><span class="line">    print(<span class="string">'training on'</span>, ctx)</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X, y = X.as_in_context(ctx), y.as_in_context(ctx)</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            trainer.step(batch_size)</span><br><span class="line">            y = y.astype(<span class="string">'float32'</span>)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net, ctx)</span><br><span class="line">        print(<span class="string">'epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">224</span>)</span><br><span class="line"></span><br><span class="line">lr, num_epochs, ctx = <span class="number">0.01</span>, <span class="number">5</span>, try_gpu()</span><br><span class="line">net.initialize(force_reinit=<span class="literal">True</span>, ctx=ctx, init=init.Xavier())</span><br><span class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">'sgd'</span>, {<span class="string">'learning_rate'</span>: lr})</span><br><span class="line">train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各输出层形状：</span></span><br><span class="line">conv0 output shape:	 (<span class="number">1</span>, <span class="number">96</span>, <span class="number">54</span>, <span class="number">54</span>)</span><br><span class="line">pool0 output shape:	 (<span class="number">1</span>, <span class="number">96</span>, <span class="number">26</span>, <span class="number">26</span>)</span><br><span class="line">conv1 output shape:	 (<span class="number">1</span>, <span class="number">256</span>, <span class="number">26</span>, <span class="number">26</span>)</span><br><span class="line">pool1 output shape:	 (<span class="number">1</span>, <span class="number">256</span>, <span class="number">12</span>, <span class="number">12</span>)</span><br><span class="line">conv2 output shape:	 (<span class="number">1</span>, <span class="number">384</span>, <span class="number">12</span>, <span class="number">12</span>)</span><br><span class="line">conv3 output shape:	 (<span class="number">1</span>, <span class="number">384</span>, <span class="number">12</span>, <span class="number">12</span>)</span><br><span class="line">conv4 output shape:	 (<span class="number">1</span>, <span class="number">256</span>, <span class="number">12</span>, <span class="number">12</span>)</span><br><span class="line">pool2 output shape:	 (<span class="number">1</span>, <span class="number">256</span>, <span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">dense0 output shape:	 (<span class="number">1</span>, <span class="number">4096</span>)</span><br><span class="line">dropout0 output shape:	 (<span class="number">1</span>, <span class="number">4096</span>)</span><br><span class="line">dense1 output shape:	 (<span class="number">1</span>, <span class="number">4096</span>)</span><br><span class="line">dropout1 output shape:	 (<span class="number">1</span>, <span class="number">4096</span>)</span><br><span class="line">dense2 output shape:	 (<span class="number">1</span>, <span class="number">10</span>)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br></pre></td><td class="code"><pre><span class="line">Outputs:</span><br><span class="line"><span class="comment"># epochs = 5</span></span><br><span class="line"><span class="comment"># batch_size = 128</span></span><br><span class="line">training on gpu(<span class="number">1</span>)</span><br><span class="line">epoch <span class="number">1</span>, loss <span class="number">1.2973</span>, train acc <span class="number">0.513</span>, test acc <span class="number">0.751</span>, time <span class="number">167.6</span> sec</span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">0.6495</span>, train acc <span class="number">0.756</span>, test acc <span class="number">0.809</span>, time <span class="number">166.3</span> sec</span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">0.5321</span>, train acc <span class="number">0.801</span>, test acc <span class="number">0.837</span>, time <span class="number">166.4</span> sec</span><br><span class="line">epoch <span class="number">4</span>, loss <span class="number">0.4692</span>, train acc <span class="number">0.828</span>, test acc <span class="number">0.855</span>, time <span class="number">166.9</span> sec</span><br><span class="line">epoch <span class="number">5</span>, loss <span class="number">0.4257</span>, train acc <span class="number">0.845</span>, test acc <span class="number">0.870</span>, time <span class="number">167.1</span> sec</span><br><span class="line"><span class="comment"># batch_size = 256</span></span><br><span class="line">training on gpu(<span class="number">1</span>)</span><br><span class="line">epoch <span class="number">1</span>, loss <span class="number">1.7323</span>, train acc <span class="number">0.357</span>, test acc <span class="number">0.690</span>, time <span class="number">92.6</span> sec</span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">0.8324</span>, train acc <span class="number">0.687</span>, test acc <span class="number">0.765</span>, time <span class="number">92.3</span> sec</span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">0.6641</span>, train acc <span class="number">0.751</span>, test acc <span class="number">0.798</span>, time <span class="number">92.6</span> sec</span><br><span class="line">epoch <span class="number">4</span>, loss <span class="number">0.5804</span>, train acc <span class="number">0.784</span>, test acc <span class="number">0.814</span>, time <span class="number">92.7</span> sec</span><br><span class="line">epoch <span class="number">5</span>, loss <span class="number">0.5285</span>, train acc <span class="number">0.804</span>, test acc <span class="number">0.835</span>, time <span class="number">92.6</span> sec</span><br><span class="line"><span class="comment"># batch_size = 512</span></span><br><span class="line">training on gpu(<span class="number">1</span>)</span><br><span class="line">epoch <span class="number">1</span>, loss <span class="number">2.2216</span>, train acc <span class="number">0.183</span>, test acc <span class="number">0.505</span>, time <span class="number">61.7</span> sec</span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">1.1832</span>, train acc <span class="number">0.545</span>, test acc <span class="number">0.678</span>, time <span class="number">61.6</span> sec</span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">0.8663</span>, train acc <span class="number">0.669</span>, test acc <span class="number">0.743</span>, time <span class="number">61.6</span> sec</span><br><span class="line">epoch <span class="number">4</span>, loss <span class="number">0.7485</span>, train acc <span class="number">0.718</span>, test acc <span class="number">0.769</span>, time <span class="number">61.5</span> sec</span><br><span class="line">epoch <span class="number">5</span>, loss <span class="number">0.6768</span>, train acc <span class="number">0.747</span>, test acc <span class="number">0.787</span>, time <span class="number">61.6</span> sec</span><br><span class="line"><span class="comment"># epochs = 10</span></span><br><span class="line"><span class="comment"># batch_size = 128</span></span><br><span class="line">training on gpu(<span class="number">3</span>)</span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">1.3067</span>, train acc <span class="number">0.511</span>, test acc <span class="number">0.728</span>, time <span class="number">169.7</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">0.6504</span>, train acc <span class="number">0.758</span>, test acc <span class="number">0.807</span>, time <span class="number">165.9</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">0.5331</span>, train acc <span class="number">0.801</span>, test acc <span class="number">0.841</span>, time <span class="number">165.2</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.4644</span>, train acc <span class="number">0.829</span>, test acc <span class="number">0.860</span>, time <span class="number">166.3</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.4256</span>, train acc <span class="number">0.844</span>, test acc <span class="number">0.864</span>, time <span class="number">166.2</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.3937</span>, train acc <span class="number">0.856</span>, test acc <span class="number">0.876</span>, time <span class="number">166.8</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.3722</span>, train acc <span class="number">0.865</span>, test acc <span class="number">0.878</span>, time <span class="number">167.0</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.3540</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.885</span>, time <span class="number">166.8</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.3396</span>, train acc <span class="number">0.877</span>, test acc <span class="number">0.886</span>, time <span class="number">166.1</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.3251</span>, train acc <span class="number">0.881</span>, test acc <span class="number">0.891</span>, time <span class="number">165.6</span> sec</span><br><span class="line"><span class="comment"># batch_size =256</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">1.7256</span>, train acc <span class="number">0.356</span>, test acc <span class="number">0.667</span>, time <span class="number">100.7</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">0.8327</span>, train acc <span class="number">0.687</span>, test acc <span class="number">0.760</span>, time <span class="number">98.0</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">0.6660</span>, train acc <span class="number">0.750</span>, test acc <span class="number">0.803</span>, time <span class="number">98.2</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.5800</span>, train acc <span class="number">0.785</span>, test acc <span class="number">0.818</span>, time <span class="number">97.8</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.5286</span>, train acc <span class="number">0.803</span>, test acc <span class="number">0.830</span>, time <span class="number">97.8</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.4896</span>, train acc <span class="number">0.820</span>, test acc <span class="number">0.850</span>, time <span class="number">97.0</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.4584</span>, train acc <span class="number">0.832</span>, test acc <span class="number">0.858</span>, time <span class="number">97.9</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.4357</span>, train acc <span class="number">0.841</span>, test acc <span class="number">0.861</span>, time <span class="number">98.0</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.4162</span>, train acc <span class="number">0.847</span>, test acc <span class="number">0.869</span>, time <span class="number">99.0</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.3980</span>, train acc <span class="number">0.855</span>, test acc <span class="number">0.873</span>, time <span class="number">96.7</span> sec</span><br><span class="line"><span class="comment"># batch_size = 512</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">2.2264</span>, train acc <span class="number">0.186</span>, test acc <span class="number">0.499</span>, time <span class="number">67.4</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">1.1839</span>, train acc <span class="number">0.547</span>, test acc <span class="number">0.688</span>, time <span class="number">60.6</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">0.8716</span>, train acc <span class="number">0.670</span>, test acc <span class="number">0.723</span>, time <span class="number">59.7</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.7464</span>, train acc <span class="number">0.722</span>, test acc <span class="number">0.763</span>, time <span class="number">60.1</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.6740</span>, train acc <span class="number">0.748</span>, test acc <span class="number">0.792</span>, time <span class="number">60.1</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.6182</span>, train acc <span class="number">0.770</span>, test acc <span class="number">0.802</span>, time <span class="number">60.1</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.5781</span>, train acc <span class="number">0.786</span>, test acc <span class="number">0.818</span>, time <span class="number">59.8</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.5479</span>, train acc <span class="number">0.796</span>, test acc <span class="number">0.824</span>, time <span class="number">60.5</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.5188</span>, train acc <span class="number">0.808</span>, test acc <span class="number">0.835</span>, time <span class="number">60.0</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.4988</span>, train acc <span class="number">0.816</span>, test acc <span class="number">0.845</span>, time <span class="number">60.1</span> sec</span><br><span class="line"><span class="comment"># epochs = 20</span></span><br><span class="line"><span class="comment"># batch_size = 128</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">1.3055</span>, train acc <span class="number">0.510</span>, test acc <span class="number">0.734</span>, time <span class="number">173.0</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">0.6487</span>, train acc <span class="number">0.757</span>, test acc <span class="number">0.811</span>, time <span class="number">170.5</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">0.5282</span>, train acc <span class="number">0.802</span>, test acc <span class="number">0.840</span>, time <span class="number">167.3</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.4642</span>, train acc <span class="number">0.829</span>, test acc <span class="number">0.860</span>, time <span class="number">165.2</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.4230</span>, train acc <span class="number">0.844</span>, test acc <span class="number">0.863</span>, time <span class="number">165.3</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.3946</span>, train acc <span class="number">0.856</span>, test acc <span class="number">0.873</span>, time <span class="number">166.0</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.3714</span>, train acc <span class="number">0.865</span>, test acc <span class="number">0.881</span>, time <span class="number">166.1</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.3557</span>, train acc <span class="number">0.870</span>, test acc <span class="number">0.887</span>, time <span class="number">164.8</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.3408</span>, train acc <span class="number">0.876</span>, test acc <span class="number">0.892</span>, time <span class="number">165.5</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.3260</span>, train acc <span class="number">0.881</span>, test acc <span class="number">0.890</span>, time <span class="number">166.8</span> sec</span><br><span class="line">epoch <span class="number">11</span>, loss <span class="number">0.3177</span>, train acc <span class="number">0.885</span>, test acc <span class="number">0.896</span>, time <span class="number">166.8</span> sec</span><br><span class="line">epoch <span class="number">12</span>, loss <span class="number">0.3061</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.895</span>, time <span class="number">165.8</span> sec</span><br><span class="line">epoch <span class="number">13</span>, loss <span class="number">0.2969</span>, train acc <span class="number">0.891</span>, test acc <span class="number">0.896</span>, time <span class="number">166.2</span> sec</span><br><span class="line">epoch <span class="number">14</span>, loss <span class="number">0.2897</span>, train acc <span class="number">0.894</span>, test acc <span class="number">0.900</span>, time <span class="number">163.5</span> sec</span><br><span class="line">epoch <span class="number">15</span>, loss <span class="number">0.2823</span>, train acc <span class="number">0.897</span>, test acc <span class="number">0.902</span>, time <span class="number">161.8</span> sec</span><br><span class="line">epoch <span class="number">16</span>, loss <span class="number">0.2754</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.902</span>, time <span class="number">161.8</span> sec</span><br><span class="line">epoch <span class="number">17</span>, loss <span class="number">0.2689</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.908</span>, time <span class="number">161.8</span> sec</span><br><span class="line">epoch <span class="number">18</span>, loss <span class="number">0.2614</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.907</span>, time <span class="number">162.1</span> sec</span><br><span class="line">epoch <span class="number">19</span>, loss <span class="number">0.2552</span>, train acc <span class="number">0.906</span>, test acc <span class="number">0.910</span>, time <span class="number">162.3</span> sec</span><br><span class="line">epoch <span class="number">20</span>, loss <span class="number">0.2499</span>, train acc <span class="number">0.908</span>, test acc <span class="number">0.908</span>, time <span class="number">162.2</span> sec</span><br><span class="line"><span class="comment"># batch_size = 256</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">1.7151</span>, train acc <span class="number">0.362</span>, test acc <span class="number">0.679</span>, time <span class="number">95.2</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">0.8305</span>, train acc <span class="number">0.687</span>, test acc <span class="number">0.764</span>, time <span class="number">92.3</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">0.6627</span>, train acc <span class="number">0.753</span>, test acc <span class="number">0.803</span>, time <span class="number">92.4</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.5785</span>, train acc <span class="number">0.784</span>, test acc <span class="number">0.821</span>, time <span class="number">92.7</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.5272</span>, train acc <span class="number">0.803</span>, test acc <span class="number">0.831</span>, time <span class="number">92.5</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.4880</span>, train acc <span class="number">0.821</span>, test acc <span class="number">0.852</span>, time <span class="number">92.4</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.4583</span>, train acc <span class="number">0.832</span>, test acc <span class="number">0.858</span>, time <span class="number">92.5</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.4338</span>, train acc <span class="number">0.841</span>, test acc <span class="number">0.863</span>, time <span class="number">92.4</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.4149</span>, train acc <span class="number">0.848</span>, test acc <span class="number">0.871</span>, time <span class="number">92.3</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.3982</span>, train acc <span class="number">0.854</span>, test acc <span class="number">0.873</span>, time <span class="number">92.2</span> sec</span><br><span class="line">epoch <span class="number">11</span>, loss <span class="number">0.3838</span>, train acc <span class="number">0.858</span>, test acc <span class="number">0.877</span>, time <span class="number">92.2</span> sec</span><br><span class="line">epoch <span class="number">12</span>, loss <span class="number">0.3721</span>, train acc <span class="number">0.863</span>, test acc <span class="number">0.878</span>, time <span class="number">92.5</span> sec</span><br><span class="line">epoch <span class="number">13</span>, loss <span class="number">0.3598</span>, train acc <span class="number">0.869</span>, test acc <span class="number">0.882</span>, time <span class="number">92.2</span> sec</span><br><span class="line">epoch <span class="number">14</span>, loss <span class="number">0.3506</span>, train acc <span class="number">0.872</span>, test acc <span class="number">0.885</span>, time <span class="number">92.3</span> sec</span><br><span class="line">epoch <span class="number">15</span>, loss <span class="number">0.3412</span>, train acc <span class="number">0.875</span>, test acc <span class="number">0.887</span>, time <span class="number">92.7</span> sec</span><br><span class="line">epoch <span class="number">16</span>, loss <span class="number">0.3340</span>, train acc <span class="number">0.878</span>, test acc <span class="number">0.886</span>, time <span class="number">92.4</span> sec</span><br><span class="line">epoch <span class="number">17</span>, loss <span class="number">0.3278</span>, train acc <span class="number">0.881</span>, test acc <span class="number">0.892</span>, time <span class="number">92.3</span> sec</span><br><span class="line">epoch <span class="number">18</span>, loss <span class="number">0.3181</span>, train acc <span class="number">0.884</span>, test acc <span class="number">0.892</span>, time <span class="number">92.4</span> sec</span><br><span class="line">epoch <span class="number">19</span>, loss <span class="number">0.3146</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.893</span>, time <span class="number">92.4</span> sec</span><br><span class="line">epoch <span class="number">20</span>, loss <span class="number">0.3091</span>, train acc <span class="number">0.888</span>, test acc <span class="number">0.895</span>, time <span class="number">92.4</span> sec</span><br><span class="line"><span class="comment"># batch_size = 512</span></span><br><span class="line">epoch <span class="number">1</span>, loss <span class="number">2.2167</span>, train acc <span class="number">0.188</span>, test acc <span class="number">0.516</span>, time <span class="number">64.0</span> sec</span><br><span class="line">epoch <span class="number">2</span>, loss <span class="number">1.1710</span>, train acc <span class="number">0.552</span>, test acc <span class="number">0.704</span>, time <span class="number">58.7</span> sec</span><br><span class="line">epoch <span class="number">3</span>, loss <span class="number">0.8665</span>, train acc <span class="number">0.672</span>, test acc <span class="number">0.732</span>, time <span class="number">59.5</span> sec</span><br><span class="line">epoch <span class="number">4</span>, loss <span class="number">0.7495</span>, train acc <span class="number">0.717</span>, test acc <span class="number">0.769</span>, time <span class="number">59.7</span> sec</span><br><span class="line">epoch <span class="number">5</span>, loss <span class="number">0.6709</span>, train acc <span class="number">0.752</span>, test acc <span class="number">0.791</span>, time <span class="number">59.5</span> sec</span><br><span class="line">epoch <span class="number">6</span>, loss <span class="number">0.6196</span>, train acc <span class="number">0.769</span>, test acc <span class="number">0.801</span>, time <span class="number">59.6</span> sec</span><br><span class="line">epoch <span class="number">7</span>, loss <span class="number">0.5763</span>, train acc <span class="number">0.786</span>, test acc <span class="number">0.812</span>, time <span class="number">59.8</span> sec</span><br><span class="line">epoch <span class="number">8</span>, loss <span class="number">0.5459</span>, train acc <span class="number">0.797</span>, test acc <span class="number">0.819</span>, time <span class="number">59.7</span> sec</span><br><span class="line">epoch <span class="number">9</span>, loss <span class="number">0.5198</span>, train acc <span class="number">0.805</span>, test acc <span class="number">0.834</span>, time <span class="number">59.3</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.5006</span>, train acc <span class="number">0.815</span>, test acc <span class="number">0.846</span>, time <span class="number">59.5</span> sec</span><br><span class="line">epoch <span class="number">11</span>, loss <span class="number">0.4800</span>, train acc <span class="number">0.821</span>, test acc <span class="number">0.849</span>, time <span class="number">59.7</span> sec</span><br><span class="line">epoch <span class="number">12</span>, loss <span class="number">0.4649</span>, train acc <span class="number">0.829</span>, test acc <span class="number">0.852</span>, time <span class="number">59.4</span> sec</span><br><span class="line">epoch <span class="number">13</span>, loss <span class="number">0.4513</span>, train acc <span class="number">0.833</span>, test acc <span class="number">0.860</span>, time <span class="number">60.3</span> sec</span><br><span class="line">epoch <span class="number">14</span>, loss <span class="number">0.4383</span>, train acc <span class="number">0.838</span>, test acc <span class="number">0.860</span>, time <span class="number">59.7</span> sec</span><br><span class="line">epoch <span class="number">15</span>, loss <span class="number">0.4259</span>, train acc <span class="number">0.844</span>, test acc <span class="number">0.862</span>, time <span class="number">59.2</span> sec</span><br><span class="line">epoch <span class="number">16</span>, loss <span class="number">0.4174</span>, train acc <span class="number">0.846</span>, test acc <span class="number">0.869</span>, time <span class="number">59.3</span> sec</span><br><span class="line">epoch <span class="number">17</span>, loss <span class="number">0.4057</span>, train acc <span class="number">0.852</span>, test acc <span class="number">0.870</span>, time <span class="number">59.5</span> sec</span><br><span class="line">epoch <span class="number">18</span>, loss <span class="number">0.3984</span>, train acc <span class="number">0.854</span>, test acc <span class="number">0.874</span>, time <span class="number">59.7</span> sec</span><br><span class="line">epoch <span class="number">19</span>, loss <span class="number">0.3893</span>, train acc <span class="number">0.857</span>, test acc <span class="number">0.873</span>, time <span class="number">59.7</span> sec</span><br><span class="line">epoch <span class="number">20</span>, loss <span class="number">0.3844</span>, train acc <span class="number">0.860</span>, test acc <span class="number">0.875</span>, time <span class="number">59.5</span> sec</span><br><span class="line"><span class="comment"># epoch = 100</span></span><br><span class="line"><span class="comment"># batch_size = 656</span></span><br><span class="line">epoch  <span class="number">1</span>, loss <span class="number">2.2770</span>, train acc <span class="number">0.149</span>, test acc <span class="number">0.373</span>, time <span class="number">56.5</span> sec</span><br><span class="line">epoch  <span class="number">2</span>, loss <span class="number">1.5185</span>, train acc <span class="number">0.444</span>, test acc <span class="number">0.618</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch  <span class="number">3</span>, loss <span class="number">0.9619</span>, train acc <span class="number">0.632</span>, test acc <span class="number">0.712</span>, time <span class="number">51.0</span> sec</span><br><span class="line">epoch  <span class="number">4</span>, loss <span class="number">0.8345</span>, train acc <span class="number">0.684</span>, test acc <span class="number">0.741</span>, time <span class="number">51.0</span> sec</span><br><span class="line">epoch  <span class="number">5</span>, loss <span class="number">0.7410</span>, train acc <span class="number">0.722</span>, test acc <span class="number">0.770</span>, time <span class="number">51.2</span> sec</span><br><span class="line">epoch  <span class="number">6</span>, loss <span class="number">0.6810</span>, train acc <span class="number">0.747</span>, test acc <span class="number">0.780</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch  <span class="number">7</span>, loss <span class="number">0.6360</span>, train acc <span class="number">0.762</span>, test acc <span class="number">0.794</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch  <span class="number">8</span>, loss <span class="number">0.5969</span>, train acc <span class="number">0.778</span>, test acc <span class="number">0.810</span>, time <span class="number">51.2</span> sec</span><br><span class="line">epoch  <span class="number">9</span>, loss <span class="number">0.5677</span>, train acc <span class="number">0.788</span>, test acc <span class="number">0.819</span>, time <span class="number">51.3</span> sec</span><br><span class="line">epoch <span class="number">10</span>, loss <span class="number">0.5440</span>, train acc <span class="number">0.796</span>, test acc <span class="number">0.821</span>, time <span class="number">51.3</span> sec</span><br><span class="line">epoch <span class="number">11</span>, loss <span class="number">0.5219</span>, train acc <span class="number">0.806</span>, test acc <span class="number">0.833</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">12</span>, loss <span class="number">0.5035</span>, train acc <span class="number">0.814</span>, test acc <span class="number">0.836</span>, time <span class="number">51.8</span> sec</span><br><span class="line">epoch <span class="number">13</span>, loss <span class="number">0.4903</span>, train acc <span class="number">0.819</span>, test acc <span class="number">0.848</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">14</span>, loss <span class="number">0.4736</span>, train acc <span class="number">0.826</span>, test acc <span class="number">0.852</span>, time <span class="number">51.3</span> sec</span><br><span class="line">epoch <span class="number">15</span>, loss <span class="number">0.4621</span>, train acc <span class="number">0.830</span>, test acc <span class="number">0.855</span>, time <span class="number">51.2</span> sec</span><br><span class="line">epoch <span class="number">16</span>, loss <span class="number">0.4509</span>, train acc <span class="number">0.832</span>, test acc <span class="number">0.855</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">17</span>, loss <span class="number">0.4432</span>, train acc <span class="number">0.838</span>, test acc <span class="number">0.858</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">18</span>, loss <span class="number">0.4297</span>, train acc <span class="number">0.843</span>, test acc <span class="number">0.860</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">19</span>, loss <span class="number">0.4213</span>, train acc <span class="number">0.846</span>, test acc <span class="number">0.867</span>, time <span class="number">51.9</span> sec</span><br><span class="line">epoch <span class="number">20</span>, loss <span class="number">0.4171</span>, train acc <span class="number">0.847</span>, test acc <span class="number">0.869</span>, time <span class="number">51.8</span> sec</span><br><span class="line">epoch <span class="number">21</span>, loss <span class="number">0.4068</span>, train acc <span class="number">0.851</span>, test acc <span class="number">0.868</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">22</span>, loss <span class="number">0.3996</span>, train acc <span class="number">0.855</span>, test acc <span class="number">0.874</span>, time <span class="number">51.5</span> sec</span><br><span class="line">epoch <span class="number">23</span>, loss <span class="number">0.3922</span>, train acc <span class="number">0.858</span>, test acc <span class="number">0.872</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">24</span>, loss <span class="number">0.3855</span>, train acc <span class="number">0.860</span>, test acc <span class="number">0.877</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">25</span>, loss <span class="number">0.3808</span>, train acc <span class="number">0.861</span>, test acc <span class="number">0.877</span>, time <span class="number">51.3</span> sec</span><br><span class="line">epoch <span class="number">26</span>, loss <span class="number">0.3771</span>, train acc <span class="number">0.862</span>, test acc <span class="number">0.881</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">27</span>, loss <span class="number">0.3714</span>, train acc <span class="number">0.866</span>, test acc <span class="number">0.880</span>, time <span class="number">51.9</span> sec</span><br><span class="line">epoch <span class="number">28</span>, loss <span class="number">0.3651</span>, train acc <span class="number">0.867</span>, test acc <span class="number">0.879</span>, time <span class="number">51.2</span> sec</span><br><span class="line">epoch <span class="number">29</span>, loss <span class="number">0.3590</span>, train acc <span class="number">0.869</span>, test acc <span class="number">0.883</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">30</span>, loss <span class="number">0.3544</span>, train acc <span class="number">0.872</span>, test acc <span class="number">0.882</span>, time <span class="number">51.5</span> sec</span><br><span class="line">epoch <span class="number">31</span>, loss <span class="number">0.3512</span>, train acc <span class="number">0.872</span>, test acc <span class="number">0.886</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">32</span>, loss <span class="number">0.3456</span>, train acc <span class="number">0.874</span>, test acc <span class="number">0.888</span>, time <span class="number">51.8</span> sec</span><br><span class="line">epoch <span class="number">33</span>, loss <span class="number">0.3411</span>, train acc <span class="number">0.875</span>, test acc <span class="number">0.889</span>, time <span class="number">52.0</span> sec</span><br><span class="line">epoch <span class="number">34</span>, loss <span class="number">0.3402</span>, train acc <span class="number">0.876</span>, test acc <span class="number">0.883</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">35</span>, loss <span class="number">0.3354</span>, train acc <span class="number">0.878</span>, test acc <span class="number">0.890</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">36</span>, loss <span class="number">0.3315</span>, train acc <span class="number">0.879</span>, test acc <span class="number">0.889</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">37</span>, loss <span class="number">0.3284</span>, train acc <span class="number">0.880</span>, test acc <span class="number">0.892</span>, time <span class="number">51.5</span> sec</span><br><span class="line">epoch <span class="number">38</span>, loss <span class="number">0.3253</span>, train acc <span class="number">0.881</span>, test acc <span class="number">0.892</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">39</span>, loss <span class="number">0.3213</span>, train acc <span class="number">0.883</span>, test acc <span class="number">0.892</span>, time <span class="number">51.5</span> sec</span><br><span class="line">epoch <span class="number">40</span>, loss <span class="number">0.3172</span>, train acc <span class="number">0.885</span>, test acc <span class="number">0.892</span>, time <span class="number">51.5</span> sec</span><br><span class="line">epoch <span class="number">41</span>, loss <span class="number">0.3156</span>, train acc <span class="number">0.884</span>, test acc <span class="number">0.892</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">42</span>, loss <span class="number">0.3107</span>, train acc <span class="number">0.886</span>, test acc <span class="number">0.895</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">43</span>, loss <span class="number">0.3069</span>, train acc <span class="number">0.889</span>, test acc <span class="number">0.898</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">44</span>, loss <span class="number">0.3081</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.894</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">45</span>, loss <span class="number">0.3044</span>, train acc <span class="number">0.889</span>, test acc <span class="number">0.896</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">46</span>, loss <span class="number">0.2996</span>, train acc <span class="number">0.890</span>, test acc <span class="number">0.899</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">47</span>, loss <span class="number">0.2984</span>, train acc <span class="number">0.891</span>, test acc <span class="number">0.894</span>, time <span class="number">51.8</span> sec</span><br><span class="line">epoch <span class="number">48</span>, loss <span class="number">0.2971</span>, train acc <span class="number">0.892</span>, test acc <span class="number">0.899</span>, time <span class="number">51.5</span> sec</span><br><span class="line">epoch <span class="number">49</span>, loss <span class="number">0.2942</span>, train acc <span class="number">0.892</span>, test acc <span class="number">0.899</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">50</span>, loss <span class="number">0.2909</span>, train acc <span class="number">0.894</span>, test acc <span class="number">0.902</span>, time <span class="number">52.0</span> sec</span><br><span class="line">epoch <span class="number">51</span>, loss <span class="number">0.2883</span>, train acc <span class="number">0.894</span>, test acc <span class="number">0.900</span>, time <span class="number">51.8</span> sec</span><br><span class="line">epoch <span class="number">52</span>, loss <span class="number">0.2862</span>, train acc <span class="number">0.895</span>, test acc <span class="number">0.899</span>, time <span class="number">52.0</span> sec</span><br><span class="line">epoch <span class="number">53</span>, loss <span class="number">0.2852</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.899</span>, time <span class="number">51.5</span> sec</span><br><span class="line">epoch <span class="number">54</span>, loss <span class="number">0.2825</span>, train acc <span class="number">0.897</span>, test acc <span class="number">0.903</span>, time <span class="number">52.5</span> sec</span><br><span class="line">epoch <span class="number">55</span>, loss <span class="number">0.2811</span>, train acc <span class="number">0.897</span>, test acc <span class="number">0.903</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">56</span>, loss <span class="number">0.2787</span>, train acc <span class="number">0.897</span>, test acc <span class="number">0.903</span>, time <span class="number">52.1</span> sec</span><br><span class="line">epoch <span class="number">57</span>, loss <span class="number">0.2760</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.903</span>, time <span class="number">52.1</span> sec</span><br><span class="line">epoch <span class="number">58</span>, loss <span class="number">0.2735</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.903</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">59</span>, loss <span class="number">0.2705</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.904</span>, time <span class="number">51.9</span> sec</span><br><span class="line">epoch <span class="number">60</span>, loss <span class="number">0.2714</span>, train acc <span class="number">0.900</span>, test acc <span class="number">0.902</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">61</span>, loss <span class="number">0.2701</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.906</span>, time <span class="number">51.9</span> sec</span><br><span class="line">epoch <span class="number">62</span>, loss <span class="number">0.2658</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.901</span>, time <span class="number">51.9</span> sec</span><br><span class="line">epoch <span class="number">63</span>, loss <span class="number">0.2628</span>, train acc <span class="number">0.903</span>, test acc <span class="number">0.905</span>, time <span class="number">52.0</span> sec</span><br><span class="line">epoch <span class="number">64</span>, loss <span class="number">0.2610</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.906</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">65</span>, loss <span class="number">0.2625</span>, train acc <span class="number">0.903</span>, test acc <span class="number">0.906</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">66</span>, loss <span class="number">0.2574</span>, train acc <span class="number">0.906</span>, test acc <span class="number">0.905</span>, time <span class="number">51.0</span> sec</span><br><span class="line">epoch <span class="number">67</span>, loss <span class="number">0.2568</span>, train acc <span class="number">0.906</span>, test acc <span class="number">0.908</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">68</span>, loss <span class="number">0.2565</span>, train acc <span class="number">0.905</span>, test acc <span class="number">0.905</span>, time <span class="number">51.2</span> sec</span><br><span class="line">epoch <span class="number">69</span>, loss <span class="number">0.2528</span>, train acc <span class="number">0.907</span>, test acc <span class="number">0.909</span>, time <span class="number">51.3</span> sec</span><br><span class="line">epoch <span class="number">70</span>, loss <span class="number">0.2516</span>, train acc <span class="number">0.908</span>, test acc <span class="number">0.906</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">71</span>, loss <span class="number">0.2505</span>, train acc <span class="number">0.909</span>, test acc <span class="number">0.909</span>, time <span class="number">52.1</span> sec</span><br><span class="line">epoch <span class="number">72</span>, loss <span class="number">0.2474</span>, train acc <span class="number">0.909</span>, test acc <span class="number">0.909</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">73</span>, loss <span class="number">0.2454</span>, train acc <span class="number">0.909</span>, test acc <span class="number">0.909</span>, time <span class="number">51.3</span> sec</span><br><span class="line">epoch <span class="number">74</span>, loss <span class="number">0.2459</span>, train acc <span class="number">0.909</span>, test acc <span class="number">0.910</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">75</span>, loss <span class="number">0.2425</span>, train acc <span class="number">0.910</span>, test acc <span class="number">0.909</span>, time <span class="number">52.0</span> sec</span><br><span class="line">epoch <span class="number">76</span>, loss <span class="number">0.2401</span>, train acc <span class="number">0.911</span>, test acc <span class="number">0.906</span>, time <span class="number">51.8</span> sec</span><br><span class="line">epoch <span class="number">77</span>, loss <span class="number">0.2393</span>, train acc <span class="number">0.912</span>, test acc <span class="number">0.911</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">78</span>, loss <span class="number">0.2365</span>, train acc <span class="number">0.913</span>, test acc <span class="number">0.911</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">79</span>, loss <span class="number">0.2363</span>, train acc <span class="number">0.913</span>, test acc <span class="number">0.910</span>, time <span class="number">51.9</span> sec</span><br><span class="line">epoch <span class="number">80</span>, loss <span class="number">0.2341</span>, train acc <span class="number">0.914</span>, test acc <span class="number">0.911</span>, time <span class="number">51.2</span> sec</span><br><span class="line">epoch <span class="number">81</span>, loss <span class="number">0.2322</span>, train acc <span class="number">0.914</span>, test acc <span class="number">0.910</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">82</span>, loss <span class="number">0.2304</span>, train acc <span class="number">0.915</span>, test acc <span class="number">0.913</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">83</span>, loss <span class="number">0.2297</span>, train acc <span class="number">0.915</span>, test acc <span class="number">0.911</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">84</span>, loss <span class="number">0.2270</span>, train acc <span class="number">0.916</span>, test acc <span class="number">0.912</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">85</span>, loss <span class="number">0.2252</span>, train acc <span class="number">0.916</span>, test acc <span class="number">0.912</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">86</span>, loss <span class="number">0.2280</span>, train acc <span class="number">0.915</span>, test acc <span class="number">0.913</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">87</span>, loss <span class="number">0.2238</span>, train acc <span class="number">0.916</span>, test acc <span class="number">0.915</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">88</span>, loss <span class="number">0.2219</span>, train acc <span class="number">0.917</span>, test acc <span class="number">0.915</span>, time <span class="number">51.9</span> sec</span><br><span class="line">epoch <span class="number">89</span>, loss <span class="number">0.2203</span>, train acc <span class="number">0.919</span>, test acc <span class="number">0.915</span>, time <span class="number">51.5</span> sec</span><br><span class="line">epoch <span class="number">90</span>, loss <span class="number">0.2178</span>, train acc <span class="number">0.920</span>, test acc <span class="number">0.912</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">91</span>, loss <span class="number">0.2184</span>, train acc <span class="number">0.919</span>, test acc <span class="number">0.915</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">92</span>, loss <span class="number">0.2155</span>, train acc <span class="number">0.920</span>, test acc <span class="number">0.915</span>, time <span class="number">51.8</span> sec</span><br><span class="line">epoch <span class="number">93</span>, loss <span class="number">0.2128</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.914</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">94</span>, loss <span class="number">0.2136</span>, train acc <span class="number">0.920</span>, test acc <span class="number">0.917</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">95</span>, loss <span class="number">0.2112</span>, train acc <span class="number">0.921</span>, test acc <span class="number">0.916</span>, time <span class="number">51.6</span> sec</span><br><span class="line">epoch <span class="number">96</span>, loss <span class="number">0.2119</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.914</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">97</span>, loss <span class="number">0.2094</span>, train acc <span class="number">0.923</span>, test acc <span class="number">0.914</span>, time <span class="number">51.7</span> sec</span><br><span class="line">epoch <span class="number">98</span>, loss <span class="number">0.2057</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.915</span>, time <span class="number">51.4</span> sec</span><br><span class="line">epoch <span class="number">99</span>, loss <span class="number">0.2026</span>, train acc <span class="number">0.925</span>, test acc <span class="number">0.917</span>, time <span class="number">51.2</span> sec</span><br><span class="line">epoch <span class="number">100</span>, loss <span class="number">0.2039</span>, train acc <span class="number">0.923</span>, test acc <span class="number">0.917</span>, time <span class="number">51.5</span> sec</span><br></pre></td></tr></tbody></table></figure>
<h2 id="使用重复元素的网络（VGG）"><a href="#使用重复元素的网络（VGG）" class="headerlink" title="使用重复元素的网络（VGG）"></a>使用重复元素的网络（VGG）</h2><table>
<thead>
<tr>
<th align="center">名称</th>
<th align="left">结构</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">VGG块</td>
<td align="left">①连续数个卷积层：channels=num_channels, padding=1，kernel_size=3<br>②最大池化层：strides=2, pool_size=2</td>
<td align="left">卷积层保持输入的高和宽不变<br>池化层对其减半</td>
</tr>
<tr>
<td align="center">VGG网络</td>
<td align="left">①VGG块：单卷积层（通道64）<br>②VGG块：单卷积层（通道128）<br>③VGG块：双卷积层（通道256）<br>④VGG块：双卷积层（通道256）<br>⑤VGG块：双卷积层（通道512）<br>⑥全输出层：通道4096，激活函数ReLU<br>⑦丢弃层：丢弃概率0.5<br>⑧全输出层：通道4096，激活函数ReLU<br>⑨丢弃层：丢弃概率0.5<br>⑩全输出层：通道10</td>
<td align="left">卷积层+全输出层</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> gluon, init, autograd, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> data <span class="keyword">as</span> gdata, loss <span class="keyword">as</span> gloss, nn</span><br><span class="line"><span class="keyword">import</span> sys, os, time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># VGG块</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg_block</span><span class="params">(num_convs, num_channels)</span>:</span></span><br><span class="line">    blk = nn.Sequential()</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_convs):</span><br><span class="line">        blk.add(nn.Conv2D(channels=num_channels,</span><br><span class="line">                          kernel_size=<span class="number">3</span>,</span><br><span class="line">                          padding=<span class="number">1</span>,</span><br><span class="line">                          activation=<span class="string">'relu'</span>))</span><br><span class="line">    blk.add(nn.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> blk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># VGG模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg</span><span class="params">(conv_arch)</span>:</span></span><br><span class="line">    net = nn.Sequential()</span><br><span class="line">    <span class="comment"># 卷积层部分</span></span><br><span class="line">    <span class="keyword">for</span> (num_convs, num_channels) <span class="keyword">in</span> conv_arch:</span><br><span class="line">        net.add(vgg_block(num_convs, num_channels))</span><br><span class="line">    <span class="comment"># 全连接层部分</span></span><br><span class="line">    net.add(nn.Dense(<span class="number">4096</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Dense(<span class="number">4096</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Dense(<span class="number">10</span>))</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span><span class="params">(batch_size, resize=None, root=os.path.join<span class="params">(<span class="string">'-'</span>, <span class="string">'mxnet'</span>, <span class="string">'datasets'</span>, <span class="string">'fashion-mnist'</span>)</span>)</span>:</span></span><br><span class="line">    root = os.path.expanduser(root)  <span class="comment"># 展开用户路径</span></span><br><span class="line">    transformer = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        transformer += [gdata.vision.transforms.Resize(resize)]</span><br><span class="line">    transformer += [gdata.vision.transforms.ToTensor()]</span><br><span class="line">    transformer = gdata.vision.transforms.Compose(transformer)</span><br><span class="line"></span><br><span class="line">    mnist_train = gdata.vision.FashionMNIST(root=root, train=<span class="literal">True</span>)</span><br><span class="line">    mnist_test = gdata.vision.FashionMNIST(root=root, train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    num_workers = <span class="number">0</span> <span class="keyword">if</span> sys.platform.startswith(<span class="string">'win'</span>) <span class="keyword">else</span> <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),</span><br><span class="line">                                  batch_size=batch_size,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  num_workers=num_workers)</span><br><span class="line">    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),</span><br><span class="line">                                 batch_size=batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=num_workers)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ctx = mx.gpu()</span><br><span class="line">        _ = nd.array((<span class="number">1</span>,), ctx=ctx)</span><br><span class="line">    <span class="keyword">except</span> mx.base.MXNetError:</span><br><span class="line">        ctx = mx.cpu()</span><br><span class="line">    <span class="keyword">return</span> ctx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(data_iter, net, ctx)</span>:</span></span><br><span class="line">    acc_sum, n = nd.array([<span class="number">0</span>], ctx=ctx), <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype(<span class="string">'float32'</span>)</span><br><span class="line">        acc_sum += (net(X).argmax(axis=<span class="number">1</span>) == y).sum()</span><br><span class="line">        n += y.size</span><br><span class="line">    <span class="keyword">return</span> acc_sum.asscalar() / n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span>:</span></span><br><span class="line">    print(<span class="string">'training on'</span>, ctx)</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X, y = X.as_in_context(ctx), y.as_in_context(ctx)</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            trainer.step(batch_size)</span><br><span class="line">            y = y.astype(<span class="string">'float32'</span>)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(test_iter, net, ctx)</span><br><span class="line">        print(<span class="string">'epoch %3d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># VGG超参数</span></span><br><span class="line">conv_arch = ((<span class="number">1</span>, <span class="number">64</span>), (<span class="number">1</span>, <span class="number">128</span>), (<span class="number">2</span>, <span class="number">256</span>), (<span class="number">2</span>, <span class="number">512</span>), (<span class="number">2</span>, <span class="number">512</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型</span></span><br><span class="line">net = vgg(conv_arch)</span><br><span class="line">net.initialize()</span><br><span class="line">X = nd.random.uniform(shape=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"><span class="keyword">for</span> blk <span class="keyword">in</span> net:</span><br><span class="line">    X = blk(X)</span><br><span class="line">    print(blk.name, <span class="string">"output shape:\t"</span>, X.shape)</span><br><span class="line"></span><br><span class="line">ratio = <span class="number">4</span></span><br><span class="line">small_conv_arch = [(pair[<span class="number">0</span>], pair[<span class="number">1</span>] // ratio) <span class="keyword">for</span> pair <span class="keyword">in</span> conv_arch]</span><br><span class="line">lr, num_epochs, batch_size, ctx = <span class="number">0.05</span>, <span class="number">5</span>, <span class="number">128</span>, try_gpu()</span><br><span class="line">net = vgg(small_conv_arch)</span><br><span class="line">net.initialize(ctx=ctx, init=init.Xavier())</span><br><span class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">'sgd'</span>, {<span class="string">'learning_rate'</span>: lr})</span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">224</span>)</span><br><span class="line">train(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各层输出形状：</span></span><br><span class="line">sequential1 output shape:	 (<span class="number">1</span>, <span class="number">64</span>, <span class="number">112</span>, <span class="number">112</span>)</span><br><span class="line">sequential2 output shape:	 (<span class="number">1</span>, <span class="number">128</span>, <span class="number">56</span>, <span class="number">56</span>)</span><br><span class="line">sequential3 output shape:	 (<span class="number">1</span>, <span class="number">256</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">sequential4 output shape:	 (<span class="number">1</span>, <span class="number">512</span>, <span class="number">14</span>, <span class="number">14</span>)</span><br><span class="line">sequential5 output shape:	 (<span class="number">1</span>, <span class="number">512</span>, <span class="number">7</span>, <span class="number">7</span>)</span><br><span class="line">dense0 output shape:	 (<span class="number">1</span>, <span class="number">4096</span>)</span><br><span class="line">dropout0 output shape:	 (<span class="number">1</span>, <span class="number">4096</span>)</span><br><span class="line">dense1 output shape:	 (<span class="number">1</span>, <span class="number">4096</span>)</span><br><span class="line">dropout1 output shape:	 (<span class="number">1</span>, <span class="number">4096</span>)</span><br><span class="line">dense2 output shape:	 (<span class="number">1</span>, <span class="number">10</span>)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># resize = 224</span></span><br><span class="line">training on gpu(<span class="number">3</span>):</span><br><span class="line">epoch   <span class="number">1</span>, loss <span class="number">1.2946</span>, train acc <span class="number">0.539</span>, test acc <span class="number">0.807</span>, time <span class="number">90.9</span> sec</span><br><span class="line">epoch   <span class="number">2</span>, loss <span class="number">0.5078</span>, train acc <span class="number">0.811</span>, test acc <span class="number">0.864</span>, time <span class="number">89.9</span> sec</span><br><span class="line">epoch   <span class="number">3</span>, loss <span class="number">0.4057</span>, train acc <span class="number">0.851</span>, test acc <span class="number">0.880</span>, time <span class="number">90.4</span> sec</span><br><span class="line">epoch   <span class="number">4</span>, loss <span class="number">0.3542</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.891</span>, time <span class="number">90.7</span> sec</span><br><span class="line">epoch   <span class="number">5</span>, loss <span class="number">0.3230</span>, train acc <span class="number">0.883</span>, test acc <span class="number">0.897</span>, time <span class="number">91.1</span> sec</span><br><span class="line">epoch   <span class="number">6</span>, loss <span class="number">0.2969</span>, train acc <span class="number">0.891</span>, test acc <span class="number">0.907</span>, time <span class="number">90.3</span> sec</span><br><span class="line">epoch   <span class="number">7</span>, loss <span class="number">0.2727</span>, train acc <span class="number">0.900</span>, test acc <span class="number">0.905</span>, time <span class="number">91.3</span> sec</span><br><span class="line">epoch   <span class="number">8</span>, loss <span class="number">0.2591</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.910</span>, time <span class="number">90.9</span> sec</span><br><span class="line">epoch   <span class="number">9</span>, loss <span class="number">0.2417</span>, train acc <span class="number">0.911</span>, test acc <span class="number">0.915</span>, time <span class="number">90.5</span> sec</span><br><span class="line">epoch  <span class="number">10</span>, loss <span class="number">0.2295</span>, train acc <span class="number">0.916</span>, test acc <span class="number">0.917</span>, time <span class="number">90.7</span> sec</span><br><span class="line">epoch  <span class="number">11</span>, loss <span class="number">0.2159</span>, train acc <span class="number">0.920</span>, test acc <span class="number">0.920</span>, time <span class="number">91.2</span> sec</span><br><span class="line">epoch  <span class="number">12</span>, loss <span class="number">0.2051</span>, train acc <span class="number">0.925</span>, test acc <span class="number">0.919</span>, time <span class="number">91.0</span> sec</span><br><span class="line">epoch  <span class="number">13</span>, loss <span class="number">0.1918</span>, train acc <span class="number">0.929</span>, test acc <span class="number">0.925</span>, time <span class="number">91.4</span> sec</span><br><span class="line">epoch  <span class="number">14</span>, loss <span class="number">0.1814</span>, train acc <span class="number">0.933</span>, test acc <span class="number">0.924</span>, time <span class="number">90.3</span> sec</span><br><span class="line">epoch  <span class="number">15</span>, loss <span class="number">0.1695</span>, train acc <span class="number">0.937</span>, test acc <span class="number">0.929</span>, time <span class="number">91.0</span> sec</span><br><span class="line">epoch  <span class="number">16</span>, loss <span class="number">0.1625</span>, train acc <span class="number">0.941</span>, test acc <span class="number">0.931</span>, time <span class="number">91.1</span> sec</span><br><span class="line">epoch  <span class="number">17</span>, loss <span class="number">0.1535</span>, train acc <span class="number">0.944</span>, test acc <span class="number">0.928</span>, time <span class="number">91.4</span> sec</span><br><span class="line">epoch  <span class="number">18</span>, loss <span class="number">0.1418</span>, train acc <span class="number">0.948</span>, test acc <span class="number">0.928</span>, time <span class="number">91.0</span> sec</span><br><span class="line">epoch  <span class="number">19</span>, loss <span class="number">0.1328</span>, train acc <span class="number">0.950</span>, test acc <span class="number">0.931</span>, time <span class="number">90.6</span> sec</span><br><span class="line">epoch  <span class="number">20</span>, loss <span class="number">0.1222</span>, train acc <span class="number">0.955</span>, test acc <span class="number">0.929</span>, time <span class="number">89.9</span> sec</span><br><span class="line">epoch  <span class="number">21</span>, loss <span class="number">0.1165</span>, train acc <span class="number">0.957</span>, test acc <span class="number">0.932</span>, time <span class="number">89.7</span> sec</span><br><span class="line">epoch  <span class="number">22</span>, loss <span class="number">0.1051</span>, train acc <span class="number">0.960</span>, test acc <span class="number">0.931</span>, time <span class="number">89.5</span> sec</span><br><span class="line">epoch  <span class="number">23</span>, loss <span class="number">0.0990</span>, train acc <span class="number">0.963</span>, test acc <span class="number">0.935</span>, time <span class="number">89.1</span> sec</span><br><span class="line">epoch  <span class="number">24</span>, loss <span class="number">0.0904</span>, train acc <span class="number">0.967</span>, test acc <span class="number">0.935</span>, time <span class="number">89.3</span> sec</span><br><span class="line">epoch  <span class="number">25</span>, loss <span class="number">0.0836</span>, train acc <span class="number">0.969</span>, test acc <span class="number">0.933</span>, time <span class="number">89.2</span> sec</span><br><span class="line">epoch  <span class="number">26</span>, loss <span class="number">0.0796</span>, train acc <span class="number">0.971</span>, test acc <span class="number">0.932</span>, time <span class="number">89.5</span> sec</span><br><span class="line">epoch  <span class="number">27</span>, loss <span class="number">0.0721</span>, train acc <span class="number">0.973</span>, test acc <span class="number">0.932</span>, time <span class="number">89.2</span> sec</span><br><span class="line">epoch  <span class="number">28</span>, loss <span class="number">0.0663</span>, train acc <span class="number">0.975</span>, test acc <span class="number">0.932</span>, time <span class="number">88.9</span> sec</span><br><span class="line">epoch  <span class="number">29</span>, loss <span class="number">0.0602</span>, train acc <span class="number">0.978</span>, test acc <span class="number">0.930</span>, time <span class="number">89.1</span> sec</span><br><span class="line">epoch  <span class="number">30</span>, loss <span class="number">0.0541</span>, train acc <span class="number">0.980</span>, test acc <span class="number">0.933</span>, time <span class="number">89.4</span> sec</span><br><span class="line">epoch  <span class="number">31</span>, loss <span class="number">0.0514</span>, train acc <span class="number">0.981</span>, test acc <span class="number">0.930</span>, time <span class="number">89.1</span> sec</span><br><span class="line">epoch  <span class="number">32</span>, loss <span class="number">0.0472</span>, train acc <span class="number">0.982</span>, test acc <span class="number">0.932</span>, time <span class="number">89.1</span> sec</span><br><span class="line">epoch  <span class="number">33</span>, loss <span class="number">0.0425</span>, train acc <span class="number">0.984</span>, test acc <span class="number">0.935</span>, time <span class="number">88.8</span> sec</span><br><span class="line">epoch  <span class="number">34</span>, loss <span class="number">0.0394</span>, train acc <span class="number">0.985</span>, test acc <span class="number">0.930</span>, time <span class="number">88.8</span> sec</span><br><span class="line">epoch  <span class="number">35</span>, loss <span class="number">0.0374</span>, train acc <span class="number">0.986</span>, test acc <span class="number">0.931</span>, time <span class="number">89.2</span> sec</span><br><span class="line">epoch  <span class="number">36</span>, loss <span class="number">0.0330</span>, train acc <span class="number">0.988</span>, test acc <span class="number">0.933</span>, time <span class="number">89.3</span> sec</span><br><span class="line">epoch  <span class="number">37</span>, loss <span class="number">0.0334</span>, train acc <span class="number">0.988</span>, test acc <span class="number">0.934</span>, time <span class="number">89.3</span> sec</span><br><span class="line">epoch  <span class="number">38</span>, loss <span class="number">0.0313</span>, train acc <span class="number">0.989</span>, test acc <span class="number">0.935</span>, time <span class="number">89.8</span> sec</span><br><span class="line">epoch  <span class="number">39</span>, loss <span class="number">0.0263</span>, train acc <span class="number">0.991</span>, test acc <span class="number">0.936</span>, time <span class="number">88.7</span> sec</span><br><span class="line">epoch  <span class="number">40</span>, loss <span class="number">0.0257</span>, train acc <span class="number">0.991</span>, test acc <span class="number">0.933</span>, time <span class="number">88.5</span> sec</span><br><span class="line">epoch  <span class="number">41</span>, loss <span class="number">0.0259</span>, train acc <span class="number">0.990</span>, test acc <span class="number">0.934</span>, time <span class="number">88.9</span> sec</span><br><span class="line">epoch  <span class="number">42</span>, loss <span class="number">0.0216</span>, train acc <span class="number">0.992</span>, test acc <span class="number">0.934</span>, time <span class="number">88.8</span> sec</span><br><span class="line">epoch  <span class="number">43</span>, loss <span class="number">0.0216</span>, train acc <span class="number">0.993</span>, test acc <span class="number">0.935</span>, time <span class="number">89.2</span> sec</span><br><span class="line">epoch  <span class="number">44</span>, loss <span class="number">0.0208</span>, train acc <span class="number">0.992</span>, test acc <span class="number">0.938</span>, time <span class="number">89.0</span> sec</span><br><span class="line">epoch  <span class="number">45</span>, loss <span class="number">0.0196</span>, train acc <span class="number">0.993</span>, test acc <span class="number">0.935</span>, time <span class="number">89.1</span> sec</span><br><span class="line">epoch  <span class="number">46</span>, loss <span class="number">0.0164</span>, train acc <span class="number">0.994</span>, test acc <span class="number">0.939</span>, time <span class="number">88.1</span> sec</span><br><span class="line">epoch  <span class="number">47</span>, loss <span class="number">0.0153</span>, train acc <span class="number">0.995</span>, test acc <span class="number">0.936</span>, time <span class="number">88.3</span> sec</span><br><span class="line">epoch  <span class="number">48</span>, loss <span class="number">0.0163</span>, train acc <span class="number">0.994</span>, test acc <span class="number">0.936</span>, time <span class="number">88.5</span> sec</span><br><span class="line">epoch  <span class="number">49</span>, loss <span class="number">0.0150</span>, train acc <span class="number">0.995</span>, test acc <span class="number">0.934</span>, time <span class="number">89.3</span> sec</span><br><span class="line">epoch  <span class="number">50</span>, loss <span class="number">0.0147</span>, train acc <span class="number">0.995</span>, test acc <span class="number">0.938</span>, time <span class="number">89.6</span> sec</span><br><span class="line">epoch  <span class="number">51</span>, loss <span class="number">0.0172</span>, train acc <span class="number">0.994</span>, test acc <span class="number">0.935</span>, time <span class="number">89.5</span> sec</span><br><span class="line">epoch  <span class="number">52</span>, loss <span class="number">0.0134</span>, train acc <span class="number">0.995</span>, test acc <span class="number">0.935</span>, time <span class="number">89.1</span> sec</span><br><span class="line">epoch  <span class="number">53</span>, loss <span class="number">0.0127</span>, train acc <span class="number">0.995</span>, test acc <span class="number">0.937</span>, time <span class="number">89.4</span> sec</span><br><span class="line">epoch  <span class="number">54</span>, loss <span class="number">0.0124</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.934</span>, time <span class="number">89.6</span> sec</span><br><span class="line">epoch  <span class="number">55</span>, loss <span class="number">0.0093</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.935</span>, time <span class="number">89.8</span> sec</span><br><span class="line">epoch  <span class="number">56</span>, loss <span class="number">0.0117</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.933</span>, time <span class="number">89.4</span> sec</span><br><span class="line">epoch  <span class="number">57</span>, loss <span class="number">0.0112</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.938</span>, time <span class="number">89.7</span> sec</span><br><span class="line">epoch  <span class="number">58</span>, loss <span class="number">0.0102</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.934</span>, time <span class="number">89.5</span> sec</span><br><span class="line">epoch  <span class="number">59</span>, loss <span class="number">0.0104</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.936</span>, time <span class="number">89.4</span> sec</span><br><span class="line">epoch  <span class="number">60</span>, loss <span class="number">0.0100</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.935</span>, time <span class="number">89.2</span> sec</span><br><span class="line">epoch  <span class="number">61</span>, loss <span class="number">0.0087</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.936</span>, time <span class="number">89.8</span> sec</span><br><span class="line">epoch  <span class="number">62</span>, loss <span class="number">0.0081</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.937</span>, time <span class="number">90.6</span> sec</span><br><span class="line">epoch  <span class="number">63</span>, loss <span class="number">0.0086</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.935</span>, time <span class="number">90.0</span> sec</span><br><span class="line">epoch  <span class="number">64</span>, loss <span class="number">0.0080</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.935</span>, time <span class="number">90.1</span> sec</span><br><span class="line">epoch  <span class="number">65</span>, loss <span class="number">0.0076</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.936</span>, time <span class="number">89.6</span> sec</span><br><span class="line">epoch  <span class="number">66</span>, loss <span class="number">0.0084</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.937</span>, time <span class="number">90.1</span> sec</span><br><span class="line">epoch  <span class="number">67</span>, loss <span class="number">0.0075</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.934</span>, time <span class="number">90.3</span> sec</span><br><span class="line">epoch  <span class="number">68</span>, loss <span class="number">0.0083</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.935</span>, time <span class="number">89.8</span> sec</span><br><span class="line">epoch  <span class="number">69</span>, loss <span class="number">0.0086</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.931</span>, time <span class="number">89.8</span> sec</span><br><span class="line">epoch  <span class="number">70</span>, loss <span class="number">0.0077</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.935</span>, time <span class="number">89.4</span> sec</span><br><span class="line">epoch  <span class="number">71</span>, loss <span class="number">0.0069</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.937</span>, time <span class="number">89.6</span> sec</span><br><span class="line">epoch  <span class="number">72</span>, loss <span class="number">0.0065</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.935</span>, time <span class="number">89.9</span> sec</span><br><span class="line">epoch  <span class="number">73</span>, loss <span class="number">0.0064</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.938</span>, time <span class="number">89.6</span> sec</span><br><span class="line">epoch  <span class="number">74</span>, loss <span class="number">0.0054</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.937</span>, time <span class="number">89.6</span> sec</span><br><span class="line">epoch  <span class="number">75</span>, loss <span class="number">0.0068</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.936</span>, time <span class="number">89.9</span> sec</span><br><span class="line">epoch  <span class="number">76</span>, loss <span class="number">0.0067</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.935</span>, time <span class="number">89.6</span> sec</span><br><span class="line">epoch  <span class="number">77</span>, loss <span class="number">0.0053</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.933</span>, time <span class="number">89.3</span> sec</span><br><span class="line">epoch  <span class="number">78</span>, loss <span class="number">0.0060</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.937</span>, time <span class="number">89.8</span> sec</span><br><span class="line">epoch  <span class="number">79</span>, loss <span class="number">0.0062</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.936</span>, time <span class="number">89.1</span> sec</span><br><span class="line">epoch  <span class="number">80</span>, loss <span class="number">0.0064</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.935</span>, time <span class="number">87.5</span> sec</span><br><span class="line">epoch  <span class="number">81</span>, loss <span class="number">0.0056</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.937</span>, time <span class="number">87.3</span> sec</span><br><span class="line">epoch  <span class="number">82</span>, loss <span class="number">0.0053</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.936</span>, time <span class="number">87.4</span> sec</span><br><span class="line">epoch  <span class="number">83</span>, loss <span class="number">0.0060</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.936</span>, time <span class="number">87.5</span> sec</span><br><span class="line">epoch  <span class="number">84</span>, loss <span class="number">0.0056</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.936</span>, time <span class="number">87.4</span> sec</span><br><span class="line">epoch  <span class="number">85</span>, loss <span class="number">0.0045</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.937</span>, time <span class="number">87.3</span> sec</span><br><span class="line">epoch  <span class="number">86</span>, loss <span class="number">0.0038</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.934</span>, time <span class="number">87.8</span> sec</span><br><span class="line">epoch  <span class="number">87</span>, loss <span class="number">0.0047</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.937</span>, time <span class="number">88.0</span> sec</span><br><span class="line">epoch  <span class="number">88</span>, loss <span class="number">0.0040</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.935</span>, time <span class="number">87.7</span> sec</span><br><span class="line">epoch  <span class="number">89</span>, loss <span class="number">0.0048</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.936</span>, time <span class="number">88.0</span> sec</span><br><span class="line">epoch  <span class="number">90</span>, loss <span class="number">0.0040</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.936</span>, time <span class="number">87.8</span> sec</span><br><span class="line">epoch  <span class="number">91</span>, loss <span class="number">0.0040</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.934</span>, time <span class="number">87.4</span> sec</span><br><span class="line">epoch  <span class="number">92</span>, loss <span class="number">0.0039</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.934</span>, time <span class="number">87.1</span> sec</span><br><span class="line">epoch  <span class="number">93</span>, loss <span class="number">0.0042</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.936</span>, time <span class="number">87.3</span> sec</span><br><span class="line">epoch  <span class="number">94</span>, loss <span class="number">0.0046</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.938</span>, time <span class="number">87.8</span> sec</span><br><span class="line">epoch  <span class="number">95</span>, loss <span class="number">0.0029</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.936</span>, time <span class="number">87.7</span> sec</span><br><span class="line">epoch  <span class="number">96</span>, loss <span class="number">0.0027</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.936</span>, time <span class="number">87.8</span> sec</span><br><span class="line">epoch  <span class="number">97</span>, loss <span class="number">0.0040</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.936</span>, time <span class="number">87.2</span> sec</span><br><span class="line">epoch  <span class="number">98</span>, loss <span class="number">0.0046</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.938</span>, time <span class="number">87.2</span> sec</span><br><span class="line">epoch  <span class="number">99</span>, loss <span class="number">0.0031</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.937</span>, time <span class="number">87.2</span> sec</span><br><span class="line">epoch <span class="number">100</span>, loss <span class="number">0.0035</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.937</span>, time <span class="number">87.7</span> sec</span><br><span class="line"><span class="comment"># resize = 96</span></span><br><span class="line">epoch   <span class="number">1</span>, loss <span class="number">1.7834</span>, train acc <span class="number">0.372</span>, test acc <span class="number">0.724</span>, time <span class="number">46.8</span> sec</span><br><span class="line">epoch   <span class="number">2</span>, loss <span class="number">0.6941</span>, train acc <span class="number">0.739</span>, test acc <span class="number">0.804</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch   <span class="number">3</span>, loss <span class="number">0.5067</span>, train acc <span class="number">0.814</span>, test acc <span class="number">0.846</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch   <span class="number">4</span>, loss <span class="number">0.4310</span>, train acc <span class="number">0.841</span>, test acc <span class="number">0.864</span>, time <span class="number">45.8</span> sec</span><br><span class="line">epoch   <span class="number">5</span>, loss <span class="number">0.3872</span>, train acc <span class="number">0.859</span>, test acc <span class="number">0.872</span>, time <span class="number">45.8</span> sec</span><br><span class="line">epoch   <span class="number">6</span>, loss <span class="number">0.3586</span>, train acc <span class="number">0.870</span>, test acc <span class="number">0.872</span>, time <span class="number">45.7</span> sec</span><br><span class="line">epoch   <span class="number">7</span>, loss <span class="number">0.3350</span>, train acc <span class="number">0.877</span>, test acc <span class="number">0.885</span>, time <span class="number">45.7</span> sec</span><br><span class="line">epoch   <span class="number">8</span>, loss <span class="number">0.3170</span>, train acc <span class="number">0.884</span>, test acc <span class="number">0.888</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch   <span class="number">9</span>, loss <span class="number">0.3008</span>, train acc <span class="number">0.889</span>, test acc <span class="number">0.891</span>, time <span class="number">45.7</span> sec</span><br><span class="line">epoch  <span class="number">10</span>, loss <span class="number">0.2846</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.897</span>, time <span class="number">45.7</span> sec</span><br><span class="line">epoch  <span class="number">11</span>, loss <span class="number">0.2729</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.900</span>, time <span class="number">45.8</span> sec</span><br><span class="line">epoch  <span class="number">12</span>, loss <span class="number">0.2606</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.903</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">13</span>, loss <span class="number">0.2486</span>, train acc <span class="number">0.908</span>, test acc <span class="number">0.910</span>, time <span class="number">45.7</span> sec</span><br><span class="line">epoch  <span class="number">14</span>, loss <span class="number">0.2406</span>, train acc <span class="number">0.911</span>, test acc <span class="number">0.909</span>, time <span class="number">45.7</span> sec</span><br><span class="line">epoch  <span class="number">15</span>, loss <span class="number">0.2319</span>, train acc <span class="number">0.914</span>, test acc <span class="number">0.911</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">16</span>, loss <span class="number">0.2223</span>, train acc <span class="number">0.917</span>, test acc <span class="number">0.908</span>, time <span class="number">45.8</span> sec</span><br><span class="line">epoch  <span class="number">17</span>, loss <span class="number">0.2144</span>, train acc <span class="number">0.920</span>, test acc <span class="number">0.916</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">18</span>, loss <span class="number">0.2042</span>, train acc <span class="number">0.924</span>, test acc <span class="number">0.912</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">19</span>, loss <span class="number">0.1964</span>, train acc <span class="number">0.927</span>, test acc <span class="number">0.912</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">20</span>, loss <span class="number">0.1870</span>, train acc <span class="number">0.930</span>, test acc <span class="number">0.914</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">21</span>, loss <span class="number">0.1796</span>, train acc <span class="number">0.933</span>, test acc <span class="number">0.916</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">22</span>, loss <span class="number">0.1733</span>, train acc <span class="number">0.936</span>, test acc <span class="number">0.917</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">23</span>, loss <span class="number">0.1619</span>, train acc <span class="number">0.940</span>, test acc <span class="number">0.920</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">24</span>, loss <span class="number">0.1566</span>, train acc <span class="number">0.942</span>, test acc <span class="number">0.918</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">25</span>, loss <span class="number">0.1495</span>, train acc <span class="number">0.944</span>, test acc <span class="number">0.922</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">26</span>, loss <span class="number">0.1418</span>, train acc <span class="number">0.947</span>, test acc <span class="number">0.920</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">27</span>, loss <span class="number">0.1364</span>, train acc <span class="number">0.948</span>, test acc <span class="number">0.920</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">28</span>, loss <span class="number">0.1276</span>, train acc <span class="number">0.952</span>, test acc <span class="number">0.923</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">29</span>, loss <span class="number">0.1218</span>, train acc <span class="number">0.954</span>, test acc <span class="number">0.919</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">30</span>, loss <span class="number">0.1164</span>, train acc <span class="number">0.957</span>, test acc <span class="number">0.924</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">31</span>, loss <span class="number">0.1098</span>, train acc <span class="number">0.958</span>, test acc <span class="number">0.922</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">32</span>, loss <span class="number">0.1035</span>, train acc <span class="number">0.960</span>, test acc <span class="number">0.921</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">33</span>, loss <span class="number">0.0977</span>, train acc <span class="number">0.963</span>, test acc <span class="number">0.921</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">34</span>, loss <span class="number">0.0948</span>, train acc <span class="number">0.965</span>, test acc <span class="number">0.921</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">35</span>, loss <span class="number">0.0866</span>, train acc <span class="number">0.968</span>, test acc <span class="number">0.923</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">36</span>, loss <span class="number">0.0831</span>, train acc <span class="number">0.968</span>, test acc <span class="number">0.924</span>, time <span class="number">45.3</span> sec</span><br><span class="line">epoch  <span class="number">37</span>, loss <span class="number">0.0777</span>, train acc <span class="number">0.971</span>, test acc <span class="number">0.922</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">38</span>, loss <span class="number">0.0750</span>, train acc <span class="number">0.972</span>, test acc <span class="number">0.922</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">39</span>, loss <span class="number">0.0682</span>, train acc <span class="number">0.974</span>, test acc <span class="number">0.925</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">40</span>, loss <span class="number">0.0636</span>, train acc <span class="number">0.976</span>, test acc <span class="number">0.925</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">41</span>, loss <span class="number">0.0640</span>, train acc <span class="number">0.976</span>, test acc <span class="number">0.922</span>, time <span class="number">45.3</span> sec</span><br><span class="line">epoch  <span class="number">42</span>, loss <span class="number">0.0549</span>, train acc <span class="number">0.980</span>, test acc <span class="number">0.923</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">43</span>, loss <span class="number">0.0535</span>, train acc <span class="number">0.980</span>, test acc <span class="number">0.922</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">44</span>, loss <span class="number">0.0527</span>, train acc <span class="number">0.980</span>, test acc <span class="number">0.920</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">45</span>, loss <span class="number">0.0470</span>, train acc <span class="number">0.983</span>, test acc <span class="number">0.921</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">46</span>, loss <span class="number">0.0458</span>, train acc <span class="number">0.983</span>, test acc <span class="number">0.925</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">47</span>, loss <span class="number">0.0433</span>, train acc <span class="number">0.984</span>, test acc <span class="number">0.923</span>, time <span class="number">45.3</span> sec</span><br><span class="line">epoch  <span class="number">48</span>, loss <span class="number">0.0396</span>, train acc <span class="number">0.985</span>, test acc <span class="number">0.920</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">49</span>, loss <span class="number">0.0397</span>, train acc <span class="number">0.985</span>, test acc <span class="number">0.924</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">50</span>, loss <span class="number">0.0347</span>, train acc <span class="number">0.987</span>, test acc <span class="number">0.923</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">51</span>, loss <span class="number">0.0358</span>, train acc <span class="number">0.987</span>, test acc <span class="number">0.922</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">52</span>, loss <span class="number">0.0314</span>, train acc <span class="number">0.989</span>, test acc <span class="number">0.921</span>, time <span class="number">45.7</span> sec</span><br><span class="line">epoch  <span class="number">53</span>, loss <span class="number">0.0323</span>, train acc <span class="number">0.988</span>, test acc <span class="number">0.924</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">54</span>, loss <span class="number">0.0313</span>, train acc <span class="number">0.989</span>, test acc <span class="number">0.922</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">55</span>, loss <span class="number">0.0306</span>, train acc <span class="number">0.989</span>, test acc <span class="number">0.925</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">56</span>, loss <span class="number">0.0260</span>, train acc <span class="number">0.991</span>, test acc <span class="number">0.924</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">57</span>, loss <span class="number">0.0260</span>, train acc <span class="number">0.991</span>, test acc <span class="number">0.924</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">58</span>, loss <span class="number">0.0290</span>, train acc <span class="number">0.989</span>, test acc <span class="number">0.924</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">59</span>, loss <span class="number">0.0223</span>, train acc <span class="number">0.992</span>, test acc <span class="number">0.927</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">60</span>, loss <span class="number">0.0218</span>, train acc <span class="number">0.992</span>, test acc <span class="number">0.926</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">61</span>, loss <span class="number">0.0221</span>, train acc <span class="number">0.992</span>, test acc <span class="number">0.924</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">62</span>, loss <span class="number">0.0189</span>, train acc <span class="number">0.993</span>, test acc <span class="number">0.927</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">63</span>, loss <span class="number">0.0195</span>, train acc <span class="number">0.993</span>, test acc <span class="number">0.923</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">64</span>, loss <span class="number">0.0178</span>, train acc <span class="number">0.994</span>, test acc <span class="number">0.923</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">65</span>, loss <span class="number">0.0201</span>, train acc <span class="number">0.993</span>, test acc <span class="number">0.924</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">66</span>, loss <span class="number">0.0192</span>, train acc <span class="number">0.993</span>, test acc <span class="number">0.923</span>, time <span class="number">45.3</span> sec</span><br><span class="line">epoch  <span class="number">67</span>, loss <span class="number">0.0176</span>, train acc <span class="number">0.994</span>, test acc <span class="number">0.926</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">68</span>, loss <span class="number">0.0155</span>, train acc <span class="number">0.994</span>, test acc <span class="number">0.924</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">69</span>, loss <span class="number">0.0163</span>, train acc <span class="number">0.994</span>, test acc <span class="number">0.922</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">70</span>, loss <span class="number">0.0139</span>, train acc <span class="number">0.995</span>, test acc <span class="number">0.922</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">71</span>, loss <span class="number">0.0158</span>, train acc <span class="number">0.994</span>, test acc <span class="number">0.923</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">72</span>, loss <span class="number">0.0164</span>, train acc <span class="number">0.994</span>, test acc <span class="number">0.926</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">73</span>, loss <span class="number">0.0117</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.926</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">74</span>, loss <span class="number">0.0141</span>, train acc <span class="number">0.995</span>, test acc <span class="number">0.926</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">75</span>, loss <span class="number">0.0125</span>, train acc <span class="number">0.995</span>, test acc <span class="number">0.923</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">76</span>, loss <span class="number">0.0139</span>, train acc <span class="number">0.995</span>, test acc <span class="number">0.925</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">77</span>, loss <span class="number">0.0134</span>, train acc <span class="number">0.995</span>, test acc <span class="number">0.926</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">78</span>, loss <span class="number">0.0090</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.922</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">79</span>, loss <span class="number">0.0106</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.925</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">80</span>, loss <span class="number">0.0117</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.925</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">81</span>, loss <span class="number">0.0107</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.925</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">82</span>, loss <span class="number">0.0106</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.922</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">83</span>, loss <span class="number">0.0100</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.923</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">84</span>, loss <span class="number">0.0097</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.926</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">85</span>, loss <span class="number">0.0104</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.923</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">86</span>, loss <span class="number">0.0110</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.925</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">87</span>, loss <span class="number">0.0087</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.924</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">88</span>, loss <span class="number">0.0114</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.927</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">89</span>, loss <span class="number">0.0078</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.923</span>, time <span class="number">45.6</span> sec</span><br><span class="line">epoch  <span class="number">90</span>, loss <span class="number">0.0081</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.925</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">91</span>, loss <span class="number">0.0084</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.925</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">92</span>, loss <span class="number">0.0068</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.926</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">93</span>, loss <span class="number">0.0066</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.924</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">94</span>, loss <span class="number">0.0104</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.926</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">95</span>, loss <span class="number">0.0062</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.927</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">96</span>, loss <span class="number">0.0065</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.925</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">97</span>, loss <span class="number">0.0069</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.925</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch  <span class="number">98</span>, loss <span class="number">0.0075</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.926</span>, time <span class="number">45.5</span> sec</span><br><span class="line">epoch  <span class="number">99</span>, loss <span class="number">0.0066</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.925</span>, time <span class="number">45.4</span> sec</span><br><span class="line">epoch <span class="number">100</span>, loss <span class="number">0.0074</span>, train acc <span class="number">0.998</span>, test acc <span class="number">0.925</span>, time <span class="number">45.4</span> sec</span><br></pre></td></tr></tbody></table></figure>
<h2 id="网络中的网络（NiN）"><a href="#网络中的网络（NiN）" class="headerlink" title="网络中的网络（NiN）"></a>网络中的网络（NiN）</h2><table>
<thead>
<tr>
<th align="center">名称</th>
<th align="left">结构</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">NiN块</td>
<td align="left">①卷积层：num_channels, kernel_size, strides, padding<br>②1×1卷积层：num_channels, kernel_size=1, activation=’relu’<br>③1×1卷积层：num_channels, kernel_size=1, activation=’relu’</td>
<td align="left">无</td>
</tr>
<tr>
<td align="center">NiN网络</td>
<td align="left">①NiN块：channels=96, kernel_size=11, strides=4, padding=0<br>②最大池化层：pool_size=3, strides=2<br>③NiN块：channels=256, kernel_size=5, strides=1, padding=2<br>④最大池化层：pool_size=3, strides=2<br>⑤NiN块：channels=384, kernel_size=3, strides=1, padding=1<br>⑥最大池化层：pool_size=3, strides=2<br>⑦丢弃层：丢弃概率0.5<br>⑧NiN块：channels=10, kernel_size=3, strides=1, padding=1<br>⑨全局平均池化层<br>⑩平整层：将四维转成二维，(批量大小，10)</td>
<td align="left">无</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> gluon, init, autograd, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> data <span class="keyword">as</span> gdata, loss <span class="keyword">as</span> gloss, nn</span><br><span class="line"><span class="keyword">import</span> sys, os, time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nin_block</span><span class="params">(num_channels, kernel_size, strides, padding)</span>:</span></span><br><span class="line">    blk = nn.Sequential()</span><br><span class="line">    blk.add(nn.Conv2D(num_channels, kernel_size, strides, padding, activation=<span class="string">'relu'</span>),</span><br><span class="line">            nn.Conv2D(num_channels, kernel_size=<span class="number">1</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">            nn.Conv2D(num_channels, kernel_size=<span class="number">1</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    <span class="keyword">return</span> blk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = nn.Sequential()</span><br><span class="line">net.add(nin_block(<span class="number">96</span>, kernel_size=<span class="number">11</span>, strides=<span class="number">4</span>, padding=<span class="number">0</span>),</span><br><span class="line">        nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>),</span><br><span class="line"></span><br><span class="line">        nin_block(<span class="number">256</span>, kernel_size=<span class="number">5</span>, strides=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">        nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>),</span><br><span class="line"></span><br><span class="line">        nin_block(<span class="number">384</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">        nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>),</span><br><span class="line"></span><br><span class="line">        nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">        <span class="comment"># 标签类别10</span></span><br><span class="line">        nin_block(<span class="number">10</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">        <span class="comment"># 全局平均池化层将窗口形状自动设置成输入的高河宽</span></span><br><span class="line">        nn.GlobalAvgPool2D(),</span><br><span class="line">        <span class="comment"># 将四维的输出转成二维的输出，其形状为（批量大小，10)</span></span><br><span class="line">        nn.Flatten())</span><br><span class="line"></span><br><span class="line">X = nd.random.uniform(shape=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">net.initialize()</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    print(layer.name, <span class="string">'output shape:\t'</span>, X.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span><span class="params">(batch_size, resize=None, root=os.path.join<span class="params">(<span class="string">'mxnet'</span>, <span class="string">'datasets'</span>, <span class="string">'fashion-mnist'</span>)</span>)</span>:</span></span><br><span class="line">    root = os.path.expanduser(root)</span><br><span class="line">    transformer = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        transformer += [gdata.vision.transforms.Resize(resize)]</span><br><span class="line">    transformer += [gdata.vision.transforms.ToTensor()]</span><br><span class="line">    transformer = gdata.vision.transforms.Compose(transformer)</span><br><span class="line"></span><br><span class="line">    mnist_train = gdata.vision.FashionMNIST(root=root, train=<span class="literal">True</span>)</span><br><span class="line">    mnist_test = gdata.vision.FashionMNIST(root=root, train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    num_workers = <span class="number">0</span> <span class="keyword">if</span> sys.platform.startswith(<span class="string">'win'</span>) <span class="keyword">else</span> <span class="number">4</span></span><br><span class="line">    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),</span><br><span class="line">                                  batch_size=batch_size,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  num_workers=num_workers)</span><br><span class="line">    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),</span><br><span class="line">                                 batch_size=batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=num_workers)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(net, data_iter, ctx)</span>:</span></span><br><span class="line">    acc_sum, n = nd.array([<span class="number">0</span>], ctx=ctx), <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype(<span class="string">'float32'</span>)</span><br><span class="line">        y_hat = net(X)</span><br><span class="line">        acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum()</span><br><span class="line">        n += y.size</span><br><span class="line">    <span class="keyword">return</span> acc_sum.asscalar() / n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span>:</span></span><br><span class="line">    print(<span class="string">"training on "</span>, ctx)</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X, y = X.as_in_context(ctx), y.as_in_context(ctx)</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            trainer.step(batch_size)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y.astype(<span class="string">'float32'</span>)).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(net, test_iter, ctx)</span><br><span class="line">        print(<span class="string">'epoch %3d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ctx = mx.gpu()</span><br><span class="line">        _ = nd.array((<span class="number">1</span>,), ctx=ctx)</span><br><span class="line">    <span class="keyword">except</span> mx.base.MXNetError:</span><br><span class="line">        ctx = mx.cpu()</span><br><span class="line">    <span class="keyword">return</span> ctx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr, num_epochs, batch_size, ctx = <span class="number">0.1</span>, <span class="number">5</span>, <span class="number">128</span>, try_gpu()</span><br><span class="line">net.initialize(force_reinit=<span class="literal">True</span>, init=init.Xavier(), ctx=ctx)</span><br><span class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">'sgd'</span>, {<span class="string">'learning_rate'</span>: lr})</span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">224</span>)</span><br><span class="line">train(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各层输出的形状：</span></span><br><span class="line">sequential1 output shape:	 (<span class="number">1</span>, <span class="number">96</span>, <span class="number">54</span>, <span class="number">54</span>)</span><br><span class="line">pool0 output shape:	 (<span class="number">1</span>, <span class="number">96</span>, <span class="number">26</span>, <span class="number">26</span>)</span><br><span class="line">sequential2 output shape:	 (<span class="number">1</span>, <span class="number">256</span>, <span class="number">26</span>, <span class="number">26</span>)</span><br><span class="line">pool1 output shape:	 (<span class="number">1</span>, <span class="number">256</span>, <span class="number">12</span>, <span class="number">12</span>)</span><br><span class="line">sequential3 output shape:	 (<span class="number">1</span>, <span class="number">384</span>, <span class="number">12</span>, <span class="number">12</span>)</span><br><span class="line">pool2 output shape:	 (<span class="number">1</span>, <span class="number">384</span>, <span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">dropout0 output shape:	 (<span class="number">1</span>, <span class="number">384</span>, <span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">sequential4 output shape:	 (<span class="number">1</span>, <span class="number">10</span>, <span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">pool3 output shape:	 (<span class="number">1</span>, <span class="number">10</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">flatten0 output shape:	 (<span class="number">1</span>, <span class="number">10</span>)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">training on gpu(<span class="number">1</span>):</span><br><span class="line"><span class="comment"># NiN块两个1×1卷积层</span></span><br><span class="line">epoch   <span class="number">1</span>, loss <span class="number">2.2408</span>, train acc <span class="number">0.187</span>, test acc <span class="number">0.418</span>, time <span class="number">45.0</span> sec</span><br><span class="line">epoch   <span class="number">2</span>, loss <span class="number">1.1892</span>, train acc <span class="number">0.565</span>, test acc <span class="number">0.731</span>, time <span class="number">42.6</span> sec</span><br><span class="line">epoch   <span class="number">3</span>, loss <span class="number">0.6967</span>, train acc <span class="number">0.746</span>, test acc <span class="number">0.801</span>, time <span class="number">46.4</span> sec</span><br><span class="line">epoch   <span class="number">4</span>, loss <span class="number">0.5585</span>, train acc <span class="number">0.796</span>, test acc <span class="number">0.833</span>, time <span class="number">43.1</span> sec</span><br><span class="line">epoch   <span class="number">5</span>, loss <span class="number">0.4827</span>, train acc <span class="number">0.822</span>, test acc <span class="number">0.851</span>, time <span class="number">42.9</span> sec</span><br><span class="line">epoch   <span class="number">6</span>, loss <span class="number">0.4360</span>, train acc <span class="number">0.840</span>, test acc <span class="number">0.859</span>, time <span class="number">42.9</span> sec</span><br><span class="line">epoch   <span class="number">7</span>, loss <span class="number">0.3934</span>, train acc <span class="number">0.854</span>, test acc <span class="number">0.866</span>, time <span class="number">43.2</span> sec</span><br><span class="line">epoch   <span class="number">8</span>, loss <span class="number">0.3693</span>, train acc <span class="number">0.863</span>, test acc <span class="number">0.880</span>, time <span class="number">43.3</span> sec</span><br><span class="line">epoch   <span class="number">9</span>, loss <span class="number">0.3500</span>, train acc <span class="number">0.870</span>, test acc <span class="number">0.883</span>, time <span class="number">43.0</span> sec</span><br><span class="line">epoch  <span class="number">10</span>, loss <span class="number">0.3332</span>, train acc <span class="number">0.878</span>, test acc <span class="number">0.861</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">11</span>, loss <span class="number">0.3225</span>, train acc <span class="number">0.882</span>, test acc <span class="number">0.883</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">12</span>, loss <span class="number">0.3071</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.898</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">13</span>, loss <span class="number">0.2971</span>, train acc <span class="number">0.890</span>, test acc <span class="number">0.902</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">14</span>, loss <span class="number">0.2880</span>, train acc <span class="number">0.894</span>, test acc <span class="number">0.897</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">15</span>, loss <span class="number">0.2780</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.905</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">16</span>, loss <span class="number">0.2715</span>, train acc <span class="number">0.900</span>, test acc <span class="number">0.911</span>, time <span class="number">42.9</span> sec</span><br><span class="line">epoch  <span class="number">17</span>, loss <span class="number">0.2629</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.907</span>, time <span class="number">42.6</span> sec</span><br><span class="line">epoch  <span class="number">18</span>, loss <span class="number">0.2538</span>, train acc <span class="number">0.906</span>, test acc <span class="number">0.909</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">19</span>, loss <span class="number">0.2494</span>, train acc <span class="number">0.910</span>, test acc <span class="number">0.916</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">20</span>, loss <span class="number">0.2445</span>, train acc <span class="number">0.910</span>, test acc <span class="number">0.916</span>, time <span class="number">42.9</span> sec</span><br><span class="line">epoch  <span class="number">21</span>, loss <span class="number">0.2396</span>, train acc <span class="number">0.911</span>, test acc <span class="number">0.914</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">22</span>, loss <span class="number">0.2326</span>, train acc <span class="number">0.914</span>, test acc <span class="number">0.902</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">23</span>, loss <span class="number">0.2276</span>, train acc <span class="number">0.917</span>, test acc <span class="number">0.919</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">24</span>, loss <span class="number">0.2253</span>, train acc <span class="number">0.918</span>, test acc <span class="number">0.899</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">25</span>, loss <span class="number">0.2184</span>, train acc <span class="number">0.920</span>, test acc <span class="number">0.919</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">26</span>, loss <span class="number">0.2161</span>, train acc <span class="number">0.920</span>, test acc <span class="number">0.916</span>, time <span class="number">42.6</span> sec</span><br><span class="line">epoch  <span class="number">27</span>, loss <span class="number">0.2114</span>, train acc <span class="number">0.923</span>, test acc <span class="number">0.923</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">28</span>, loss <span class="number">0.2054</span>, train acc <span class="number">0.924</span>, test acc <span class="number">0.918</span>, time <span class="number">42.6</span> sec</span><br><span class="line">epoch  <span class="number">29</span>, loss <span class="number">0.2014</span>, train acc <span class="number">0.926</span>, test acc <span class="number">0.921</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">30</span>, loss <span class="number">0.2008</span>, train acc <span class="number">0.926</span>, test acc <span class="number">0.923</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">31</span>, loss <span class="number">0.1953</span>, train acc <span class="number">0.929</span>, test acc <span class="number">0.924</span>, time <span class="number">42.9</span> sec</span><br><span class="line">epoch  <span class="number">32</span>, loss <span class="number">0.1915</span>, train acc <span class="number">0.929</span>, test acc <span class="number">0.924</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">33</span>, loss <span class="number">0.1866</span>, train acc <span class="number">0.931</span>, test acc <span class="number">0.922</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">34</span>, loss <span class="number">0.1861</span>, train acc <span class="number">0.931</span>, test acc <span class="number">0.921</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">35</span>, loss <span class="number">0.1797</span>, train acc <span class="number">0.934</span>, test acc <span class="number">0.927</span>, time <span class="number">42.6</span> sec</span><br><span class="line">epoch  <span class="number">36</span>, loss <span class="number">0.1761</span>, train acc <span class="number">0.935</span>, test acc <span class="number">0.927</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">37</span>, loss <span class="number">0.1727</span>, train acc <span class="number">0.937</span>, test acc <span class="number">0.929</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">38</span>, loss <span class="number">0.1716</span>, train acc <span class="number">0.935</span>, test acc <span class="number">0.927</span>, time <span class="number">42.9</span> sec</span><br><span class="line">epoch  <span class="number">39</span>, loss <span class="number">0.1683</span>, train acc <span class="number">0.938</span>, test acc <span class="number">0.922</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">40</span>, loss <span class="number">0.1645</span>, train acc <span class="number">0.940</span>, test acc <span class="number">0.928</span>, time <span class="number">42.6</span> sec</span><br><span class="line">epoch  <span class="number">41</span>, loss <span class="number">0.1598</span>, train acc <span class="number">0.941</span>, test acc <span class="number">0.919</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">42</span>, loss <span class="number">0.1558</span>, train acc <span class="number">0.943</span>, test acc <span class="number">0.920</span>, time <span class="number">42.9</span> sec</span><br><span class="line">epoch  <span class="number">43</span>, loss <span class="number">0.1542</span>, train acc <span class="number">0.943</span>, test acc <span class="number">0.924</span>, time <span class="number">42.6</span> sec</span><br><span class="line">epoch  <span class="number">44</span>, loss <span class="number">0.1527</span>, train acc <span class="number">0.945</span>, test acc <span class="number">0.932</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">45</span>, loss <span class="number">0.1491</span>, train acc <span class="number">0.945</span>, test acc <span class="number">0.924</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">46</span>, loss <span class="number">0.1474</span>, train acc <span class="number">0.945</span>, test acc <span class="number">0.932</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">47</span>, loss <span class="number">0.1419</span>, train acc <span class="number">0.947</span>, test acc <span class="number">0.926</span>, time <span class="number">42.8</span> sec</span><br><span class="line">epoch  <span class="number">48</span>, loss <span class="number">0.1406</span>, train acc <span class="number">0.948</span>, test acc <span class="number">0.926</span>, time <span class="number">42.7</span> sec</span><br><span class="line">epoch  <span class="number">49</span>, loss <span class="number">0.1377</span>, train acc <span class="number">0.949</span>, test acc <span class="number">0.931</span>, time <span class="number">42.6</span> sec</span><br><span class="line">epoch  <span class="number">50</span>, loss <span class="number">0.1338</span>, train acc <span class="number">0.951</span>, test acc <span class="number">0.929</span>, time <span class="number">42.8</span> sec</span><br><span class="line"><span class="comment"># # NiN块一个1×1卷积层</span></span><br><span class="line">epoch   <span class="number">1</span>, loss <span class="number">1.8875</span>, train acc <span class="number">0.342</span>, test acc <span class="number">0.612</span>, time <span class="number">32.8</span> sec</span><br><span class="line">epoch   <span class="number">2</span>, loss <span class="number">0.7512</span>, train acc <span class="number">0.718</span>, test acc <span class="number">0.805</span>, time <span class="number">31.0</span> sec</span><br><span class="line">epoch   <span class="number">3</span>, loss <span class="number">0.5529</span>, train acc <span class="number">0.800</span>, test acc <span class="number">0.835</span>, time <span class="number">30.6</span> sec</span><br><span class="line">epoch   <span class="number">4</span>, loss <span class="number">0.4634</span>, train acc <span class="number">0.831</span>, test acc <span class="number">0.854</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch   <span class="number">5</span>, loss <span class="number">0.4178</span>, train acc <span class="number">0.849</span>, test acc <span class="number">0.873</span>, time <span class="number">30.4</span> sec</span><br><span class="line">epoch   <span class="number">6</span>, loss <span class="number">0.3921</span>, train acc <span class="number">0.855</span>, test acc <span class="number">0.876</span>, time <span class="number">30.5</span> sec</span><br><span class="line">epoch   <span class="number">7</span>, loss <span class="number">0.3671</span>, train acc <span class="number">0.866</span>, test acc <span class="number">0.881</span>, time <span class="number">30.7</span> sec</span><br><span class="line">epoch   <span class="number">8</span>, loss <span class="number">0.3498</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.884</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch   <span class="number">9</span>, loss <span class="number">0.3386</span>, train acc <span class="number">0.875</span>, test acc <span class="number">0.886</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">10</span>, loss <span class="number">0.3226</span>, train acc <span class="number">0.881</span>, test acc <span class="number">0.891</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">11</span>, loss <span class="number">0.3117</span>, train acc <span class="number">0.885</span>, test acc <span class="number">0.898</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">12</span>, loss <span class="number">0.3012</span>, train acc <span class="number">0.889</span>, test acc <span class="number">0.897</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">13</span>, loss <span class="number">0.2919</span>, train acc <span class="number">0.892</span>, test acc <span class="number">0.902</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">14</span>, loss <span class="number">0.2818</span>, train acc <span class="number">0.897</span>, test acc <span class="number">0.907</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">15</span>, loss <span class="number">0.2746</span>, train acc <span class="number">0.898</span>, test acc <span class="number">0.907</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">16</span>, loss <span class="number">0.2669</span>, train acc <span class="number">0.902</span>, test acc <span class="number">0.907</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch  <span class="number">17</span>, loss <span class="number">0.2620</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.900</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">18</span>, loss <span class="number">0.2528</span>, train acc <span class="number">0.907</span>, test acc <span class="number">0.885</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">19</span>, loss <span class="number">0.2488</span>, train acc <span class="number">0.909</span>, test acc <span class="number">0.908</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">20</span>, loss <span class="number">0.2415</span>, train acc <span class="number">0.911</span>, test acc <span class="number">0.896</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch  <span class="number">21</span>, loss <span class="number">0.2374</span>, train acc <span class="number">0.912</span>, test acc <span class="number">0.912</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">22</span>, loss <span class="number">0.2326</span>, train acc <span class="number">0.915</span>, test acc <span class="number">0.914</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">23</span>, loss <span class="number">0.2263</span>, train acc <span class="number">0.916</span>, test acc <span class="number">0.921</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">24</span>, loss <span class="number">0.2257</span>, train acc <span class="number">0.918</span>, test acc <span class="number">0.920</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">25</span>, loss <span class="number">0.2208</span>, train acc <span class="number">0.919</span>, test acc <span class="number">0.916</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">26</span>, loss <span class="number">0.2166</span>, train acc <span class="number">0.921</span>, test acc <span class="number">0.917</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">27</span>, loss <span class="number">0.2122</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.917</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">28</span>, loss <span class="number">0.2081</span>, train acc <span class="number">0.924</span>, test acc <span class="number">0.919</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">29</span>, loss <span class="number">0.2053</span>, train acc <span class="number">0.926</span>, test acc <span class="number">0.919</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">30</span>, loss <span class="number">0.2023</span>, train acc <span class="number">0.925</span>, test acc <span class="number">0.917</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">31</span>, loss <span class="number">0.1973</span>, train acc <span class="number">0.927</span>, test acc <span class="number">0.923</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">32</span>, loss <span class="number">0.1965</span>, train acc <span class="number">0.929</span>, test acc <span class="number">0.919</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">33</span>, loss <span class="number">0.1946</span>, train acc <span class="number">0.929</span>, test acc <span class="number">0.927</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">34</span>, loss <span class="number">0.1862</span>, train acc <span class="number">0.931</span>, test acc <span class="number">0.927</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">35</span>, loss <span class="number">0.1859</span>, train acc <span class="number">0.932</span>, test acc <span class="number">0.926</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch  <span class="number">36</span>, loss <span class="number">0.1811</span>, train acc <span class="number">0.934</span>, test acc <span class="number">0.923</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">37</span>, loss <span class="number">0.1791</span>, train acc <span class="number">0.934</span>, test acc <span class="number">0.925</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">38</span>, loss <span class="number">0.1783</span>, train acc <span class="number">0.934</span>, test acc <span class="number">0.918</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">39</span>, loss <span class="number">0.1748</span>, train acc <span class="number">0.936</span>, test acc <span class="number">0.923</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">40</span>, loss <span class="number">0.1693</span>, train acc <span class="number">0.938</span>, test acc <span class="number">0.926</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">41</span>, loss <span class="number">0.1690</span>, train acc <span class="number">0.937</span>, test acc <span class="number">0.926</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">42</span>, loss <span class="number">0.1653</span>, train acc <span class="number">0.939</span>, test acc <span class="number">0.929</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">43</span>, loss <span class="number">0.1615</span>, train acc <span class="number">0.940</span>, test acc <span class="number">0.922</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">44</span>, loss <span class="number">0.1596</span>, train acc <span class="number">0.942</span>, test acc <span class="number">0.928</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">45</span>, loss <span class="number">0.1538</span>, train acc <span class="number">0.943</span>, test acc <span class="number">0.926</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">46</span>, loss <span class="number">0.1530</span>, train acc <span class="number">0.942</span>, test acc <span class="number">0.926</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">47</span>, loss <span class="number">0.1498</span>, train acc <span class="number">0.944</span>, test acc <span class="number">0.930</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">48</span>, loss <span class="number">0.1507</span>, train acc <span class="number">0.944</span>, test acc <span class="number">0.924</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">49</span>, loss <span class="number">0.1469</span>, train acc <span class="number">0.944</span>, test acc <span class="number">0.924</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">50</span>, loss <span class="number">0.1438</span>, train acc <span class="number">0.948</span>, test acc <span class="number">0.928</span>, time <span class="number">30.1</span> sec</span><br></pre></td></tr></tbody></table></figure>
<h2 id="含并行连结的网络（GoogLeNet）"><a href="#含并行连结的网络（GoogLeNet）" class="headerlink" title="含并行连结的网络（GoogLeNet）"></a>含并行连结的网络（GoogLeNet）</h2><table>
<thead>
<tr>
<th align="center">名称</th>
<th align="left">结构</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Inception Block<br>(c1, c2, c3, c4)</td>
<td align="left">①线路1：<br>　　1×1卷积层：channels=c1, kernel_size=1, activation=’relu’<br>②线路2：<br>　　1×1卷积层：channels=c2[0], kernel_size=1, activation=’relu’<br>　　3×3卷积层：channels=c2[1], kernel_size=3, padding=1, activatio=’relu’<br>③线路3：<br>　　1×1卷积层：channels=c3[0], kernel_size=1, activation=’relu’<br>　　5×5卷积层：channels=c3[1],kernel_size=5, padding=2, activation=’relu’<br>④线路4：<br>　　3×3最大池化层：pool_size=3, strides=1. padding=1<br>　　1×1卷积层：channels=c4, kernel_size=1, activation=’relu’</td>
</tr>
</tbody></table>
<p><img src="/assets/img/deep_learning/deep_learning_01.png" alt="Inception块图示"></p>
<table>
<thead>
<tr>
<th align="center">名称</th>
<th align="left">结构</th>
</tr>
</thead>
<tbody><tr>
<td align="center">GoogLeNet</td>
<td align="left">①Block 1：<br>　　7×7卷积层：channels=64, kernel_size=7, strides=2, padding=3, activation=’relu’<br>　　3×3最大池化层：pool_size=3, strides=2, padding=1<br>②Block 2：<br>　　1×1卷积层：channels=64, kernel_size=1, activation=’relu’<br>　　3×3卷积层：channels=192, kernel_size=3, padding=1, activation=’relu’<br>　　3×3最大池化层：pool_size=3, strides=2, padding=1<br>③Block 3：<br>　　Inception(64, (96, 128), (16, 32), 32)<br>　　Inception(128, (128, 192), (32, 96), 64)<br>　　3×3最大池化层：pool_size=3, strides=2, padding=1<br>④Block 4：<br>　　Inception(192, (96, 208), (16, 48), 64)<br>　　Inception(160, (112, 224), (24, 64), 64)<br>　　Inception(128, (128, 256), (24, 64), 64)<br>　　Inception(112, (144, 288), (32, 64), 64)<br>　　Inception(256, (160, 320), (32, 128), 128)<br>　　3×3最大池化层：pool_size=3, strides=2, padding=1<br>⑤Block 5：<br>　　Inception(256, (160, 320), (32, 128), 128)<br>　　Inception(384, (192, 384), (48, 128), 128)<br>　　全局平均池化层<br>⑥全连接层：channels=10</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> gluon, init, nd, autograd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> data <span class="keyword">as</span> gdata, loss <span class="keyword">as</span> gloss, nn</span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Log</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.NONE = <span class="number">0</span></span><br><span class="line">        self.INFO = <span class="number">1</span></span><br><span class="line">        self.level = self.NONE</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_level</span><span class="params">(self, level)</span>:</span></span><br><span class="line">        self.level = level</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">info</span><span class="params">(self, arg)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.level != self.NONE:</span><br><span class="line">            print(arg)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inception</span><span class="params">(nn.Block, Log)</span>:</span></span><br><span class="line">    <span class="comment"># c1 - c4为每条线路里的层的输出通道数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, c1, c2, c3, c4, **kwargs)</span>:</span></span><br><span class="line">        nn.Block.__init__(self, **kwargs)</span><br><span class="line">        Log.__init__(self)</span><br><span class="line">        <span class="comment"># 线路1，单1×1卷积层</span></span><br><span class="line">        self.p1_1 = nn.Conv2D(c1, kernel_size=<span class="number">1</span>, activation=<span class="string">'relu'</span>)</span><br><span class="line">        <span class="comment"># 线路2，1×1卷积层后接3×3卷积层</span></span><br><span class="line">        self.p2_1 = nn.Conv2D(c2[<span class="number">0</span>], kernel_size=<span class="number">1</span>, activation=<span class="string">'relu'</span>)</span><br><span class="line">        self.p2_2 = nn.Conv2D(c2[<span class="number">1</span>], kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, activation=<span class="string">'relu'</span>)</span><br><span class="line">        <span class="comment"># 线路3，1×1卷积层后接5×5卷积层</span></span><br><span class="line">        self.p3_1 = nn.Conv2D(c3[<span class="number">0</span>], kernel_size=<span class="number">1</span>, activation=<span class="string">'relu'</span>)</span><br><span class="line">        self.p3_2 = nn.Conv2D(c3[<span class="number">1</span>], kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>, activation=<span class="string">'relu'</span>)</span><br><span class="line">        <span class="comment"># 线路4，3×3池化层后接1×1卷积层</span></span><br><span class="line">        self.p4_1 = nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.p4_2 = nn.Conv2D(c4, kernel_size=<span class="number">1</span>, activation=<span class="string">'relu'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        p1 = self.p1_1(x)</span><br><span class="line">        self.info(<span class="string">'Path 1:\t output shpae:\t'</span> + p1.shape.__str__())</span><br><span class="line">        p2 = self.p2_2(self.p2_1(x))</span><br><span class="line">        self.info(<span class="string">'Path 2:\t output shape:\t'</span> + p2.shape.__str__())</span><br><span class="line">        p3 = self.p3_2(self.p3_1(x))</span><br><span class="line">        self.info(<span class="string">'Path 3:\t output shape:\t'</span> + p3.shape.__str__())</span><br><span class="line">        p4 = self.p4_2(self.p4_1(x))</span><br><span class="line">        self.info(<span class="string">'Path 4:\t output shape:\t'</span> + p4.shape.__str__())</span><br><span class="line">        <span class="keyword">return</span> nd.concat(p1, p2, p3, p4, dim=<span class="number">1</span>)  <span class="comment"># 在通道维上连接输出</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">f = open(<span class="string">'GoogLeNet_Log.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line"></span><br><span class="line">b1 = nn.Sequential()</span><br><span class="line">b1.add(nn.Conv2D(<span class="number">64</span>, kernel_size=<span class="number">7</span>, strides=<span class="number">2</span>, padding=<span class="number">3</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">       nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b2 = nn.Sequential()</span><br><span class="line">b2.add(nn.Conv2D(<span class="number">64</span>, kernel_size=<span class="number">1</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">       nn.Conv2D(<span class="number">192</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">       nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b3 = nn.Sequential()</span><br><span class="line">b3.add(Inception(<span class="number">64</span>, (<span class="number">96</span>, <span class="number">128</span>), (<span class="number">16</span>, <span class="number">32</span>), <span class="number">32</span>),</span><br><span class="line">       Inception(<span class="number">128</span>, (<span class="number">128</span>, <span class="number">192</span>), (<span class="number">32</span>, <span class="number">96</span>), <span class="number">64</span>),</span><br><span class="line">       nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b4 = nn.Sequential()</span><br><span class="line">b4.add(Inception(<span class="number">192</span>, (<span class="number">96</span>, <span class="number">208</span>), (<span class="number">16</span>, <span class="number">48</span>), <span class="number">64</span>),</span><br><span class="line">       Inception(<span class="number">160</span>, (<span class="number">112</span>, <span class="number">224</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">       Inception(<span class="number">128</span>, (<span class="number">128</span>, <span class="number">256</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">       Inception(<span class="number">112</span>, (<span class="number">144</span>, <span class="number">288</span>), (<span class="number">32</span>, <span class="number">64</span>), <span class="number">64</span>),</span><br><span class="line">       Inception(<span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">       nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">b5 = nn.Sequential()</span><br><span class="line">b5.add(Inception(<span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">       Inception(<span class="number">384</span>, (<span class="number">192</span>, <span class="number">384</span>), (<span class="number">48</span>, <span class="number">128</span>), <span class="number">128</span>),</span><br><span class="line">       nn.GlobalAvgPool2D())</span><br><span class="line"></span><br><span class="line">net = nn.Sequential()</span><br><span class="line">net.add(b1, b2, b3, b4, b5, nn.Dense(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">X = nd.random.uniform(shape=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">96</span>, <span class="number">96</span>))</span><br><span class="line">net.initialize()</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">    X = layer(X)</span><br><span class="line">    print(layer.name, <span class="string">'output shape:\t'</span>, X.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ctx = mx.gpu(<span class="number">0</span>)</span><br><span class="line">        _ = nd.array((<span class="number">1</span>,), ctx=ctx)</span><br><span class="line">    <span class="keyword">except</span> mx.base.MXNetError:</span><br><span class="line">        ctx = mx.cpu()</span><br><span class="line">    <span class="keyword">return</span> ctx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span><span class="params">(batch_size, resize=None, root=os.path.join<span class="params">(<span class="string">'mxnet'</span>, <span class="string">'datasets'</span>, <span class="string">'fashion-mnist'</span>)</span>)</span>:</span></span><br><span class="line">    root = os.path.expanduser(root)</span><br><span class="line">    transformer = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        transformer += [gdata.vision.transforms.Resize(resize)]</span><br><span class="line">    transformer += [gdata.vision.transforms.ToTensor()]</span><br><span class="line">    transformer = gdata.vision.transforms.Compose(transformer)</span><br><span class="line"></span><br><span class="line">    mnist_train = gdata.vision.FashionMNIST(root=root, train=<span class="literal">True</span>)</span><br><span class="line">    mnist_test = gdata.vision.FashionMNIST(root=root, train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    num_workers = <span class="number">0</span> <span class="keyword">if</span> sys.platform.startswith(<span class="string">'win'</span>) <span class="keyword">else</span> <span class="number">4</span></span><br><span class="line">    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),</span><br><span class="line">                                  batch_size=batch_size,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  num_workers=num_workers)</span><br><span class="line">    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),</span><br><span class="line">                                 batch_size=batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=num_workers)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(net, data_iter, ctx)</span>:</span></span><br><span class="line">    acc_sum, n = nd.array([<span class="number">0</span>], ctx=ctx), <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype(<span class="string">'float32'</span>)</span><br><span class="line">        y_hat = net(X)</span><br><span class="line">        acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum()</span><br><span class="line">        n += y.size</span><br><span class="line">    <span class="keyword">return</span> acc_sum.asscalar() / n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span>:</span></span><br><span class="line">    print(<span class="string">"training on "</span>, ctx)</span><br><span class="line">    print(<span class="string">"training on"</span>, ctx, file=f):</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X, y = X.as_in_context(ctx), y.as_in_context(ctx)</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            trainer.step(batch_size)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y.astype(<span class="string">'float32'</span>)).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(net, test_iter, ctx)</span><br><span class="line">        print(<span class="string">'epoch %3d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start), file=f)</span><br><span class="line">        print(<span class="string">'epoch %3d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr, num_epochs, batch_size, ctx = <span class="number">0.1</span>, <span class="number">200</span>, <span class="number">640</span>, try_gpu()</span><br><span class="line">net.initialize(force_reinit=<span class="literal">True</span>, ctx=ctx, init=init.Xavier())</span><br><span class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">'sgd'</span>, {<span class="string">'learning_rate'</span>: lr})</span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">96</span>)</span><br><span class="line">train(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span><br><span class="line">f.close()</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各层输出形状：</span></span><br><span class="line">sequential0 output shape:	 (<span class="number">1</span>, <span class="number">64</span>, <span class="number">24</span>, <span class="number">24</span>)</span><br><span class="line">sequential1 output shape:	 (<span class="number">1</span>, <span class="number">192</span>, <span class="number">12</span>, <span class="number">12</span>)</span><br><span class="line">sequential2 output shape:	 (<span class="number">1</span>, <span class="number">480</span>, <span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">sequential3 output shape:	 (<span class="number">1</span>, <span class="number">832</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">sequential4 output shape:	 (<span class="number">1</span>, <span class="number">1024</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">dense0 output shape:	 (<span class="number">1</span>, <span class="number">10</span>)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lr = 0.1</span></span><br><span class="line"><span class="comment"># 学习率太大，迭代条件无法继续收敛，逼近局部最优解</span></span><br><span class="line">training on gpu(<span class="number">0</span>)</span><br><span class="line">epoch   <span class="number">1</span>, loss <span class="number">2.2956</span>, train acc <span class="number">0.202</span>, test acc <span class="number">0.287</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch   <span class="number">2</span>, loss <span class="number">2.2502</span>, train acc <span class="number">0.196</span>, test acc <span class="number">0.100</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch   <span class="number">3</span>, loss <span class="number">2.2327</span>, train acc <span class="number">0.195</span>, test acc <span class="number">0.112</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch   <span class="number">4</span>, loss <span class="number">1.9764</span>, train acc <span class="number">0.238</span>, test acc <span class="number">0.438</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch   <span class="number">5</span>, loss <span class="number">1.2506</span>, train acc <span class="number">0.491</span>, test acc <span class="number">0.585</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch   <span class="number">6</span>, loss <span class="number">0.9741</span>, train acc <span class="number">0.597</span>, test acc <span class="number">0.644</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch   <span class="number">7</span>, loss <span class="number">0.8311</span>, train acc <span class="number">0.673</span>, test acc <span class="number">0.732</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch   <span class="number">8</span>, loss <span class="number">0.7428</span>, train acc <span class="number">0.717</span>, test acc <span class="number">0.716</span>, time <span class="number">30.6</span> sec</span><br><span class="line">epoch   <span class="number">9</span>, loss <span class="number">0.6305</span>, train acc <span class="number">0.762</span>, test acc <span class="number">0.801</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">10</span>, loss <span class="number">0.5576</span>, train acc <span class="number">0.792</span>, test acc <span class="number">0.811</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">11</span>, loss <span class="number">0.5094</span>, train acc <span class="number">0.807</span>, test acc <span class="number">0.789</span>, time <span class="number">30.5</span> sec</span><br><span class="line">epoch  <span class="number">12</span>, loss <span class="number">0.4768</span>, train acc <span class="number">0.819</span>, test acc <span class="number">0.830</span>, time <span class="number">30.7</span> sec</span><br><span class="line">epoch  <span class="number">13</span>, loss <span class="number">0.4396</span>, train acc <span class="number">0.833</span>, test acc <span class="number">0.847</span>, time <span class="number">30.5</span> sec</span><br><span class="line">epoch  <span class="number">14</span>, loss <span class="number">0.4206</span>, train acc <span class="number">0.842</span>, test acc <span class="number">0.858</span>, time <span class="number">30.7</span> sec</span><br><span class="line">epoch  <span class="number">15</span>, loss <span class="number">0.8486</span>, train acc <span class="number">0.694</span>, test acc <span class="number">0.662</span>, time <span class="number">30.4</span> sec</span><br><span class="line">epoch  <span class="number">16</span>, loss <span class="number">0.6279</span>, train acc <span class="number">0.767</span>, test acc <span class="number">0.849</span>, time <span class="number">30.6</span> sec</span><br><span class="line">epoch  <span class="number">17</span>, loss <span class="number">0.5334</span>, train acc <span class="number">0.806</span>, test acc <span class="number">0.855</span>, time <span class="number">30.4</span> sec</span><br><span class="line">epoch  <span class="number">18</span>, loss <span class="number">0.3896</span>, train acc <span class="number">0.854</span>, test acc <span class="number">0.866</span>, time <span class="number">30.6</span> sec</span><br><span class="line">epoch  <span class="number">19</span>, loss <span class="number">0.3684</span>, train acc <span class="number">0.862</span>, test acc <span class="number">0.864</span>, time <span class="number">30.6</span> sec</span><br><span class="line">epoch  <span class="number">20</span>, loss <span class="number">0.3499</span>, train acc <span class="number">0.867</span>, test acc <span class="number">0.873</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">21</span>, loss <span class="number">0.3360</span>, train acc <span class="number">0.873</span>, test acc <span class="number">0.877</span>, time <span class="number">30.5</span> sec</span><br><span class="line">epoch  <span class="number">22</span>, loss <span class="number">0.3333</span>, train acc <span class="number">0.874</span>, test acc <span class="number">0.884</span>, time <span class="number">30.6</span> sec</span><br><span class="line">epoch  <span class="number">23</span>, loss <span class="number">0.3102</span>, train acc <span class="number">0.883</span>, test acc <span class="number">0.887</span>, time <span class="number">31.0</span> sec</span><br><span class="line">epoch  <span class="number">24</span>, loss <span class="number">0.3080</span>, train acc <span class="number">0.883</span>, test acc <span class="number">0.886</span>, time <span class="number">30.5</span> sec</span><br><span class="line">epoch  <span class="number">25</span>, loss <span class="number">0.2979</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.886</span>, time <span class="number">30.6</span> sec</span><br><span class="line">epoch  <span class="number">26</span>, loss <span class="number">0.2865</span>, train acc <span class="number">0.891</span>, test acc <span class="number">0.894</span>, time <span class="number">30.6</span> sec</span><br><span class="line">epoch  <span class="number">27</span>, loss <span class="number">0.2806</span>, train acc <span class="number">0.893</span>, test acc <span class="number">0.889</span>, time <span class="number">30.7</span> sec</span><br><span class="line">epoch  <span class="number">28</span>, loss <span class="number">0.2754</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.891</span>, time <span class="number">30.5</span> sec</span><br><span class="line">epoch  <span class="number">29</span>, loss <span class="number">0.2661</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.892</span>, time <span class="number">30.5</span> sec</span><br><span class="line">epoch  <span class="number">30</span>, loss <span class="number">0.2614</span>, train acc <span class="number">0.900</span>, test acc <span class="number">0.895</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">31</span>, loss <span class="number">0.2662</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.891</span>, time <span class="number">30.6</span> sec</span><br><span class="line">epoch  <span class="number">32</span>, loss <span class="number">0.2514</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.897</span>, time <span class="number">30.5</span> sec</span><br><span class="line">epoch  <span class="number">33</span>, loss <span class="number">0.2514</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.900</span>, time <span class="number">30.4</span> sec</span><br><span class="line">epoch  <span class="number">34</span>, loss <span class="number">0.2327</span>, train acc <span class="number">0.911</span>, test acc <span class="number">0.901</span>, time <span class="number">30.6</span> sec</span><br><span class="line">epoch  <span class="number">35</span>, loss <span class="number">0.2309</span>, train acc <span class="number">0.912</span>, test acc <span class="number">0.903</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">36</span>, loss <span class="number">0.2287</span>, train acc <span class="number">0.912</span>, test acc <span class="number">0.898</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">37</span>, loss <span class="number">0.2253</span>, train acc <span class="number">0.914</span>, test acc <span class="number">0.900</span>, time <span class="number">30.7</span> sec</span><br><span class="line">epoch  <span class="number">38</span>, loss nan, train acc <span class="number">0.597</span>, test acc <span class="number">0.100</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">39</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch  <span class="number">40</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">41</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">42</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">43</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">44</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch  <span class="number">45</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch  <span class="number">46</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">47</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">48</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch  <span class="number">49</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch  <span class="number">50</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch  <span class="number">51</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">52</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">53</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch  <span class="number">54</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch  <span class="number">55</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">56</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch  <span class="number">57</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">58</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">59</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch  <span class="number">60</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">61</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch  <span class="number">62</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch  <span class="number">63</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch  <span class="number">64</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch  <span class="number">65</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">66</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch  <span class="number">67</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch  <span class="number">68</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">69</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">70</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">71</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">72</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch  <span class="number">73</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch  <span class="number">74</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch  <span class="number">75</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">76</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">77</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch  <span class="number">78</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch  <span class="number">79</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch  <span class="number">80</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch  <span class="number">81</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">82</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.0</span> sec</span><br><span class="line">epoch  <span class="number">83</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch  <span class="number">84</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch  <span class="number">85</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.0</span> sec</span><br><span class="line">epoch  <span class="number">86</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">87</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch  <span class="number">88</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">89</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch  <span class="number">90</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch  <span class="number">91</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch  <span class="number">92</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch  <span class="number">93</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch  <span class="number">94</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch  <span class="number">95</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch  <span class="number">96</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch  <span class="number">97</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch  <span class="number">98</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch  <span class="number">99</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch <span class="number">100</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch <span class="number">101</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch <span class="number">102</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">103</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">104</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.0</span> sec</span><br><span class="line">epoch <span class="number">105</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch <span class="number">106</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.0</span> sec</span><br><span class="line">epoch <span class="number">107</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch <span class="number">108</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch <span class="number">109</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">110</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch <span class="number">111</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">112</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch <span class="number">113</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">114</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch <span class="number">115</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch <span class="number">116</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">117</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch <span class="number">118</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch <span class="number">119</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch <span class="number">120</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">121</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">122</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch <span class="number">123</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch <span class="number">124</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch <span class="number">125</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">126</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch <span class="number">127</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch <span class="number">128</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">129</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch <span class="number">130</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">131</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch <span class="number">132</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">133</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">134</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">135</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.0</span> sec</span><br><span class="line">epoch <span class="number">136</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">137</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch <span class="number">138</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">139</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">140</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">141</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">142</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">143</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">144</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch <span class="number">145</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">146</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">147</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">148</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">149</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">150</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">151</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">152</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">153</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch <span class="number">154</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch <span class="number">155</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch <span class="number">156</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch <span class="number">157</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch <span class="number">158</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch <span class="number">159</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch <span class="number">160</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">161</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">162</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch <span class="number">163</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">164</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">165</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch <span class="number">166</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">167</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.0</span> sec</span><br><span class="line">epoch <span class="number">168</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">169</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">170</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">171</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">172</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">173</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch <span class="number">174</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">175</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch <span class="number">176</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">177</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch <span class="number">178</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch <span class="number">179</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.2</span> sec</span><br><span class="line">epoch <span class="number">180</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch <span class="number">181</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch <span class="number">182</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">183</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch <span class="number">184</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">185</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch <span class="number">186</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch <span class="number">187</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch <span class="number">188</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">189</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">190</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">191</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">192</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch <span class="number">193</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.1</span> sec</span><br><span class="line">epoch <span class="number">194</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">195</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.6</span> sec</span><br><span class="line">epoch <span class="number">196</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">197</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch <span class="number">198</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.3</span> sec</span><br><span class="line">epoch <span class="number">199</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">200</span>, loss nan, train acc <span class="number">0.100</span>, test acc <span class="number">0.100</span>, time <span class="number">29.5</span> sec</span><br><span class="line"><span class="comment"># lr = 0.05</span></span><br><span class="line"><span class="comment"># 学习率适中，然而由实验数据可得，出现循环收敛情况</span></span><br><span class="line"><span class="comment"># 但是每次循环，可以发现，训练误差越来越小</span></span><br><span class="line"><span class="comment"># 可理解为但次循环逼近局部最优解，突变不收敛增大，但之后继续继续收敛, 但每次循环更加逼近局部最优解</span></span><br><span class="line"><span class="comment"># 这一现象与学习率大小有关，学习率越小，逼近程度更高</span></span><br><span class="line">training on gpu(<span class="number">0</span>):</span><br><span class="line">epoch   <span class="number">1</span>, loss <span class="number">2.3003</span>, train acc <span class="number">0.186</span>, test acc <span class="number">0.290</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch   <span class="number">2</span>, loss <span class="number">2.2902</span>, train acc <span class="number">0.303</span>, test acc <span class="number">0.366</span>, time <span class="number">29.4</span> sec</span><br><span class="line">epoch   <span class="number">3</span>, loss <span class="number">2.2375</span>, train acc <span class="number">0.272</span>, test acc <span class="number">0.269</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch   <span class="number">4</span>, loss <span class="number">2.1884</span>, train acc <span class="number">0.221</span>, test acc <span class="number">0.306</span>, time <span class="number">29.5</span> sec</span><br><span class="line">epoch   <span class="number">5</span>, loss <span class="number">1.6043</span>, train acc <span class="number">0.381</span>, test acc <span class="number">0.557</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch   <span class="number">6</span>, loss <span class="number">1.0165</span>, train acc <span class="number">0.584</span>, test acc <span class="number">0.690</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch   <span class="number">7</span>, loss <span class="number">0.8938</span>, train acc <span class="number">0.645</span>, test acc <span class="number">0.679</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch   <span class="number">8</span>, loss <span class="number">0.7415</span>, train acc <span class="number">0.712</span>, test acc <span class="number">0.759</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch   <span class="number">9</span>, loss <span class="number">0.6586</span>, train acc <span class="number">0.748</span>, test acc <span class="number">0.775</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">10</span>, loss <span class="number">0.6061</span>, train acc <span class="number">0.770</span>, test acc <span class="number">0.776</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">11</span>, loss <span class="number">0.5721</span>, train acc <span class="number">0.785</span>, test acc <span class="number">0.807</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">12</span>, loss <span class="number">0.5282</span>, train acc <span class="number">0.799</span>, test acc <span class="number">0.812</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">13</span>, loss <span class="number">0.8901</span>, train acc <span class="number">0.721</span>, test acc <span class="number">0.187</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">14</span>, loss <span class="number">1.9727</span>, train acc <span class="number">0.324</span>, test acc <span class="number">0.307</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">15</span>, loss <span class="number">0.9870</span>, train acc <span class="number">0.629</span>, test acc <span class="number">0.752</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">16</span>, loss <span class="number">0.6531</span>, train acc <span class="number">0.752</span>, test acc <span class="number">0.794</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">17</span>, loss <span class="number">0.5645</span>, train acc <span class="number">0.788</span>, test acc <span class="number">0.816</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">18</span>, loss <span class="number">0.5092</span>, train acc <span class="number">0.809</span>, test acc <span class="number">0.833</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">19</span>, loss <span class="number">0.4741</span>, train acc <span class="number">0.823</span>, test acc <span class="number">0.844</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">20</span>, loss <span class="number">0.4490</span>, train acc <span class="number">0.832</span>, test acc <span class="number">0.849</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">21</span>, loss <span class="number">0.4191</span>, train acc <span class="number">0.843</span>, test acc <span class="number">0.854</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">22</span>, loss <span class="number">0.4022</span>, train acc <span class="number">0.849</span>, test acc <span class="number">0.861</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">23</span>, loss <span class="number">0.3884</span>, train acc <span class="number">0.856</span>, test acc <span class="number">0.851</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">24</span>, loss <span class="number">0.3807</span>, train acc <span class="number">0.859</span>, test acc <span class="number">0.863</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">25</span>, loss <span class="number">0.3618</span>, train acc <span class="number">0.864</span>, test acc <span class="number">0.870</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">26</span>, loss <span class="number">0.3511</span>, train acc <span class="number">0.868</span>, test acc <span class="number">0.857</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">27</span>, loss <span class="number">0.3423</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.876</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">28</span>, loss <span class="number">0.3302</span>, train acc <span class="number">0.877</span>, test acc <span class="number">0.878</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">29</span>, loss <span class="number">0.3270</span>, train acc <span class="number">0.877</span>, test acc <span class="number">0.877</span>, time <span class="number">30.5</span> sec</span><br><span class="line">epoch  <span class="number">30</span>, loss <span class="number">0.3198</span>, train acc <span class="number">0.879</span>, test acc <span class="number">0.875</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">31</span>, loss <span class="number">0.3094</span>, train acc <span class="number">0.883</span>, test acc <span class="number">0.882</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">32</span>, loss <span class="number">0.2998</span>, train acc <span class="number">0.886</span>, test acc <span class="number">0.883</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">33</span>, loss <span class="number">0.2976</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.879</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">34</span>, loss <span class="number">0.2883</span>, train acc <span class="number">0.891</span>, test acc <span class="number">0.886</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">35</span>, loss <span class="number">0.2865</span>, train acc <span class="number">0.890</span>, test acc <span class="number">0.886</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">36</span>, loss <span class="number">0.2759</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.883</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">37</span>, loss <span class="number">0.2776</span>, train acc <span class="number">0.894</span>, test acc <span class="number">0.890</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">38</span>, loss <span class="number">0.2702</span>, train acc <span class="number">0.898</span>, test acc <span class="number">0.885</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">39</span>, loss <span class="number">0.6599</span>, train acc <span class="number">0.769</span>, test acc <span class="number">0.853</span>, time <span class="number">30.4</span> sec</span><br><span class="line">epoch  <span class="number">40</span>, loss <span class="number">0.3453</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.887</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">41</span>, loss <span class="number">0.2877</span>, train acc <span class="number">0.892</span>, test acc <span class="number">0.884</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">42</span>, loss <span class="number">0.2640</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.891</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">43</span>, loss <span class="number">0.2652</span>, train acc <span class="number">0.900</span>, test acc <span class="number">0.896</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">44</span>, loss <span class="number">1.0945</span>, train acc <span class="number">0.625</span>, test acc <span class="number">0.771</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">45</span>, loss <span class="number">0.4668</span>, train acc <span class="number">0.824</span>, test acc <span class="number">0.865</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">46</span>, loss <span class="number">0.3392</span>, train acc <span class="number">0.873</span>, test acc <span class="number">0.876</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">47</span>, loss <span class="number">0.3065</span>, train acc <span class="number">0.885</span>, test acc <span class="number">0.886</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">48</span>, loss <span class="number">0.2955</span>, train acc <span class="number">0.889</span>, test acc <span class="number">0.879</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">49</span>, loss <span class="number">0.2719</span>, train acc <span class="number">0.897</span>, test acc <span class="number">0.884</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">50</span>, loss <span class="number">0.2648</span>, train acc <span class="number">0.900</span>, test acc <span class="number">0.889</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">51</span>, loss <span class="number">0.2611</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.894</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">52</span>, loss <span class="number">0.2479</span>, train acc <span class="number">0.906</span>, test acc <span class="number">0.893</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">53</span>, loss <span class="number">0.2422</span>, train acc <span class="number">0.908</span>, test acc <span class="number">0.893</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">54</span>, loss <span class="number">0.2358</span>, train acc <span class="number">0.911</span>, test acc <span class="number">0.893</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">55</span>, loss <span class="number">0.2271</span>, train acc <span class="number">0.913</span>, test acc <span class="number">0.897</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">56</span>, loss <span class="number">0.2275</span>, train acc <span class="number">0.913</span>, test acc <span class="number">0.896</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">57</span>, loss <span class="number">0.2155</span>, train acc <span class="number">0.918</span>, test acc <span class="number">0.890</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">58</span>, loss <span class="number">0.2200</span>, train acc <span class="number">0.917</span>, test acc <span class="number">0.896</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">59</span>, loss <span class="number">0.2058</span>, train acc <span class="number">0.921</span>, test acc <span class="number">0.892</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">60</span>, loss <span class="number">0.2058</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.900</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">61</span>, loss <span class="number">0.1935</span>, train acc <span class="number">0.927</span>, test acc <span class="number">0.893</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">62</span>, loss <span class="number">0.2005</span>, train acc <span class="number">0.925</span>, test acc <span class="number">0.893</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">63</span>, loss <span class="number">0.1846</span>, train acc <span class="number">0.929</span>, test acc <span class="number">0.901</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">64</span>, loss <span class="number">0.1840</span>, train acc <span class="number">0.931</span>, test acc <span class="number">0.899</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">65</span>, loss <span class="number">0.1749</span>, train acc <span class="number">0.933</span>, test acc <span class="number">0.898</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">66</span>, loss <span class="number">0.2420</span>, train acc <span class="number">0.914</span>, test acc <span class="number">0.897</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">67</span>, loss <span class="number">0.1775</span>, train acc <span class="number">0.933</span>, test acc <span class="number">0.891</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">68</span>, loss <span class="number">0.1617</span>, train acc <span class="number">0.938</span>, test acc <span class="number">0.900</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">69</span>, loss <span class="number">0.1630</span>, train acc <span class="number">0.937</span>, test acc <span class="number">0.897</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">70</span>, loss <span class="number">0.1605</span>, train acc <span class="number">0.939</span>, test acc <span class="number">0.900</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">71</span>, loss <span class="number">0.1569</span>, train acc <span class="number">0.939</span>, test acc <span class="number">0.897</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">72</span>, loss <span class="number">0.1481</span>, train acc <span class="number">0.942</span>, test acc <span class="number">0.900</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">73</span>, loss <span class="number">0.2770</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.898</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">74</span>, loss <span class="number">0.1559</span>, train acc <span class="number">0.940</span>, test acc <span class="number">0.902</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">75</span>, loss <span class="number">0.1339</span>, train acc <span class="number">0.948</span>, test acc <span class="number">0.899</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">76</span>, loss <span class="number">0.1275</span>, train acc <span class="number">0.952</span>, test acc <span class="number">0.899</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">77</span>, loss <span class="number">0.8637</span>, train acc <span class="number">0.750</span>, test acc <span class="number">0.288</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch  <span class="number">78</span>, loss <span class="number">1.5166</span>, train acc <span class="number">0.407</span>, test acc <span class="number">0.680</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">79</span>, loss <span class="number">0.7373</span>, train acc <span class="number">0.713</span>, test acc <span class="number">0.771</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">80</span>, loss <span class="number">0.5596</span>, train acc <span class="number">0.787</span>, test acc <span class="number">0.801</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">81</span>, loss <span class="number">0.4604</span>, train acc <span class="number">0.826</span>, test acc <span class="number">0.849</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">82</span>, loss <span class="number">0.4002</span>, train acc <span class="number">0.849</span>, test acc <span class="number">0.862</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">83</span>, loss <span class="number">0.3632</span>, train acc <span class="number">0.861</span>, test acc <span class="number">0.866</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">84</span>, loss <span class="number">0.3530</span>, train acc <span class="number">0.866</span>, test acc <span class="number">0.868</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">85</span>, loss <span class="number">0.3164</span>, train acc <span class="number">0.880</span>, test acc <span class="number">0.875</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch  <span class="number">86</span>, loss <span class="number">0.2966</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.880</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">87</span>, loss <span class="number">0.2817</span>, train acc <span class="number">0.894</span>, test acc <span class="number">0.883</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">88</span>, loss <span class="number">0.2684</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.876</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">89</span>, loss <span class="number">0.2589</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.886</span>, time <span class="number">29.7</span> sec</span><br><span class="line">epoch  <span class="number">90</span>, loss <span class="number">0.2498</span>, train acc <span class="number">0.904</span>, test acc <span class="number">0.888</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">91</span>, loss <span class="number">0.2329</span>, train acc <span class="number">0.911</span>, test acc <span class="number">0.889</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch  <span class="number">92</span>, loss <span class="number">0.2262</span>, train acc <span class="number">0.913</span>, test acc <span class="number">0.885</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch  <span class="number">93</span>, loss <span class="number">0.2192</span>, train acc <span class="number">0.916</span>, test acc <span class="number">0.889</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">94</span>, loss <span class="number">0.2065</span>, train acc <span class="number">0.920</span>, test acc <span class="number">0.888</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">95</span>, loss <span class="number">0.1980</span>, train acc <span class="number">0.924</span>, test acc <span class="number">0.888</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">96</span>, loss <span class="number">0.3008</span>, train acc <span class="number">0.893</span>, test acc <span class="number">0.885</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">97</span>, loss <span class="number">0.2022</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.890</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch  <span class="number">98</span>, loss <span class="number">0.1815</span>, train acc <span class="number">0.930</span>, test acc <span class="number">0.891</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch  <span class="number">99</span>, loss <span class="number">0.1708</span>, train acc <span class="number">0.934</span>, test acc <span class="number">0.885</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">100</span>, loss <span class="number">0.1677</span>, train acc <span class="number">0.935</span>, test acc <span class="number">0.887</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">101</span>, loss <span class="number">0.1568</span>, train acc <span class="number">0.939</span>, test acc <span class="number">0.893</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch <span class="number">102</span>, loss <span class="number">0.1474</span>, train acc <span class="number">0.944</span>, test acc <span class="number">0.884</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">103</span>, loss <span class="number">1.7684</span>, train acc <span class="number">0.468</span>, test acc <span class="number">0.274</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">104</span>, loss <span class="number">1.9524</span>, train acc <span class="number">0.255</span>, test acc <span class="number">0.424</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">105</span>, loss <span class="number">1.1871</span>, train acc <span class="number">0.536</span>, test acc <span class="number">0.676</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">106</span>, loss <span class="number">0.8104</span>, train acc <span class="number">0.683</span>, test acc <span class="number">0.721</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">107</span>, loss <span class="number">0.6903</span>, train acc <span class="number">0.735</span>, test acc <span class="number">0.780</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">108</span>, loss <span class="number">0.5807</span>, train acc <span class="number">0.779</span>, test acc <span class="number">0.803</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">109</span>, loss <span class="number">0.5175</span>, train acc <span class="number">0.803</span>, test acc <span class="number">0.839</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch <span class="number">110</span>, loss <span class="number">0.4664</span>, train acc <span class="number">0.824</span>, test acc <span class="number">0.847</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">111</span>, loss <span class="number">0.4257</span>, train acc <span class="number">0.839</span>, test acc <span class="number">0.853</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">112</span>, loss <span class="number">0.3951</span>, train acc <span class="number">0.852</span>, test acc <span class="number">0.863</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">113</span>, loss <span class="number">0.3752</span>, train acc <span class="number">0.859</span>, test acc <span class="number">0.867</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">114</span>, loss <span class="number">0.3572</span>, train acc <span class="number">0.865</span>, test acc <span class="number">0.869</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch <span class="number">115</span>, loss <span class="number">0.3391</span>, train acc <span class="number">0.871</span>, test acc <span class="number">0.878</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">116</span>, loss <span class="number">0.3298</span>, train acc <span class="number">0.875</span>, test acc <span class="number">0.878</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">117</span>, loss <span class="number">0.3201</span>, train acc <span class="number">0.879</span>, test acc <span class="number">0.881</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">118</span>, loss <span class="number">0.3082</span>, train acc <span class="number">0.884</span>, test acc <span class="number">0.877</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch <span class="number">119</span>, loss <span class="number">0.2994</span>, train acc <span class="number">0.887</span>, test acc <span class="number">0.884</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">120</span>, loss <span class="number">0.2915</span>, train acc <span class="number">0.890</span>, test acc <span class="number">0.887</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">121</span>, loss <span class="number">0.2861</span>, train acc <span class="number">0.892</span>, test acc <span class="number">0.888</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">122</span>, loss <span class="number">0.2766</span>, train acc <span class="number">0.896</span>, test acc <span class="number">0.889</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">123</span>, loss <span class="number">0.2759</span>, train acc <span class="number">0.895</span>, test acc <span class="number">0.887</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">124</span>, loss <span class="number">0.2654</span>, train acc <span class="number">0.899</span>, test acc <span class="number">0.889</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">125</span>, loss <span class="number">0.2549</span>, train acc <span class="number">0.903</span>, test acc <span class="number">0.889</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">126</span>, loss <span class="number">0.2557</span>, train acc <span class="number">0.903</span>, test acc <span class="number">0.888</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">127</span>, loss <span class="number">0.2459</span>, train acc <span class="number">0.905</span>, test acc <span class="number">0.890</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">128</span>, loss <span class="number">0.2405</span>, train acc <span class="number">0.908</span>, test acc <span class="number">0.893</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">129</span>, loss <span class="number">0.9341</span>, train acc <span class="number">0.683</span>, test acc <span class="number">0.859</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">130</span>, loss <span class="number">0.3582</span>, train acc <span class="number">0.866</span>, test acc <span class="number">0.872</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">131</span>, loss <span class="number">0.3120</span>, train acc <span class="number">0.883</span>, test acc <span class="number">0.879</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">132</span>, loss <span class="number">0.2901</span>, train acc <span class="number">0.889</span>, test acc <span class="number">0.889</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">133</span>, loss <span class="number">0.2712</span>, train acc <span class="number">0.897</span>, test acc <span class="number">0.889</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">134</span>, loss <span class="number">0.2628</span>, train acc <span class="number">0.901</span>, test acc <span class="number">0.891</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">135</span>, loss <span class="number">0.2497</span>, train acc <span class="number">0.905</span>, test acc <span class="number">0.891</span>, time <span class="number">30.4</span> sec</span><br><span class="line">epoch <span class="number">136</span>, loss <span class="number">0.2393</span>, train acc <span class="number">0.909</span>, test acc <span class="number">0.894</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">137</span>, loss <span class="number">0.2339</span>, train acc <span class="number">0.912</span>, test acc <span class="number">0.899</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">138</span>, loss <span class="number">0.2277</span>, train acc <span class="number">0.913</span>, test acc <span class="number">0.893</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">139</span>, loss <span class="number">0.2179</span>, train acc <span class="number">0.918</span>, test acc <span class="number">0.897</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">140</span>, loss <span class="number">0.2136</span>, train acc <span class="number">0.918</span>, test acc <span class="number">0.901</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">141</span>, loss <span class="number">0.2068</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.902</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">142</span>, loss <span class="number">0.1987</span>, train acc <span class="number">0.925</span>, test acc <span class="number">0.900</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">143</span>, loss <span class="number">0.1910</span>, train acc <span class="number">0.927</span>, test acc <span class="number">0.900</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">144</span>, loss <span class="number">0.2195</span>, train acc <span class="number">0.920</span>, test acc <span class="number">0.308</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">145</span>, loss <span class="number">0.6532</span>, train acc <span class="number">0.775</span>, test acc <span class="number">0.879</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">146</span>, loss <span class="number">0.2677</span>, train acc <span class="number">0.898</span>, test acc <span class="number">0.890</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">147</span>, loss <span class="number">0.2322</span>, train acc <span class="number">0.911</span>, test acc <span class="number">0.887</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">148</span>, loss <span class="number">0.2168</span>, train acc <span class="number">0.917</span>, test acc <span class="number">0.898</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">149</span>, loss <span class="number">0.2022</span>, train acc <span class="number">0.924</span>, test acc <span class="number">0.901</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">150</span>, loss <span class="number">0.1907</span>, train acc <span class="number">0.927</span>, test acc <span class="number">0.903</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">151</span>, loss <span class="number">0.1824</span>, train acc <span class="number">0.929</span>, test acc <span class="number">0.904</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">152</span>, loss <span class="number">0.1769</span>, train acc <span class="number">0.932</span>, test acc <span class="number">0.901</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">153</span>, loss <span class="number">0.1690</span>, train acc <span class="number">0.935</span>, test acc <span class="number">0.905</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">154</span>, loss <span class="number">0.1654</span>, train acc <span class="number">0.937</span>, test acc <span class="number">0.903</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">155</span>, loss <span class="number">0.1585</span>, train acc <span class="number">0.939</span>, test acc <span class="number">0.905</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">156</span>, loss <span class="number">0.1480</span>, train acc <span class="number">0.943</span>, test acc <span class="number">0.898</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">157</span>, loss <span class="number">0.1466</span>, train acc <span class="number">0.943</span>, test acc <span class="number">0.905</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">158</span>, loss <span class="number">0.1392</span>, train acc <span class="number">0.946</span>, test acc <span class="number">0.900</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">159</span>, loss <span class="number">0.1303</span>, train acc <span class="number">0.950</span>, test acc <span class="number">0.902</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">160</span>, loss <span class="number">0.1284</span>, train acc <span class="number">0.951</span>, test acc <span class="number">0.897</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">161</span>, loss <span class="number">0.1290</span>, train acc <span class="number">0.950</span>, test acc <span class="number">0.900</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">162</span>, loss <span class="number">0.1558</span>, train acc <span class="number">0.944</span>, test acc <span class="number">0.907</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">163</span>, loss <span class="number">0.1078</span>, train acc <span class="number">0.959</span>, test acc <span class="number">0.906</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">164</span>, loss <span class="number">0.1217</span>, train acc <span class="number">0.953</span>, test acc <span class="number">0.904</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">165</span>, loss <span class="number">0.0972</span>, train acc <span class="number">0.962</span>, test acc <span class="number">0.901</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">166</span>, loss <span class="number">0.0936</span>, train acc <span class="number">0.964</span>, test acc <span class="number">0.895</span>, time <span class="number">30.3</span> sec</span><br><span class="line">epoch <span class="number">167</span>, loss <span class="number">0.1055</span>, train acc <span class="number">0.961</span>, test acc <span class="number">0.895</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">168</span>, loss <span class="number">0.0889</span>, train acc <span class="number">0.966</span>, test acc <span class="number">0.901</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">169</span>, loss <span class="number">0.0915</span>, train acc <span class="number">0.967</span>, test acc <span class="number">0.904</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">170</span>, loss <span class="number">1.2126</span>, train acc <span class="number">0.586</span>, test acc <span class="number">0.698</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">171</span>, loss <span class="number">0.5554</span>, train acc <span class="number">0.791</span>, test acc <span class="number">0.846</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">172</span>, loss <span class="number">0.3570</span>, train acc <span class="number">0.864</span>, test acc <span class="number">0.878</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">173</span>, loss <span class="number">0.3000</span>, train acc <span class="number">0.885</span>, test acc <span class="number">0.887</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">174</span>, loss <span class="number">0.2677</span>, train acc <span class="number">0.898</span>, test acc <span class="number">0.890</span>, time <span class="number">30.4</span> sec</span><br><span class="line">epoch <span class="number">175</span>, loss <span class="number">0.2418</span>, train acc <span class="number">0.908</span>, test acc <span class="number">0.894</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">176</span>, loss <span class="number">0.2261</span>, train acc <span class="number">0.913</span>, test acc <span class="number">0.893</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">177</span>, loss <span class="number">0.2012</span>, train acc <span class="number">0.922</span>, test acc <span class="number">0.897</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">178</span>, loss <span class="number">0.1879</span>, train acc <span class="number">0.928</span>, test acc <span class="number">0.900</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch <span class="number">179</span>, loss <span class="number">0.1736</span>, train acc <span class="number">0.933</span>, test acc <span class="number">0.901</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">180</span>, loss <span class="number">0.1667</span>, train acc <span class="number">0.935</span>, test acc <span class="number">0.892</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch <span class="number">181</span>, loss <span class="number">0.1527</span>, train acc <span class="number">0.942</span>, test acc <span class="number">0.903</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">182</span>, loss <span class="number">0.1445</span>, train acc <span class="number">0.944</span>, test acc <span class="number">0.899</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">183</span>, loss <span class="number">0.1343</span>, train acc <span class="number">0.948</span>, test acc <span class="number">0.897</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">184</span>, loss <span class="number">0.1201</span>, train acc <span class="number">0.953</span>, test acc <span class="number">0.898</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">185</span>, loss <span class="number">0.1206</span>, train acc <span class="number">0.954</span>, test acc <span class="number">0.899</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">186</span>, loss <span class="number">0.1038</span>, train acc <span class="number">0.960</span>, test acc <span class="number">0.898</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">187</span>, loss <span class="number">0.1244</span>, train acc <span class="number">0.954</span>, test acc <span class="number">0.903</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">188</span>, loss <span class="number">0.0979</span>, train acc <span class="number">0.962</span>, test acc <span class="number">0.898</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">189</span>, loss <span class="number">0.0980</span>, train acc <span class="number">0.963</span>, test acc <span class="number">0.901</span>, time <span class="number">30.2</span> sec</span><br><span class="line">epoch <span class="number">190</span>, loss <span class="number">0.1009</span>, train acc <span class="number">0.964</span>, test acc <span class="number">0.903</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">191</span>, loss <span class="number">0.0732</span>, train acc <span class="number">0.972</span>, test acc <span class="number">0.901</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">192</span>, loss <span class="number">0.0732</span>, train acc <span class="number">0.973</span>, test acc <span class="number">0.899</span>, time <span class="number">29.9</span> sec</span><br><span class="line">epoch <span class="number">193</span>, loss <span class="number">0.0720</span>, train acc <span class="number">0.973</span>, test acc <span class="number">0.894</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">194</span>, loss <span class="number">0.0822</span>, train acc <span class="number">0.970</span>, test acc <span class="number">0.901</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">195</span>, loss <span class="number">0.1778</span>, train acc <span class="number">0.942</span>, test acc <span class="number">0.874</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">196</span>, loss <span class="number">0.1346</span>, train acc <span class="number">0.948</span>, test acc <span class="number">0.901</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">197</span>, loss <span class="number">0.0698</span>, train acc <span class="number">0.975</span>, test acc <span class="number">0.897</span>, time <span class="number">30.0</span> sec</span><br><span class="line">epoch <span class="number">198</span>, loss <span class="number">0.0584</span>, train acc <span class="number">0.979</span>, test acc <span class="number">0.898</span>, time <span class="number">29.8</span> sec</span><br><span class="line">epoch <span class="number">199</span>, loss <span class="number">0.0522</span>, train acc <span class="number">0.983</span>, test acc <span class="number">0.903</span>, time <span class="number">30.1</span> sec</span><br><span class="line">epoch <span class="number">200</span>, loss <span class="number">0.0472</span>, train acc <span class="number">0.983</span>, test acc <span class="number">0.902</span>, time <span class="number">30.0</span> sec</span><br></pre></td></tr></tbody></table></figure>
<h2 id="批量归一化（Batch-Normalization）"><a href="#批量归一化（Batch-Normalization）" class="headerlink" title="批量归一化（Batch Normalization）"></a>批量归一化（Batch Normalization）</h2><table>
<thead>
<tr>
<th align="center">类型</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">数据标准化</td>
<td align="left">适用于浅层模型，模型训练时，当每层中参数更新时，靠近输出层的输出较难出现剧烈变化</td>
</tr>
<tr>
<td align="center">批量归一化</td>
<td align="left">适用于深层模型，即使输入数据已做标准化，训练中模型参数的更新依然很容易造成靠近输出层输出的剧烈变化。<br>模型训练时，利用小批量上的均值和标准差，不断调整神经网络中间输出，从而使整个神经网络在各层的中间输出的数值更稳定</td>
</tr>
</tbody></table>
<h3 id="原生实现"><a href="#原生实现" class="headerlink" title="原生实现"></a>原生实现</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, gluon, init, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn, data <span class="keyword">as</span> gdata, loss <span class="keyword">as</span> gloss</span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_norm</span><span class="params">(X, gamma, beta, moving_mean, moving_var, eps, momentum)</span>:</span></span><br><span class="line">    <span class="comment"># 通过autograd来判断当前模式是训练模式还是预测模式</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> autograd.is_training():</span><br><span class="line">        <span class="comment"># 如果在预测模式下，直接使用转入的移动平均所得的均值和方差</span></span><br><span class="line">        X_hat = (X - moving_mean) / nd.sqrt(moving_var + eps)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">assert</span> len(X.shape) <span class="keyword">in</span> (<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">        <span class="keyword">if</span> len(X.shape) == <span class="number">2</span>:</span><br><span class="line">            <span class="comment"># 使用全连接层的情况， 计算特征维上的均值和方差</span></span><br><span class="line">            mean = X.mean(axis=<span class="number">0</span>)</span><br><span class="line">            var = ((X - mean) ** <span class="number">2</span>).mean(axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。</span></span><br><span class="line">            <span class="comment"># 这里我们需要保持X的形状以便后面可以做广播运算</span></span><br><span class="line">            mean = X.mean(axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">            var = ((X - mean) ** <span class="number">2</span>).mean(axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 训练模式下用当前的均值和方差做标准化</span></span><br><span class="line">        X_hat = (X - mean) / nd.sqrt(var + eps)</span><br><span class="line">        <span class="comment"># 更新移动平均的均值和方差</span></span><br><span class="line">        moving_mean = momentum * moving_mean + (<span class="number">1.0</span> - momentum) * mean</span><br><span class="line">        moving_var = momentum * moving_var + (<span class="number">1.0</span> - momentum) * var</span><br><span class="line">    Y = gamma * X_hat + beta  <span class="comment"># 拉伸和偏移</span></span><br><span class="line">    <span class="keyword">return</span> Y, moving_mean, moving_var</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line"><span class="comment"># Y = nd.random.uniform(shape=(2, 2, 3, 3))</span></span><br><span class="line"><span class="comment"># print(Y.shape)</span></span><br><span class="line"><span class="comment"># print(Y)</span></span><br><span class="line"><span class="comment"># print(Y.mean(axis=(0, 2, 3), keepdims=True))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BatchNorm</span><span class="params">(nn.Block)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_features, num_dims, **kwargs)</span>:</span></span><br><span class="line">        super(BatchNorm, self).__init__(**kwargs)</span><br><span class="line">        <span class="keyword">if</span> num_dims == <span class="number">2</span>:</span><br><span class="line">            shape = (<span class="number">1</span>, num_features)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            shape = (<span class="number">1</span>, num_features, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 参与求梯度和迭代的拉伸和偏移参数，分别初始化为0和1</span></span><br><span class="line">        self.gamma = self.params.get(<span class="string">'gamma'</span>, shape=shape, init=init.One())</span><br><span class="line">        self.beta = self.params.get(<span class="string">'beta'</span>, shape=shape, init=init.Zero())</span><br><span class="line">        <span class="comment"># 不参与求梯度和迭代的变量，全在内存上初始化为0</span></span><br><span class="line">        self.moving_mean = nd.zeros(shape)</span><br><span class="line">        self.moving_var = nd.zeros(shape)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="comment"># 如果X不在内存上，将moving_mean和moving_var复制到X所在显存上</span></span><br><span class="line">        <span class="keyword">if</span> self.moving_mean.context != X.context:</span><br><span class="line">            self.moving_mean = self.moving_mean.copyto(X.context)</span><br><span class="line">            self.moving_var = self.moving_var.copyto(X.context)</span><br><span class="line">        <span class="comment"># 保存更新过的moving_mean和moving_var</span></span><br><span class="line">        print(<span class="string">'X shape:'</span>, X.shape)</span><br><span class="line">        print(<span class="string">'X:'</span>, X)</span><br><span class="line">        Y, self.moving_mean, self.moving_var = batch_norm(</span><br><span class="line">            X, self.gamma.data(), self.beta.data(), self.moving_mean,</span><br><span class="line">            self.moving_var, eps=<span class="number">1</span>e - <span class="number">5</span>, momentum=<span class="number">0.5</span>)</span><br><span class="line">        <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = nn.Sequential()</span><br><span class="line">net.add(nn.Conv2D(<span class="number">6</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">        BatchNorm(<span class="number">6</span>, num_dims=<span class="number">4</span>),</span><br><span class="line">        nn.Activation(<span class="string">'sigmoid'</span>),</span><br><span class="line">        nn.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>),</span><br><span class="line"></span><br><span class="line">        nn.Conv2D(<span class="number">16</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">        BatchNorm(<span class="number">16</span>, num_dims=<span class="number">4</span>),</span><br><span class="line">        nn.Activation(<span class="string">'sigmoid'</span>),</span><br><span class="line">        nn.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>),</span><br><span class="line"></span><br><span class="line">        nn.Dense(<span class="number">120</span>),</span><br><span class="line">        BatchNorm(<span class="number">120</span>, num_dims=<span class="number">2</span>),</span><br><span class="line">        nn.Activation(<span class="string">'sigmoid'</span>),</span><br><span class="line"></span><br><span class="line">        nn.Dense(<span class="number">84</span>),</span><br><span class="line">        BatchNorm(<span class="number">84</span>, num_dims=<span class="number">2</span>),</span><br><span class="line">        nn.Activation(<span class="string">'sigmoid'</span>),</span><br><span class="line"></span><br><span class="line">        nn.Dense(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ctx = mx.gpu(<span class="number">3</span>)</span><br><span class="line">        _ = nd.array((<span class="number">1</span>,), ctx=ctx)</span><br><span class="line">    <span class="keyword">except</span> mx.base.MXNetError:</span><br><span class="line">        ctx = mx.cpu()</span><br><span class="line">    <span class="keyword">return</span> ctx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span><span class="params">(batch_size, resize=None, root=os.path.join<span class="params">(<span class="string">'-'</span>, <span class="string">'mxnet'</span>, <span class="string">'datasets'</span>, <span class="string">'fashion-mnist'</span>)</span>)</span>:</span></span><br><span class="line">    root = os.path.expanduser(root)</span><br><span class="line">    transformer = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        transformer += [gdata.vision.transforms.Resize(resize)]</span><br><span class="line">    transformer += [gdata.vision.transforms.ToTensor()]</span><br><span class="line">    transformer = gdata.vision.transforms.Compose(transformer)</span><br><span class="line"></span><br><span class="line">    mnist_train = gdata.vision.FashionMNIST(root=root, train=<span class="literal">True</span>)</span><br><span class="line">    mnist_test = gdata.vision.FashionMNIST(root=root, train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    num_workers = <span class="number">0</span> <span class="keyword">if</span> sys.platform.startswith(<span class="string">'win'</span>) <span class="keyword">else</span> <span class="number">4</span></span><br><span class="line">    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),</span><br><span class="line">                                  batch_size=batch_size,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  num_workers=num_workers)</span><br><span class="line">    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),</span><br><span class="line">                                 batch_size=batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=num_workers)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(net, data_iter, ctx)</span>:</span></span><br><span class="line">    acc_sum, n = nd.array([<span class="number">0</span>], ctx=ctx), <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype(<span class="string">'float32'</span>)</span><br><span class="line">        y_hat = net(X)</span><br><span class="line">        acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum()</span><br><span class="line">        n += y.size</span><br><span class="line">    <span class="keyword">return</span> acc_sum.asscalar() / n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span>:</span></span><br><span class="line">    print(<span class="string">"training on "</span>, ctx)</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X, y = X.as_in_context(ctx), y.as_in_context(ctx)</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            trainer.step(batch_size)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y.astype(<span class="string">'float32'</span>)).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(net, test_iter, ctx)</span><br><span class="line">        print(<span class="string">'epoch %3d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr, num_epochs, batch_size, ctx = <span class="number">1.0</span>, <span class="number">5</span>, <span class="number">256</span>, try_gpu()</span><br><span class="line">net.initialize(ctx=ctx, init=init.Xavier())</span><br><span class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">'sgd'</span>, {<span class="string">'learning_rate'</span>: lr})</span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size)</span><br><span class="line">train(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># x = nd.random.uniform(shape=(4, 2, 28, 28))</span></span><br><span class="line"><span class="comment"># for layer in net:</span></span><br><span class="line"><span class="comment">#     with autograd.record():</span></span><br><span class="line"><span class="comment">#         x = layer(x)</span></span><br><span class="line"><span class="comment">#         print(x.shape)</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="简洁实现"><a href="#简洁实现" class="headerlink" title="简洁实现"></a>简洁实现</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, gluon, init, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn, data <span class="keyword">as</span> gdata, loss <span class="keyword">as</span> gloss</span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">net = nn.Sequential()</span><br><span class="line">net.add(nn.Conv2D(<span class="number">6</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">        nn.BatchNorm(),</span><br><span class="line">        nn.Activation(<span class="string">'sigmoid'</span>),</span><br><span class="line">        nn.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>),</span><br><span class="line"></span><br><span class="line">        nn.Conv2D(<span class="number">16</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">        nn.BatchNorm(),</span><br><span class="line">        nn.Activation(<span class="string">'sigmoid'</span>),</span><br><span class="line">        nn.MaxPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>),</span><br><span class="line"></span><br><span class="line">        nn.Dense(<span class="number">120</span>),</span><br><span class="line">        nn.BatchNorm(),</span><br><span class="line">        nn.Activation(<span class="string">'sigmoid'</span>),</span><br><span class="line"></span><br><span class="line">        nn.Dense(<span class="number">84</span>),</span><br><span class="line">        nn.BatchNorm(),</span><br><span class="line">        nn.Activation(<span class="string">'sigmoid'</span>),</span><br><span class="line"></span><br><span class="line">        nn.Dense(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ctx = mx.gpu(<span class="number">3</span>)</span><br><span class="line">        _ = nd.array((<span class="number">1</span>,), ctx=ctx)</span><br><span class="line">    <span class="keyword">except</span> mx.base.MXNetError:</span><br><span class="line">        ctx = mx.cpu()</span><br><span class="line">    <span class="keyword">return</span> ctx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span><span class="params">(batch_size, resize=None, root=os.path.join<span class="params">(<span class="string">'-'</span>, <span class="string">'mxnet'</span>, <span class="string">'datasets'</span>, <span class="string">'fashion-mnist'</span>)</span>)</span>:</span></span><br><span class="line">    root = os.path.expanduser(root)</span><br><span class="line">    transformer = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        transformer += [gdata.vision.transforms.Resize(resize)]</span><br><span class="line">    transformer += [gdata.vision.transforms.ToTensor()]</span><br><span class="line">    transformer = gdata.vision.transforms.Compose(transformer)</span><br><span class="line"></span><br><span class="line">    mnist_train = gdata.vision.FashionMNIST(root=root, train=<span class="literal">True</span>)</span><br><span class="line">    mnist_test = gdata.vision.FashionMNIST(root=root, train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    num_workers = <span class="number">0</span> <span class="keyword">if</span> sys.platform.startswith(<span class="string">'win'</span>) <span class="keyword">else</span> <span class="number">4</span></span><br><span class="line">    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),</span><br><span class="line">                                  batch_size=batch_size,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  num_workers=num_workers)</span><br><span class="line">    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),</span><br><span class="line">                                 batch_size=batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=num_workers)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(net, data_iter, ctx)</span>:</span></span><br><span class="line">    acc_sum, n = nd.array([<span class="number">0</span>], ctx=ctx), <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype(<span class="string">'float32'</span>)</span><br><span class="line">        y_hat = net(X)</span><br><span class="line">        acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum()</span><br><span class="line">        n += y.size</span><br><span class="line">    <span class="keyword">return</span> acc_sum.asscalar() / n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span>:</span></span><br><span class="line">    print(<span class="string">"training on "</span>, ctx)</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X, y = X.as_in_context(ctx), y.as_in_context(ctx)</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            trainer.step(batch_size)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y.astype(<span class="string">'float32'</span>)).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(net, test_iter, ctx)</span><br><span class="line">        print(<span class="string">'epoch %3d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr, num_epochs, batch_size, ctx = <span class="number">1.0</span>, <span class="number">5</span>, <span class="number">256</span>, try_gpu()</span><br><span class="line">net.initialize(ctx=ctx, init=init.Xavier())</span><br><span class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">'sgd'</span>, {<span class="string">'learning_rate'</span>: lr})</span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size)</span><br><span class="line">train(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="残差网络（ResNet）"><a href="#残差网络（ResNet）" class="headerlink" title="残差网络（ResNet）"></a>残差网络（ResNet）</h2><table>
<thead>
<tr>
<th align="center">名称</th>
<th align="left">结构</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Residual Block</td>
<td align="left">①3×3卷积层：channels=num_channels, kernel_size=3, padding=1, strides=strides<br>②批量归一化层<br>③激活函数层<br>④3×3卷积层：channels=num_channels, kernel_size=3, padding=1, strides=strides<br>⑤批量归一化层<br>⑥（可选）1×1卷积层：channels=num_channels, kernel_size=1, strides=strides<br>⑦激活函数层</td>
</tr>
</tbody></table>
<p><img src="/assets/img/deep_learning/deep_learning_02.png" alt="Resnet图示"></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, gluon, init, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn, data <span class="keyword">as</span> gdata, loss <span class="keyword">as</span> gloss</span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Residual</span><span class="params">(nn.Block)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_channels, user_1x1conv=False, strides=<span class="number">1</span>, **kwargs)</span>:</span></span><br><span class="line">        super(Residual, self).__init__(**kwargs)</span><br><span class="line">        self.conv1 = nn.Conv2D(num_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, strides=strides)</span><br><span class="line">        self.conv2 = nn.Conv2D(num_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> user_1x1conv:</span><br><span class="line">            self.conv3 = nn.Conv2D(num_channels, kernel_size=<span class="number">1</span>, strides=strides)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv3 = <span class="literal">None</span></span><br><span class="line">        self.bn1 = nn.BatchNorm()</span><br><span class="line">        self.bn2 = nn.BatchNorm()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        Y = nd.relu(self.bn1(self.conv1(X)))</span><br><span class="line">        Y = self.bn2(self.conv2(Y))</span><br><span class="line">        <span class="keyword">if</span> self.conv3:</span><br><span class="line">            X = self.conv3(X)</span><br><span class="line">        <span class="keyword">return</span> nd.relu(Y + X)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># blk = Residual(3)</span></span><br><span class="line"><span class="comment"># blk.initialize()</span></span><br><span class="line"><span class="comment"># X = nd.random.uniform(shape=(4, 3, 6, 6))</span></span><br><span class="line"><span class="comment"># print(blk(X).shape)</span></span><br><span class="line"></span><br><span class="line">net = nn.Sequential()</span><br><span class="line">net.add(nn.Conv2D(<span class="number">64</span>, kernel_size=<span class="number">7</span>, strides=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">        nn.BatchNorm(),</span><br><span class="line">        nn.Activation(<span class="string">'relu'</span>),</span><br><span class="line">        nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet_block</span><span class="params">(num_channels, num_residuals, first_block=False)</span>:</span></span><br><span class="line">    blk = nn.Sequential()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_residuals):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> first_block:</span><br><span class="line">            blk.add(Residual(num_channels, user_1x1conv=<span class="literal">True</span>, strides=<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            blk.add(Residual(num_channels))</span><br><span class="line">    <span class="keyword">return</span> blk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.add(resnet_block(<span class="number">64</span>, <span class="number">2</span>, first_block=<span class="literal">True</span>),</span><br><span class="line">        resnet_block(<span class="number">128</span>, <span class="number">2</span>),</span><br><span class="line">        resnet_block(<span class="number">256</span>, <span class="number">2</span>),</span><br><span class="line">        resnet_block(<span class="number">512</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">net.add(nn.GlobalAvgPool2D(),</span><br><span class="line">        nn.Dense(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># X = nd.random.uniform(shape=(1, 1, 224, 224))</span></span><br><span class="line"><span class="comment"># net.initialize()</span></span><br><span class="line"><span class="comment"># for layer in net:</span></span><br><span class="line"><span class="comment">#     X = layer(X)</span></span><br><span class="line"><span class="comment">#     print(layer.name, 'output shape:\t', X.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ctx = mx.gpu(<span class="number">3</span>)</span><br><span class="line">        _ = nd.array((<span class="number">1</span>,), ctx=ctx)</span><br><span class="line">    <span class="keyword">except</span> mx.base.MXNetError:</span><br><span class="line">        ctx = mx.cpu()</span><br><span class="line">    <span class="keyword">return</span> ctx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span><span class="params">(batch_size, resize=None, root=os.path.join<span class="params">(<span class="string">'-'</span>, <span class="string">'mxnet'</span>, <span class="string">'datasets'</span>, <span class="string">'fashion-mnist'</span>)</span>)</span>:</span></span><br><span class="line">    root = os.path.expanduser(root)</span><br><span class="line">    transformer = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        transformer += [gdata.vision.transforms.Resize(resize)]</span><br><span class="line">    transformer += [gdata.vision.transforms.ToTensor()]</span><br><span class="line">    transformer = gdata.vision.transforms.Compose(transformer)</span><br><span class="line"></span><br><span class="line">    mnist_train = gdata.vision.FashionMNIST(root=root, train=<span class="literal">True</span>)</span><br><span class="line">    mnist_test = gdata.vision.FashionMNIST(root=root, train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    num_workers = <span class="number">0</span> <span class="keyword">if</span> sys.platform.startswith(<span class="string">'win'</span>) <span class="keyword">else</span> <span class="number">4</span></span><br><span class="line">    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),</span><br><span class="line">                                  batch_size=batch_size,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  num_workers=num_workers)</span><br><span class="line">    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),</span><br><span class="line">                                 batch_size=batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=num_workers)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(net, data_iter, ctx)</span>:</span></span><br><span class="line">    acc_sum, n = nd.array([<span class="number">0</span>], ctx=ctx), <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype(<span class="string">'float32'</span>)</span><br><span class="line">        y_hat = net(X)</span><br><span class="line">        acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum()</span><br><span class="line">        n += y.size</span><br><span class="line">    <span class="keyword">return</span> acc_sum.asscalar() / n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span>:</span></span><br><span class="line">    print(<span class="string">"training on "</span>, ctx)</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X, y = X.as_in_context(ctx), y.as_in_context(ctx)</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            trainer.step(batch_size)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y.astype(<span class="string">'float32'</span>)).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(net, test_iter, ctx)</span><br><span class="line">        print(<span class="string">'epoch %3d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lr, num_epochs, batch_size, ctx = <span class="number">0.05</span>, <span class="number">200</span>, <span class="number">672</span>, try_gpu()</span><br><span class="line">net.initialize(force_reinit=<span class="literal">True</span>, ctx=ctx, init=init.Xavier())</span><br><span class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">'sgd'</span>, {<span class="string">'learning_rate'</span>: lr})</span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">96</span>)</span><br><span class="line">train(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各层输出形状：</span></span><br><span class="line">conv0 output shape:	 (<span class="number">1</span>, <span class="number">64</span>, <span class="number">112</span>, <span class="number">112</span>)</span><br><span class="line">batchnorm0 output shape:	 (<span class="number">1</span>, <span class="number">64</span>, <span class="number">112</span>, <span class="number">112</span>)</span><br><span class="line">relu0 output shape:	 (<span class="number">1</span>, <span class="number">64</span>, <span class="number">112</span>, <span class="number">112</span>)</span><br><span class="line">pool0 output shape:	 (<span class="number">1</span>, <span class="number">64</span>, <span class="number">56</span>, <span class="number">56</span>)</span><br><span class="line">sequential1 output shape:	 (<span class="number">1</span>, <span class="number">64</span>, <span class="number">56</span>, <span class="number">56</span>)</span><br><span class="line">sequential2 output shape:	 (<span class="number">1</span>, <span class="number">128</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">sequential3 output shape:	 (<span class="number">1</span>, <span class="number">256</span>, <span class="number">14</span>, <span class="number">14</span>)</span><br><span class="line">sequential4 output shape:	 (<span class="number">1</span>, <span class="number">512</span>, <span class="number">7</span>, <span class="number">7</span>)</span><br><span class="line">pool1 output shape:	 (<span class="number">1</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">dense0 output shape:	 (<span class="number">1</span>, <span class="number">10</span>)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br></pre></td><td class="code"><pre><span class="line">training on gpu(<span class="number">0</span>):</span><br><span class="line">epoch   <span class="number">1</span>, loss <span class="number">0.6444</span>, train acc <span class="number">0.781</span>, test acc <span class="number">0.876</span>, time <span class="number">31.4</span> sec</span><br><span class="line">epoch   <span class="number">2</span>, loss <span class="number">0.2992</span>, train acc <span class="number">0.891</span>, test acc <span class="number">0.891</span>, time <span class="number">27.0</span> sec</span><br><span class="line">epoch   <span class="number">3</span>, loss <span class="number">0.2351</span>, train acc <span class="number">0.915</span>, test acc <span class="number">0.898</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch   <span class="number">4</span>, loss <span class="number">0.1896</span>, train acc <span class="number">0.932</span>, test acc <span class="number">0.901</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch   <span class="number">5</span>, loss <span class="number">0.1576</span>, train acc <span class="number">0.944</span>, test acc <span class="number">0.907</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch   <span class="number">6</span>, loss <span class="number">0.1128</span>, train acc <span class="number">0.962</span>, test acc <span class="number">0.904</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch   <span class="number">7</span>, loss <span class="number">0.0908</span>, train acc <span class="number">0.970</span>, test acc <span class="number">0.914</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch   <span class="number">8</span>, loss <span class="number">0.0590</span>, train acc <span class="number">0.983</span>, test acc <span class="number">0.912</span>, time <span class="number">27.9</span> sec</span><br><span class="line">epoch   <span class="number">9</span>, loss <span class="number">0.0388</span>, train acc <span class="number">0.990</span>, test acc <span class="number">0.915</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch  <span class="number">10</span>, loss <span class="number">0.0187</span>, train acc <span class="number">0.997</span>, test acc <span class="number">0.918</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch  <span class="number">11</span>, loss <span class="number">0.0080</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">12</span>, loss <span class="number">0.0037</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch  <span class="number">13</span>, loss <span class="number">0.0025</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch  <span class="number">14</span>, loss <span class="number">0.0020</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">15</span>, loss <span class="number">0.0017</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">16</span>, loss <span class="number">0.0014</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.921</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">17</span>, loss <span class="number">0.0012</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">18</span>, loss <span class="number">0.0011</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">28.0</span> sec</span><br><span class="line">epoch  <span class="number">19</span>, loss <span class="number">0.0010</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">20</span>, loss <span class="number">0.0009</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch  <span class="number">21</span>, loss <span class="number">0.0008</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.921</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">22</span>, loss <span class="number">0.0008</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">23</span>, loss <span class="number">0.0007</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch  <span class="number">24</span>, loss <span class="number">0.0007</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">25</span>, loss <span class="number">0.0006</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch  <span class="number">26</span>, loss <span class="number">0.0006</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">27</span>, loss <span class="number">0.0005</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch  <span class="number">28</span>, loss <span class="number">0.0005</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch  <span class="number">29</span>, loss <span class="number">0.0005</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">30</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">31</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">32</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">33</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">34</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">35</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">36</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch  <span class="number">37</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">38</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">39</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch  <span class="number">40</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">28.0</span> sec</span><br><span class="line">epoch  <span class="number">41</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.2</span> sec</span><br><span class="line">epoch  <span class="number">42</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">43</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch  <span class="number">44</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">45</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch  <span class="number">46</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">47</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">48</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">49</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">50</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch  <span class="number">51</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">52</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch  <span class="number">53</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch  <span class="number">54</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">55</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.9</span> sec</span><br><span class="line">epoch  <span class="number">56</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">57</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">58</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">59</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">60</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch  <span class="number">61</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">62</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">63</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">64</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">65</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">66</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">67</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.2</span> sec</span><br><span class="line">epoch  <span class="number">68</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">69</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch  <span class="number">70</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">71</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">72</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch  <span class="number">73</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch  <span class="number">74</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">75</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">76</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">77</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">78</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch  <span class="number">79</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">80</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch  <span class="number">81</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch  <span class="number">82</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch  <span class="number">83</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">84</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">85</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.921</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch  <span class="number">86</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">87</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">88</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">89</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">90</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">91</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">92</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">93</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">94</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.2</span> sec</span><br><span class="line">epoch  <span class="number">95</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch  <span class="number">96</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch  <span class="number">97</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch  <span class="number">98</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch  <span class="number">99</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">100</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">101</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">102</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">103</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">104</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">105</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">106</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">107</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">108</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">109</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch <span class="number">110</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">111</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">112</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">113</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">114</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch <span class="number">115</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">116</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">117</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">118</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">119</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch <span class="number">120</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">121</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">122</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">123</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">124</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">125</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">28.0</span> sec</span><br><span class="line">epoch <span class="number">126</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">127</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">128</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">129</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">130</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">131</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">132</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">133</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">134</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">135</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">136</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">137</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">138</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">139</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">140</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.2</span> sec</span><br><span class="line">epoch <span class="number">141</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch <span class="number">142</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">143</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">144</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch <span class="number">145</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">146</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">147</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">148</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">149</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">150</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">151</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">152</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.2</span> sec</span><br><span class="line">epoch <span class="number">153</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">154</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch <span class="number">155</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">156</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch <span class="number">157</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">158</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">159</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">160</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">161</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">162</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">163</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">164</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">165</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">166</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">167</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">168</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">169</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch <span class="number">170</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">171</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">172</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch <span class="number">173</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">174</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch <span class="number">175</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">176</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.2</span> sec</span><br><span class="line">epoch <span class="number">177</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch <span class="number">178</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">179</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">180</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">181</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">182</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.8</span> sec</span><br><span class="line">epoch <span class="number">183</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">184</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch <span class="number">185</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">186</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">187</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch <span class="number">188</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">189</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.7</span> sec</span><br><span class="line">epoch <span class="number">190</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">191</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.921</span>, time <span class="number">27.3</span> sec</span><br><span class="line">epoch <span class="number">192</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.6</span> sec</span><br><span class="line">epoch <span class="number">193</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">194</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">195</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">196</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">197</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.5</span> sec</span><br><span class="line">epoch <span class="number">198</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">199</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.922</span>, time <span class="number">27.4</span> sec</span><br><span class="line">epoch <span class="number">200</span>, loss <span class="number">0.0000</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.923</span>, time <span class="number">27.3</span> sec</span><br></pre></td></tr></tbody></table></figure>
<h2 id="稠密连结网络（DenseNet）"><a href="#稠密连结网络（DenseNet）" class="headerlink" title="稠密连结网络（DenseNet）"></a>稠密连结网络（DenseNet）</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, gluon, init, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn, data <span class="keyword">as</span> gdata, loss <span class="keyword">as</span> gloss</span><br><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_block</span><span class="params">(num_channels)</span>:</span></span><br><span class="line">    blk = nn.Sequential()</span><br><span class="line">    blk.add(nn.BatchNorm(),</span><br><span class="line">            nn.Activation(<span class="string">'relu'</span>),</span><br><span class="line">            nn.Conv2D(num_channels, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> blk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DenseBlock</span><span class="params">(nn.Block)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_convs, num_channels, **kwargs)</span>:</span></span><br><span class="line">        super(DenseBlock, self).__init__(**kwargs)</span><br><span class="line">        self.net = nn.Sequential()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_convs):</span><br><span class="line">            self.net.add(conv_block(num_channels))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> self.net:</span><br><span class="line">            Y = blk(X)</span><br><span class="line">            X = nd.concat(X, Y, dim=<span class="number">1</span>)  <span class="comment"># 在通道维上将输入和输出连结</span></span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transition_block</span><span class="params">(num_channels)</span>:</span></span><br><span class="line">    blk = nn.Sequential()</span><br><span class="line">    blk.add(nn.BatchNorm(),</span><br><span class="line">            nn.Activation(<span class="string">'relu'</span>),</span><br><span class="line">            nn.Conv2D(num_channels, kernel_size=<span class="number">1</span>),</span><br><span class="line">            nn.AvgPool2D(pool_size=<span class="number">2</span>, strides=<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> blk</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # 测试</span></span><br><span class="line"><span class="comment"># X = nd.random.uniform(shape=(1, 2, 4, 4))</span></span><br><span class="line"><span class="comment"># Y = nd.random.uniform(shape=(1, 3, 4, 4))</span></span><br><span class="line"><span class="comment"># Z = nd.concat(X, Y, dim=1)</span></span><br><span class="line"><span class="comment"># print(Z.shape)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># blk = DenseBlock(2, 10)</span></span><br><span class="line"><span class="comment"># blk.initialize()</span></span><br><span class="line"><span class="comment"># X = nd.random.uniform(shape=(4, 3, 8, 8))</span></span><br><span class="line"><span class="comment"># Y = blk(X)</span></span><br><span class="line"><span class="comment"># print(Y.shape)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># blk = transition_block(10)</span></span><br><span class="line"><span class="comment"># blk.initialize()</span></span><br><span class="line"><span class="comment"># print(blk(Y).shape)</span></span><br><span class="line"><span class="comment"># # 测试输出</span></span><br><span class="line"><span class="comment"># # (1, 5, 4, 4)</span></span><br><span class="line"><span class="comment"># # (4, 23, 8, 8)</span></span><br><span class="line"><span class="comment"># # (4, 10, 4, 4)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        ctx = mx.gpu(<span class="number">3</span>)</span><br><span class="line">        _ = nd.array((<span class="number">1</span>,), ctx=ctx)</span><br><span class="line">    <span class="keyword">except</span> mx.base.MXNetError:</span><br><span class="line">        ctx = mx.cpu()</span><br><span class="line">    <span class="keyword">return</span> ctx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_fashion_mnist</span><span class="params">(batch_size, resize=None, root=os.path.join<span class="params">(<span class="string">'-'</span>, <span class="string">'mxnet'</span>, <span class="string">'datasets'</span>, <span class="string">'fashion-mnist'</span>)</span>)</span>:</span></span><br><span class="line">    root = os.path.expanduser(root)</span><br><span class="line">    transformer = []</span><br><span class="line">    <span class="keyword">if</span> resize:</span><br><span class="line">        transformer += [gdata.vision.transforms.Resize(resize)]</span><br><span class="line">    transformer += [gdata.vision.transforms.ToTensor()]</span><br><span class="line">    transformer = gdata.vision.transforms.Compose(transformer)</span><br><span class="line"></span><br><span class="line">    mnist_train = gdata.vision.FashionMNIST(root=root, train=<span class="literal">True</span>)</span><br><span class="line">    mnist_test = gdata.vision.FashionMNIST(root=root, train=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    num_workers = <span class="number">0</span> <span class="keyword">if</span> sys.platform.startswith(<span class="string">'win'</span>) <span class="keyword">else</span> <span class="number">4</span></span><br><span class="line">    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),</span><br><span class="line">                                  batch_size=batch_size,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  num_workers=num_workers)</span><br><span class="line">    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),</span><br><span class="line">                                 batch_size=batch_size,</span><br><span class="line">                                 shuffle=<span class="literal">True</span>,</span><br><span class="line">                                 num_workers=num_workers)</span><br><span class="line">    <span class="keyword">return</span> train_iter, test_iter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_accuracy</span><span class="params">(net, data_iter, ctx)</span>:</span></span><br><span class="line">    acc_sum, n = nd.array([<span class="number">0</span>], ctx=ctx), <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype(<span class="string">'float32'</span>)</span><br><span class="line">        y_hat = net(X)</span><br><span class="line">        acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y).sum()</span><br><span class="line">        n += y.size</span><br><span class="line">    <span class="keyword">return</span> acc_sum.asscalar() / n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span>:</span></span><br><span class="line">    print(<span class="string">"training on "</span>, ctx)</span><br><span class="line">    loss = gloss.SoftmaxCrossEntropyLoss()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epochs):</span><br><span class="line">        train_l_sum, train_acc_sum, n, start = <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0</span>, time.time()</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            X, y = X.as_in_context(ctx), y.as_in_context(ctx)</span><br><span class="line">            <span class="keyword">with</span> autograd.record():</span><br><span class="line">                y_hat = net(X)</span><br><span class="line">                l = loss(y_hat, y).sum()</span><br><span class="line">            l.backward()</span><br><span class="line">            trainer.step(batch_size)</span><br><span class="line">            train_l_sum += l.asscalar()</span><br><span class="line">            train_acc_sum += (y_hat.argmax(axis=<span class="number">1</span>) == y.astype(<span class="string">'float32'</span>)).sum().asscalar()</span><br><span class="line">            n += y.size</span><br><span class="line">        test_acc = evaluate_accuracy(net, test_iter, ctx)</span><br><span class="line">        print(<span class="string">'epoch %3d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'</span></span><br><span class="line">              % (epoch + <span class="number">1</span>, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = nn.Sequential()</span><br><span class="line">net.add(nn.Conv2D(<span class="number">64</span>, kernel_size=<span class="number">7</span>, strides=<span class="number">2</span>, padding=<span class="number">3</span>),</span><br><span class="line">        nn.BatchNorm(),</span><br><span class="line">        nn.Activation(<span class="string">'relu'</span>),</span><br><span class="line">        nn.MaxPool2D(pool_size=<span class="number">3</span>, strides=<span class="number">2</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">num_channels, groth_rate = <span class="number">64</span>, <span class="number">43</span>  <span class="comment"># num_channels为当前的通道数</span></span><br><span class="line">num_convs_in_dense_blocks = [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, num_convs <span class="keyword">in</span> enumerate(num_convs_in_dense_blocks):</span><br><span class="line">    net.add(DenseBlock(num_convs, groth_rate))</span><br><span class="line">    <span class="comment"># 上一个稠密块的输出通道数</span></span><br><span class="line">    num_channels += num_convs * groth_rate</span><br><span class="line">    <span class="comment"># 在稠密块之间加入通道数减半的过渡层</span></span><br><span class="line">    <span class="keyword">if</span> i != len(num_convs_in_dense_blocks) - <span class="number">1</span>:</span><br><span class="line">        num_channels //= <span class="number">2</span></span><br><span class="line">        net.add(transition_block(num_channels))</span><br><span class="line"></span><br><span class="line">net.add(nn.BatchNorm(),</span><br><span class="line">        nn.Activation(<span class="string">'relu'</span>),</span><br><span class="line">        nn.GlobalAvgPool2D(),</span><br><span class="line">        nn.Dense(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">lr, num_epochs, batch_size, ctx = <span class="number">0.1</span>, <span class="number">200</span>, <span class="number">640</span>, try_gpu()</span><br><span class="line">net.initialize(force_reinit=<span class="literal">True</span>, ctx=ctx, init=init.Xavier())</span><br><span class="line">trainer = gluon.Trainer(net.collect_params(), <span class="string">'sgd'</span>, {<span class="string">'learning_rate'</span>: lr})</span><br><span class="line">train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=<span class="number">96</span>)</span><br><span class="line">train(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br></pre></td><td class="code"><pre><span class="line">training on  gpu(<span class="number">0</span>)</span><br><span class="line">epoch   <span class="number">1</span>, loss <span class="number">0.6599</span>, train acc <span class="number">0.771</span>, test acc <span class="number">0.849</span>, time <span class="number">65.5</span> sec</span><br><span class="line">epoch   <span class="number">2</span>, loss <span class="number">0.3640</span>, train acc <span class="number">0.869</span>, test acc <span class="number">0.881</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch   <span class="number">3</span>, loss <span class="number">0.3030</span>, train acc <span class="number">0.890</span>, test acc <span class="number">0.893</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch   <span class="number">4</span>, loss <span class="number">0.2646</span>, train acc <span class="number">0.903</span>, test acc <span class="number">0.904</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch   <span class="number">5</span>, loss <span class="number">0.2404</span>, train acc <span class="number">0.913</span>, test acc <span class="number">0.907</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch   <span class="number">6</span>, loss <span class="number">0.2225</span>, train acc <span class="number">0.919</span>, test acc <span class="number">0.903</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch   <span class="number">7</span>, loss <span class="number">0.2074</span>, train acc <span class="number">0.924</span>, test acc <span class="number">0.920</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch   <span class="number">8</span>, loss <span class="number">0.1889</span>, train acc <span class="number">0.931</span>, test acc <span class="number">0.909</span>, time <span class="number">57.4</span> sec</span><br><span class="line">epoch   <span class="number">9</span>, loss <span class="number">0.1790</span>, train acc <span class="number">0.936</span>, test acc <span class="number">0.912</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">10</span>, loss <span class="number">0.1657</span>, train acc <span class="number">0.939</span>, test acc <span class="number">0.892</span>, time <span class="number">57.4</span> sec</span><br><span class="line">epoch  <span class="number">11</span>, loss <span class="number">0.1596</span>, train acc <span class="number">0.943</span>, test acc <span class="number">0.911</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">12</span>, loss <span class="number">0.1484</span>, train acc <span class="number">0.946</span>, test acc <span class="number">0.915</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">13</span>, loss <span class="number">0.1381</span>, train acc <span class="number">0.950</span>, test acc <span class="number">0.915</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">14</span>, loss <span class="number">0.1308</span>, train acc <span class="number">0.953</span>, test acc <span class="number">0.926</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">15</span>, loss <span class="number">0.1207</span>, train acc <span class="number">0.957</span>, test acc <span class="number">0.921</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">16</span>, loss <span class="number">0.1113</span>, train acc <span class="number">0.960</span>, test acc <span class="number">0.928</span>, time <span class="number">57.4</span> sec</span><br><span class="line">epoch  <span class="number">17</span>, loss <span class="number">0.1085</span>, train acc <span class="number">0.962</span>, test acc <span class="number">0.836</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">18</span>, loss <span class="number">0.0990</span>, train acc <span class="number">0.964</span>, test acc <span class="number">0.911</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">19</span>, loss <span class="number">0.0892</span>, train acc <span class="number">0.968</span>, test acc <span class="number">0.917</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">20</span>, loss <span class="number">0.0824</span>, train acc <span class="number">0.971</span>, test acc <span class="number">0.904</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">21</span>, loss <span class="number">0.0759</span>, train acc <span class="number">0.974</span>, test acc <span class="number">0.919</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">22</span>, loss <span class="number">0.0669</span>, train acc <span class="number">0.976</span>, test acc <span class="number">0.921</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">23</span>, loss <span class="number">0.0648</span>, train acc <span class="number">0.978</span>, test acc <span class="number">0.922</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">24</span>, loss <span class="number">0.0595</span>, train acc <span class="number">0.980</span>, test acc <span class="number">0.925</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">25</span>, loss <span class="number">0.0588</span>, train acc <span class="number">0.981</span>, test acc <span class="number">0.932</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">26</span>, loss <span class="number">0.0404</span>, train acc <span class="number">0.988</span>, test acc <span class="number">0.909</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">27</span>, loss <span class="number">0.0530</span>, train acc <span class="number">0.983</span>, test acc <span class="number">0.917</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">28</span>, loss <span class="number">0.0372</span>, train acc <span class="number">0.988</span>, test acc <span class="number">0.932</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">29</span>, loss <span class="number">0.0245</span>, train acc <span class="number">0.993</span>, test acc <span class="number">0.925</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">30</span>, loss <span class="number">0.0227</span>, train acc <span class="number">0.994</span>, test acc <span class="number">0.928</span>, time <span class="number">56.7</span> sec</span><br><span class="line">epoch  <span class="number">31</span>, loss <span class="number">0.0178</span>, train acc <span class="number">0.996</span>, test acc <span class="number">0.925</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">32</span>, loss <span class="number">0.0077</span>, train acc <span class="number">0.999</span>, test acc <span class="number">0.934</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">33</span>, loss <span class="number">0.0040</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.933</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">34</span>, loss <span class="number">0.0025</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.939</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">35</span>, loss <span class="number">0.0019</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">36</span>, loss <span class="number">0.0015</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">37</span>, loss <span class="number">0.0013</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">38</span>, loss <span class="number">0.0012</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">39</span>, loss <span class="number">0.0011</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.9</span> sec</span><br><span class="line">epoch  <span class="number">40</span>, loss <span class="number">0.0010</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.5</span> sec</span><br><span class="line">epoch  <span class="number">41</span>, loss <span class="number">0.0009</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">42</span>, loss <span class="number">0.0008</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">43</span>, loss <span class="number">0.0008</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">44</span>, loss <span class="number">0.0007</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.942</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">45</span>, loss <span class="number">0.0007</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.9</span> sec</span><br><span class="line">epoch  <span class="number">46</span>, loss <span class="number">0.0007</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">47</span>, loss <span class="number">0.0006</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">48</span>, loss <span class="number">0.0006</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">49</span>, loss <span class="number">0.0006</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.9</span> sec</span><br><span class="line">epoch  <span class="number">50</span>, loss <span class="number">0.0006</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">51</span>, loss <span class="number">0.0005</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">52</span>, loss <span class="number">0.0005</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">53</span>, loss <span class="number">0.0005</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">54</span>, loss <span class="number">0.0005</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">55</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">56</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">57</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">58</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">59</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">60</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">61</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">62</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.942</span>, time <span class="number">57.4</span> sec</span><br><span class="line">epoch  <span class="number">63</span>, loss <span class="number">0.0004</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.942</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">64</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">65</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">66</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.942</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">67</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">68</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">69</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">70</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">71</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.942</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">72</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">73</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">74</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">75</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">76</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">77</span>, loss <span class="number">0.0003</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">78</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.942</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">79</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">80</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.9</span> sec</span><br><span class="line">epoch  <span class="number">81</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">82</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.9</span> sec</span><br><span class="line">epoch  <span class="number">83</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">84</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">85</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">86</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">87</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">88</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">89</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch  <span class="number">90</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.9</span> sec</span><br><span class="line">epoch  <span class="number">91</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">92</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">93</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch  <span class="number">94</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">95</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch  <span class="number">96</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.4</span> sec</span><br><span class="line">epoch  <span class="number">97</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">98</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch  <span class="number">99</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.8</span> sec</span><br><span class="line">epoch <span class="number">100</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.9</span> sec</span><br><span class="line">epoch <span class="number">101</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">102</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">103</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">104</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">105</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">106</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">107</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">108</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">109</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">110</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">111</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">112</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">113</span>, loss <span class="number">0.0002</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">114</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch <span class="number">115</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">116</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">117</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">118</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">119</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">120</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">121</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">122</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">123</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">124</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.8</span> sec</span><br><span class="line">epoch <span class="number">125</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">126</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">127</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">128</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.9</span> sec</span><br><span class="line">epoch <span class="number">129</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">130</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">131</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.8</span> sec</span><br><span class="line">epoch <span class="number">132</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">133</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">134</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">135</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">136</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">137</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">138</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">139</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">140</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">141</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">142</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">143</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">144</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">145</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch <span class="number">146</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">147</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">148</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">149</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch <span class="number">150</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch <span class="number">151</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">152</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">153</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">154</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">155</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">156</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">157</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">158</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">159</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">160</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">161</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">162</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch <span class="number">163</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">164</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">165</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">166</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">167</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">168</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch <span class="number">169</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">170</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">171</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">172</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch <span class="number">173</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch <span class="number">174</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch <span class="number">175</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">56.9</span> sec</span><br><span class="line">epoch <span class="number">176</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">177</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">178</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">179</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">180</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">181</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.4</span> sec</span><br><span class="line">epoch <span class="number">182</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.4</span> sec</span><br><span class="line">epoch <span class="number">183</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">184</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">185</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">186</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">187</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.3</span> sec</span><br><span class="line">epoch <span class="number">188</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">189</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">190</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">191</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">192</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">193</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">194</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">195</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">196</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">197</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.1</span> sec</span><br><span class="line">epoch <span class="number">198</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.0</span> sec</span><br><span class="line">epoch <span class="number">199</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.941</span>, time <span class="number">57.2</span> sec</span><br><span class="line">epoch <span class="number">200</span>, loss <span class="number">0.0001</span>, train acc <span class="number">1.000</span>, test acc <span class="number">0.940</span>, time <span class="number">57.2</span> sec</span><br></pre></td></tr></tbody></table></figure>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">ML</a>
        		</li>
      		 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">DL</a>
        		</li>
      		
		</ul>
	</div>

      

      

      
        
<div class="share-btn share-icons tooltip-left">
  <div class="tooltip tooltip-east">
    <span class="tooltip-item">
      <a href="javascript:;" class="share-sns share-outer">
        <i class="icon icon-share"></i>
      </a>
    </span>
    <span class="tooltip-content">
      <div class="share-wrap">
        <div class="share-icons">
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="icon icon-weibo"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="icon icon-weixin"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="icon icon-qq"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="icon icon-douban"></i>
          </a>
          <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a>
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="icon icon-facebook"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="icon icon-twitter"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="icon icon-google"></i>
          </a>
        </div>
      </div>
    </span>
  </div>
</div>

<div class="page-modal wx-share js-wx-box">
    <a class="close js-modal-close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="http://s.jiathis.com/qrcode.php?url=https://lourisxu.github.io/2019/07/25/3-deep-learning-convolutional-neural-networks.html/" alt="微信分享二维码">
    </div>
</div>

<div class="mask js-mask"></div>
      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

  
<nav id="article-nav">
  
    <a href="/2019/08/05/4-deep-learning-optimizor.html/" id="article-nav-newer" class="article-nav-link-wrap">
      <i class="icon-circle-left"></i>
      <div class="article-nav-title">
        
          (4) Deep Learning: Optimizor
        
      </div>
    </a>
  
  
    <a href="/2019/07/15/2-deep-learning-computation.html/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">(2) Deep Learning: Computation</div>
      <i class="icon-circle-right"></i>
    </a>
  
</nav>


<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
        <div class="toc-container tooltip-left">
            <i class="icon-font icon-category"></i>
            <div class="tooltip tooltip-east">
                <span class="tooltip-item">
                </span>
                <span class="tooltip-content">
                  <div class="toc-article">
                  <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#卷积神经网络"><span class="toc-number">1.</span> <span class="toc-text">卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#二维卷积层"><span class="toc-number">1.1.</span> <span class="toc-text">二维卷积层</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#二维互相关计算"><span class="toc-number">1.1.1.</span> <span class="toc-text">二维互相关计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#二维卷积层-1"><span class="toc-number">1.1.2.</span> <span class="toc-text">二维卷积层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#边缘检测"><span class="toc-number">1.1.3.</span> <span class="toc-text">边缘检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#通过数据学习核数组"><span class="toc-number">1.1.4.</span> <span class="toc-text">通过数据学习核数组</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#互相关运算和卷积运算"><span class="toc-number">1.1.5.</span> <span class="toc-text">互相关运算和卷积运算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征图和感受野"><span class="toc-number">1.1.6.</span> <span class="toc-text">特征图和感受野</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#练习：自定义互相关计算类的自动求梯度"><span class="toc-number">1.1.7.</span> <span class="toc-text">练习：自定义互相关计算类的自动求梯度</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#填充和步幅"><span class="toc-number">1.2.</span> <span class="toc-text">填充和步幅</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多输入通道和多输出通道"><span class="toc-number">1.3.</span> <span class="toc-text">多输入通道和多输出通道</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#多输入和多输出通道"><span class="toc-number">1.3.1.</span> <span class="toc-text">多输入和多输出通道</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1×1卷积层"><span class="toc-number">1.3.2.</span> <span class="toc-text">1×1卷积层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#池化层"><span class="toc-number">1.4.</span> <span class="toc-text">池化层</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#二维最大池化和平均池化"><span class="toc-number">1.4.1.</span> <span class="toc-text">二维最大池化和平均池化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#填充和步幅、多通道"><span class="toc-number">1.4.2.</span> <span class="toc-text">填充和步幅、多通道</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#卷积层和池化层"><span class="toc-number">1.4.3.</span> <span class="toc-text">卷积层和池化层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#卷积神经网络（LeNet）"><span class="toc-number">1.5.</span> <span class="toc-text">卷积神经网络（LeNet）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#深度卷积神经网络（AlexNet）"><span class="toc-number">1.6.</span> <span class="toc-text">深度卷积神经网络（AlexNet）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用重复元素的网络（VGG）"><span class="toc-number">1.7.</span> <span class="toc-text">使用重复元素的网络（VGG）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#网络中的网络（NiN）"><span class="toc-number">1.8.</span> <span class="toc-text">网络中的网络（NiN）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#含并行连结的网络（GoogLeNet）"><span class="toc-number">1.9.</span> <span class="toc-text">含并行连结的网络（GoogLeNet）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#批量归一化（Batch-Normalization）"><span class="toc-number">1.10.</span> <span class="toc-text">批量归一化（Batch Normalization）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#原生实现"><span class="toc-number">1.10.1.</span> <span class="toc-text">原生实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#简洁实现"><span class="toc-number">1.10.2.</span> <span class="toc-text">简洁实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#残差网络（ResNet）"><span class="toc-number">1.11.</span> <span class="toc-text">残差网络（ResNet）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#稠密连结网络（DenseNet）"><span class="toc-number">1.12.</span> <span class="toc-text">稠密连结网络（DenseNet）</span></a></li></ol></li></ol>
                  </div>
                </span>

            </div>
        </div>
        

    </div>
</aside>




  

  

  

  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2024 Louris
        <span style="font-size: smaller">
          Hosted by
          <a href="https://coding.net/" target="_blank" rel="noopener" style="font-weight: bold">Coding Pages</a>/
          <a href="https://gitee.com/" target="_blank" rel="noopener" style="font-weight: bold">Gitee Pages</a>/
          <a href="https://github.com/" target="_blank" rel="noopener" style="font-weight: bold">Github Pages</a>
        </span>
        <!-- <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
        <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人次</span> -->
    	</div>

      <!-- <div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
           <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
           <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人次</span>
      </div> -->

      <div class="footer-right">
      	<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      </div>
    </div>
  </div>
</footer>

    </div>
    <script>
	var yiliaConfig = {
		mathjax: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: false,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(203),t.exports=r(199)},function(t,n,r){var e=r(3),i=r(49),o=r(26),u=r(27),c=r(46),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,m=t&a.B,b=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),S=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&b&&void 0!==b[s],h=(l?b:r)[s],v=m&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,b&&u(b,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&S[s]!=h&&(S[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(5);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n,r){var e=r(128)("wks"),i=r(78),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(170),o=r(53),u=Object.defineProperty;n.f=r(9)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(52),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(59),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(95),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(6).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(50);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r=t.exports={version:"2.5.1"};"number"==typeof __e&&(__e=r)},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(10),i=r(74);t.exports=r(9)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(26),o=r(25),u=r(78)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(49).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(50),u=/"/g,c=function(t,n,r,e){var i=String(o(t)),c="<"+n;return""!==r&&(c+=" "+r+'="'+String(e).replace(u,"&quot;")+'"'),c+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(c),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(64),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(116),i=r(74),o=r(32),u=r(53),c=r(25),f=r(170),a=Object.getOwnPropertyDescriptor;n.f=r(9)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(25),i=r(17),o=r(149)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(115),i=r(50);t.exports=function(t){return e(i(t))}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(16)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(6),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(6),i=r(24),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(16)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(19);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){"use strict";var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(46),i=r(115),o=r(17),u=r(11),c=r(134);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),m=i(g),b=e(c,p,3),x=u(m.length),S=0,w=r?v(n,x):f?v(n,0):void 0;x>S;S++)if((h||S in m)&&(d=m[S],y=b(d,S,g),t))if(r)w[S]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return S;case 2:w.push(d)}else if(s)return!1;return l?-1:a||s?s:w}}},function(t,n){var r=t.exports={version:"2.5.1"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(1),i=r(49),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(5);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(6),i=r(24),o=r(92),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,m=v?i:i[n]||(i[n]={}),b=m[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in m||(l=s?x[a]:r[a],m[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((m.virtual||(m.virtual={}))[a]=l,t&f.R&&b&&!b[a]&&u(b,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n,r){var e=r(191),i=r(1),o=r(128)("metadata"),u=o.store||(o.store=new(r(194))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o};t.exports={store:u,map:c,has:function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},get:function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},set:function(t,n,r,e){c(r,e,!0).set(t,n)},keys:function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},key:function(t){return void 0===t||"symbol"==typeof t?t:String(t)},exp:function(t){i(i.S,"Reflect",t)}}},function(t,n,r){"use strict";if(r(9)){var e=r(70),i=r(3),o=r(4),u=r(1),c=r(130),f=r(155),a=r(46),s=r(68),l=r(74),h=r(26),v=r(75),p=r(52),d=r(11),y=r(189),g=r(77),m=r(53),b=r(25),x=r(114),S=r(5),w=r(17),_=r(141),O=r(71),E=r(31),M=r(72).f,P=r(157),j=r(78),F=r(7),A=r(48),L=r(117),N=r(129),T=r(158),I=r(80),k=r(123),R=r(76),C=r(133),D=r(162),G=r(10),W=r(30),U=G.f,V=W.f,B=i.RangeError,q=i.TypeError,z=i.Uint8Array,H="ArrayBuffer",K="Shared"+H,J="BYTES_PER_ELEMENT",Y="prototype",$=Array[Y],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=L(!0),ut=L(!1),ct=T.values,ft=T.keys,at=T.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,mt=F("iterator"),bt=F("toStringTag"),xt=j("typed_constructor"),St=j("def_constructor"),wt=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Mt=A(1,function(t,n){return Lt(N(t,t[St]),n)}),Pt=o(function(){return 1===new z(new Uint16Array([1]).buffer)[0]}),jt=!!z&&!!z[Y].set&&o(function(){new z(1).set({})}),Ft=function(t,n){var r=p(t);if(r<0||r%n)throw B("Wrong offset!");return r},At=function(t){if(S(t)&&_t in t)return t;throw q(t+" is not a typed array!")},Lt=function(t,n){if(!(S(t)&&xt in t))throw q("It is not a typed array constructor!");return new t(n)},Nt=function(t,n){return Tt(N(t,t[St]),n)},Tt=function(t,n){for(var r=0,e=n.length,i=Lt(t,e);e>r;)i[r]=n[r++];return i},It=function(t,n,r){U(t,n,{get:function(){return this._d[r]}})},kt=function(t){var n,r,e,i,o,u,c=w(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=P(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Lt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Rt=function(){for(var t=0,n=arguments.length,r=Lt(this,n);n>t;)r[t]=arguments[t++];return r},Ct=!!z&&o(function(){gt.call(new z(1))}),Dt=function(){return gt.apply(Ct?dt.call(At(this)):At(this),arguments)},Gt={copyWithin:function(t,n){return D.call(At(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(At(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(At(this),arguments)},filter:function(t){return Nt(this,tt(At(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(At(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(At(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(At(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(At(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(At(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(At(this),arguments)},lastIndexOf:function(t){return st.apply(At(this),arguments)},map:function(t){return Mt(At(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(At(this),arguments)},reduceRight:function(t){return ht.apply(At(this),arguments)},reverse:function(){for(var t,n=this,r=At(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(At(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(At(this),t)},subarray:function(t,n){var r=At(this),e=r.length,i=g(t,e);return new(N(r,r[St]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:g(n,e))-i))}},Wt=function(t,n){return Nt(this,dt.call(At(this),t,n))},Ut=function(t){At(this);var n=Ft(arguments[1],1),r=this.length,e=w(t),i=d(e.length),o=0;if(i+n>r)throw B(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(At(this))},keys:function(){return ft.call(At(this))},values:function(){return ct.call(At(this))}},Bt=function(t,n){return S(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return Bt(t,n=m(n,!0))?l(2,t[n]):V(t,n)},zt=function(t,n,r){return!(Bt(t,n=m(n,!0))&&S(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?U(t,n,r):(t[n]=r.value,t)};wt||(W.f=qt,G.f=zt),u(u.S+u.F*!wt,"Object",{getOwnPropertyDescriptor:qt,defineProperty:zt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Ht=v({},Gt);v(Ht,Vt),h(Ht,mt,Vt.values),v(Ht,{slice:Wt,set:Ut,constructor:function(){},toString:yt,toLocaleString:Dt}),It(Ht,"buffer","b"),It(Ht,"byteOffset","o"),It(Ht,"byteLength","l"),It(Ht,"length","e"),U(Ht,bt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){var a=t+((f=!!f)?"Clamped":"")+"Array",l="get"+t,v="set"+t,p=i[a],g=p||{},m=p&&E(p),b=!p||!c.ABV,w={},_=p&&p[Y],P=function(t,r){var e=t._d;return e.v[l](r*n+e.o,Pt)},j=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[v](r*n+i.o,e,Pt)},F=function(t,n){U(t,n,{get:function(){return P(this,n)},set:function(t){return j(this,n,t)},enumerable:!0})};b?(p=r(function(t,r,e,i){s(t,p,a,"_d");var o,u,c,f,l=0,v=0;if(S(r)){if(!(r instanceof X||(f=x(r))==H||f==K))return _t in r?Tt(p,r):kt.call(p,r);o=r,v=Ft(e,n);var g=r.byteLength;if(void 0===i){if(g%n)throw B(Et);if((u=g-v)<0)throw B(Et)}else if((u=d(i)*n)+v>g)throw B(Et);c=u/n}else c=y(r),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)F(t,l++)}),_=p[Y]=O(Ht),h(_,"constructor",p)):o(function(){p(1)})&&o(function(){new p(-1)})&&k(function(t){new p,new p(null),new p(1.5),new p(t)},!0)||(p=r(function(t,r,e,i){s(t,p,a);var o;return S(r)?r instanceof X||(o=x(r))==H||o==K?void 0!==i?new g(r,Ft(e,n),i):void 0!==e?new g(r,Ft(e,n)):new g(r):_t in r?Tt(p,r):kt.call(p,r):new g(y(r))}),Z(m!==Function.prototype?M(g).concat(M(m)):M(g),function(t){t in p||h(p,t,g[t])}),p[Y]=_,e||(_.constructor=p));var A=_[mt],L=!!A&&("values"==A.name||void 0==A.name),N=Vt.values;h(p,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,St,p),(f?new p(1)[bt]==a:bt in _)||U(_,bt,{get:function(){return a}}),w[a]=p,u(u.G+u.W+u.F*(p!=g),w),u(u.S,a,{BYTES_PER_ELEMENT:n}),u(u.S+u.F*o(function(){g.of.call(p,1)}),a,{from:kt,of:Rt}),J in _||h(_,J,n),u(u.P,a,Gt),R(a),u(u.P+u.F*jt,a,{set:Ut}),u(u.P+u.F*!L,a,Vt),e||_.toString==yt||(_.toString=yt),u(u.P+u.F*o(function(){new p(1).slice()}),a,{slice:Wt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new p([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Dt}),I[a]=L?A:N,e||L||h(_,mt,N)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(6).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(58)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(54),o=r(65),u=r(13),c=r(8),f=r(35),a=r(97),s=r(38),l=r(103),h=r(16)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,m,b,x){a(r,n,g);var S,w,_,O=function(t){if(!v&&t in j)return j[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",M=m==d,P=!1,j=t.prototype,F=j[h]||j["@@iterator"]||m&&j[m],A=F||O(m),L=m?M?O("entries"):A:void 0,N="Array"==n?j.entries||F:F;if(N&&(_=l(N.call(new t)))!==Object.prototype&&_.next&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),M&&F&&F.name!==d&&(P=!0,A=function(){return F.call(this)}),e&&!x||!v&&!P&&j[h]||u(j,h,A),f[n]=A,f[E]=y,m)if(S={values:M?A:O(d),keys:b?A:O(p),entries:L},x)for(w in S)w in j||o(j,w,S[w]);else i(i.P+i.F*(v||P),n,S);return S}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(58)("iframe"),e=o.length;for(n.style.display="none",r(94).appendChild(n),n.src="javascript:",(t=n.contentWindow.document).open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(64),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(15),o=r(91)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(26)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(78)("meta"),i=r(5),o=r(25),u=r(10).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=t.exports={KEY:e,NEED:!1,fastKey:function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},getWeak:function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},onFreeze:function(t){return a&&l.NEED&&f(t)&&!o(t,e)&&s(t),t}}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n,r){var e=r(46),i=r(173),o=r(141),u=r(2),c=r(11),f=r(157),a={},s={};(n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),m=e(r,l,n?2:1),b=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>b;b++)if((y=n?m(u(p=t[b])[0],p[1]):m(t[b]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,m,p.value,n))===a||y===s)return y}).BREAK=a,n.RETURN=s},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(179),o=r(137),u=r(149)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(136)("iframe"),e=o.length;for(n.style.display="none",r(139).appendChild(n),n.src="javascript:",(t=n.contentWindow.document).open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(181),i=r(137).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(181),i=r(137);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n,r){var e=r(27);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(9),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(52),i=Math.max,o=Math.min;t.exports=function(t,n){return(t=e(t))<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports={}},function(t,n,r){var e=r(10).f,i=r(25),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(50),o=r(4),u=r(153),c="["+u+"]",f=RegExp("^"+c+c+"*"),a=RegExp(c+c+"*$"),s=function(t,n,r){var i={},c=o(function(){return!!u[t]()||"​"!="​"[t]()}),f=i[t]=c?n(l):u[t];r&&(i[r]=f),e(e.P+e.F*c,"String",i)},l=s.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(f,"")),2&n&&(t=t.replace(a,"")),t};t.exports=s},function(t,n,r){var e=r(5);t.exports=function(t,n){if(!e(t)||t._t!==n)throw TypeError("Incompatible receiver, "+n+" required!");return t}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){t.exports={default:r(88),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=e(r(85)),o=e(r(84)),u="function"==typeof o.default&&"symbol"==typeof i.default?function(t){return typeof t}:function(t){return t&&"function"==typeof o.default&&t.constructor===o.default&&t!==o.default.prototype?"symbol":typeof t};n.default="function"==typeof o.default&&"symbol"===u(i.default)?function(t){return void 0===t?"undefined":u(t)}:function(t){return t&&"function"==typeof o.default&&t.constructor===o.default&&t!==o.default.prototype?"symbol":void 0===t?"undefined":u(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(24).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(15),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(89);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(29),i=r(63),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(6).document;t.exports=e&&e.documentElement},function(t,n,r){var e=r(57);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(57);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(61),i=r(22),o=r(38),u={};r(13)(u,r(16)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=t.exports={KEY:e,NEED:!1,fastKey:function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},getWeak:function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},onFreeze:function(t){return a&&l.NEED&&f(t)&&!o(t,e)&&s(t),t}}},function(t,n,r){var e=r(14),i=r(20),o=r(29);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(15),u=r(42),c=r(8),f=r(59),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(15),i=r(62).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(79),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f))<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return(t=e(t))<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(90),i=r(98),o=r(35),u=r(15);t.exports=r(60)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(60)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(6),i=r(8),o=r(12),u=r(54),c=r(65),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(16),p=r(44),d=r(43),y=r(93),g=r(96),m=r(20),b=r(15),x=r(42),S=r(22),w=r(61),_=r(102),O=r(101),E=r(14),M=r(29),P=O.f,j=E.f,F=_.f,A=e.Symbol,L=e.JSON,N=L&&L.stringify,T="prototype",I=v("_hidden"),k=v("toPrimitive"),R={}.propertyIsEnumerable,C=s("symbol-registry"),D=s("symbols"),G=s("op-symbols"),W=Object[T],U="function"==typeof A,V=e.QObject,B=!V||!V[T]||!V[T].findChild,q=o&&a(function(){return 7!=w(j({},"a",{get:function(){return j(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=P(W,n);e&&delete W[n],j(t,n,r),e&&t!==W&&j(W,n,e)}:j,z=function(t){var n=D[t]=w(A[T]);return n._k=t,n},H=U&&"symbol"==typeof A.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof A},K=function(t,n,r){return t===W&&K(G,n,r),m(t),n=x(n,!0),m(r),i(D,n)?(r.enumerable?(i(t,I)&&t[I][n]&&(t[I][n]=!1),r=w(r,{enumerable:S(0,!1)})):(i(t,I)||j(t,I,S(1,{})),t[I][n]=!0),q(t,n,r)):j(t,n,r)},J=function(t,n){m(t);for(var r,e=y(n=b(n)),i=0,o=e.length;o>i;)K(t,r=e[i++],n[r]);return t},Y=function(t){var n=R.call(this,t=x(t,!0));return!(this===W&&i(D,t)&&!i(G,t))&&(!(n||!i(this,t)||!i(D,t)||i(this,I)&&this[I][t])||n)},$=function(t,n){if(t=b(t),n=x(n,!0),t!==W||!i(D,n)||i(G,n)){var r=P(t,n);return!r||!i(D,n)||i(t,I)&&t[I][n]||(r.enumerable=!0),r}},X=function(t){for(var n,r=F(b(t)),e=[],o=0;r.length>o;)i(D,n=r[o++])||n==I||n==f||e.push(n);return e},Q=function(t){for(var n,r=t===W,e=F(r?G:b(t)),o=[],u=0;e.length>u;)!i(D,n=e[u++])||r&&!i(W,n)||o.push(D[n]);return o};U||(A=function(){if(this instanceof A)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===W&&n.call(G,r),i(this,I)&&i(this[I],t)&&(this[I][t]=!1),q(this,t,S(1,r))};return o&&B&&q(W,t,{configurable:!0,set:n}),z(t)},c(A[T],"toString",function(){return this._k}),O.f=$,E.f=K,r(62).f=_.f=X,r(37).f=Y,r(63).f=Q,o&&!r(36)&&c(W,"propertyIsEnumerable",Y,!0),p.f=function(t){return z(v(t))}),u(u.G+u.W+u.F*!U,{Symbol:A});for(var Z="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),tt=0;Z.length>tt;)v(Z[tt++]);for(var nt=M(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!U,"Symbol",{for:function(t){return i(C,t+="")?C[t]:C[t]=A(t)},keyFor:function(t){if(!H(t))throw TypeError(t+" is not a symbol!");for(var n in C)if(C[n]===t)return n},useSetter:function(){B=!0},useSimple:function(){B=!1}}),u(u.S+u.F*!U,"Object",{create:function(t,n){return void 0===n?w(t):J(w(t),n)},defineProperty:K,defineProperties:J,getOwnPropertyDescriptor:$,getOwnPropertyNames:X,getOwnPropertySymbols:Q}),L&&u(u.S+u.F*(!U||a(function(){var t=A();return"[null]"!=N([t])||"{}"!=N({a:t})||"{}"!=N(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!H(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return"function"==typeof(n=e[1])&&(r=n),!r&&g(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!H(n))return n}),e[1]=n,N.apply(L,e)}}}),A[T][k]||r(13)(A[T],k,A[T].valueOf),l(A,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(6),i=r(13),o=r(35),u=r(16)("toStringTag"),c="CSSRuleList,CSSStyleDeclaration,CSSValueList,ClientRectList,DOMRectList,DOMStringList,DOMTokenList,DataTransferItemList,FileList,HTMLAllCollection,HTMLCollection,HTMLFormElement,HTMLSelectElement,MediaList,MimeTypeArray,NamedNodeMap,NodeList,PaintRequestList,Plugin,PluginArray,SVGLengthList,SVGNumberList,SVGPathSegList,SVGPointList,SVGStringList,SVGTransformList,SourceBufferList,StyleSheetList,TextTrackCueList,TextTrackList,TouchList".split(","),f=0;f<c.length;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(32),i=r(11),o=r(77);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(27),u=r(75),c=r(67),f=r(69),a=r(68),s=r(5),l=r(4),h=r(123),v=r(81),p=r(140);t.exports=function(t,n,r,d,y,g){var m=e[t],b=m,x=y?"set":"add",S=b&&b.prototype,w={},_=function(t){var n=S[t];o(S,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof b&&(g||S.forEach&&!l(function(){(new b).entries().next()}))){var O=new b,E=O[x](g?{}:-0,1)!=O,M=l(function(){O.has(1)}),P=h(function(t){new b(t)}),j=!g&&l(function(){for(var t=new b,n=5;n--;)t[x](n,n);return!t.has(-0)});P||(b=n(function(n,r){a(n,b,t);var e=p(new m,n,b);return void 0!=r&&f(r,y,e[x],e),e}),b.prototype=S,S.constructor=b),(M||j)&&(_("delete"),_("has"),y&&_("get")),(j||E)&&_(x),g&&S.clear&&delete S.clear}else b=d.getConstructor(n,t,y,x),u(b.prototype,r),c.NEED=!0;return v(b,t),w[t]=b,i(i.G+i.W+i.F*(b!=m),w),g||d.setStrong(b,t,y),b}},function(t,n,r){"use strict";var e=r(26),i=r(27),o=r(4),u=r(50),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){var e=r(5),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){"use strict";t.exports=r(70)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){"use strict";var e=r(1),i=r(19),o=r(46),u=r(69);t.exports=function(t){e(e.S,t,{from:function(t){var n,r,e,c,f=arguments[1];return i(this),(n=void 0!==f)&&i(f),void 0==t?new this:(r=[],n?(e=0,c=o(f,arguments[2],2),u(t,!1,function(t){r.push(c(t,e++))})):u(t,!1,r.push,r),new this(r))}})}},function(t,n,r){"use strict";var e=r(1);t.exports=function(t){e(e.S,t,{of:function(){for(var t=arguments.length,n=Array(t);t--;)n[t]=arguments[t];return new this(n)}})}},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){var e=r(2),i=r(19),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){for(var e,i=r(3),o=r(26),u=r(78),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=function(t){return t&&t.__esModule?t:{default:t}}(r(86)),i=function(){function t(t,n,r){return n||r?String.fromCharCode(n||r):u[t]||t}function n(t){return l[t]}var r=/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,o=/['<> "&]/g,u={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},c=/\u00a0/g,f=/<br\s*\/?>/gi,a=/\r?\n/g,s=/\s/g,l={};for(var h in u)l[u[h]]=h;return u["&apos;"]="'",l["'"]="&#39;",{encode:function(t){return t?(""+t).replace(o,n).replace(a,"<br/>").replace(s,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(f,"\n").replace(r,t).replace(c," "):""},encodeBase16:function(t){if(!t)return t;for(var n=[],r=0,e=(t+="").length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;for(var n=[],r=0,e=(t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")})).length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;for(var n=[],r=0,e=(t+="").length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=i.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,e.default)(t)))for(var o in t)t[o]=i.encodeObject(t[o]);else if("string"==typeof t)return i.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=i},function(t,n,r){"use strict";var e=r(17),i=r(77),o=r(11);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){var e=r(211);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(10),i=r(74);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(5),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){var e=r(3).document;t.exports=e&&e.documentElement},function(t,n,r){var e=r(5),i=r(148).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){"use strict";var e=r(71),i=r(74),o=r(81),u={};r(26)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(70),i=r(1),o=r(27),u=r(26),c=r(25),f=r(80),a=r(142),s=r(81),l=r(31),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,m,b,x){a(r,n,g);var S,w,_,O=function(t){if(!v&&t in j)return j[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",M=m==d,P=!1,j=t.prototype,F=j[h]||j["@@iterator"]||m&&j[m],A=F||O(m),L=m?M?O("entries"):A:void 0,N="Array"==n?j.entries||F:F;if(N&&(_=l(N.call(new t)))!==Object.prototype&&_.next&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),M&&F&&F.name!==d&&(P=!0,A=function(){return F.call(this)}),e&&!x||!v&&!P&&j[h]||u(j,h,A),f[n]=A,f[E]=y,m)if(S={values:M?A:O(d),keys:b?A:O(p),entries:L},x)for(w in S)w in j||o(j,w,S[w]);else i(i.P+i.F*(v||P),n,S);return S}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(154).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){"use strict";function e(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw TypeError("Bad Promise constructor");n=t,r=e}),this.resolve=i(n),this.reject=i(r)}var i=r(19);t.exports.f=function(t){return new e(t)}},function(t,n,r){var e=r(5),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{(e=r(46)(Function.call,r(30).f(Object.prototype,"__proto__").set,2))(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(128)("keys"),i=r(78);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(52),i=r(50);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f))<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536}}},function(t,n,r){var e=r(122),i=r(50);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(52),i=r(50);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(46),c=r(171),f=r(139),a=r(136),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=s.Dispatch,y=0,g={},m="onreadystatechange",b=function(){var t=+this;if(g.hasOwnProperty(t)){var n=g[t];delete g[t],n()}},x=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return g[++y]=function(){c("function"==typeof t?t:Function(t),n)},e(y),y},v=function(t){delete g[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:d&&d.now?e=function(t){d.now(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=x,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",x,!1)):e=m in a("script")?function(t){f.appendChild(a("script"))[m]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";function e(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?W(2,-24)-W(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for((t=G(t))!=t||t===C?(i=t!=t?1:0,e=f):(e=U(V(t)/B),t*(o=W(2,-e))<1&&(e--,o*=2),(t+=e+a>=1?s/o:s*W(2,1-a))*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*W(2,n),e+=a):(i=t*W(2,a-1)*W(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u}function i(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-C:C;e+=W(2,n),s-=u}return(a?-1:1)*e*W(2,s-n)}function o(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]}function u(t){return[255&t]}function c(t){return[255&t,t>>8&255]}function f(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]}function a(t){return e(t,52,8)}function s(t){return e(t,23,4)}function l(t,n,r){M(t[L],n,{get:function(){return this[r]}})}function h(t,n,r,e){var i=O(+r);if(i+n>t[J])throw R(N);var o=t[K]._b,u=i+t[Y],c=o.slice(u,u+n);return e?c:c.reverse()}function v(t,n,r,e,i,o){var u=O(+r);if(u+n>t[J])throw R(N);for(var c=t[K]._b,f=u+t[Y],a=e(+i),s=0;s<n;s++)c[f+s]=a[o?s:n-s-1]}var p=r(3),d=r(9),y=r(70),g=r(130),m=r(26),b=r(75),x=r(4),S=r(68),w=r(52),_=r(11),O=r(189),E=r(72).f,M=r(10).f,P=r(133),j=r(81),F="ArrayBuffer",A="DataView",L="prototype",N="Wrong index!",T=p[F],I=p[A],k=p.Math,R=p.RangeError,C=p.Infinity,D=T,G=k.abs,W=k.pow,U=k.floor,V=k.log,B=k.LN2,q="buffer",z="byteLength",H="byteOffset",K=d?"_b":q,J=d?"_l":z,Y=d?"_o":H;if(g.ABV){if(!x(function(){T(1)})||!x(function(){new T(-1)})||x(function(){return new T,new T(1.5),new T(NaN),T.name!=F})){for(var $,X=(T=function(t){return S(this,T),new D(O(t))})[L]=D[L],Q=E(D),Z=0;Q.length>Z;)($=Q[Z++])in T||m(T,$,D[$]);y||(X.constructor=T)}var tt=new I(new T(2)),nt=I[L].setInt8;tt.setInt8(0,2147483648),tt.setInt8(1,2147483649),!tt.getInt8(0)&&tt.getInt8(1)||b(I[L],{setInt8:function(t,n){nt.call(this,t,n<<24>>24)},setUint8:function(t,n){nt.call(this,t,n<<24>>24)}},!0)}else T=function(t){S(this,T,F);var n=O(t);this._b=P.call(Array(n),0),this[J]=n},I=function(t,n,r){S(this,I,A),S(t,T,A);var e=t[J],i=w(n);if(i<0||i>e)throw R("Wrong offset!");if(r=void 0===r?e-i:_(r),i+r>e)throw R("Wrong length!");this[K]=t,this[Y]=i,this[J]=r},d&&(l(T,z,"_l"),l(I,q,"_b"),l(I,z,"_l"),l(I,H,"_o")),b(I[L],{getInt8:function(t){return h(this,1,t)[0]<<24>>24},getUint8:function(t){return h(this,1,t)[0]},getInt16:function(t){var n=h(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=h(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return o(h(this,4,t,arguments[1]))},getUint32:function(t){return o(h(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return i(h(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return i(h(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){v(this,1,t,u,n)},setUint8:function(t,n){v(this,1,t,u,n)},setInt16:function(t,n){v(this,2,t,c,n,arguments[2])},setUint16:function(t,n){v(this,2,t,c,n,arguments[2])},setInt32:function(t,n){v(this,4,t,f,n,arguments[2])},setUint32:function(t,n){v(this,4,t,f,n,arguments[2])},setFloat32:function(t,n){v(this,4,t,s,n,arguments[2])},setFloat64:function(t,n){v(this,8,t,a,n,arguments[2])}});j(T,F),j(I,A),m(I[L],g.VIEW,!0),n[F]=T,n[A]=I},function(t,n,r){var e=r(3),i=r(49),o=r(70),u=r(190),c=r(10).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(49).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(66),i=r(174),o=r(80),u=r(32);t.exports=r(143)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){t.exports=function(t,n){t.classList?t.classList.add(n):t.className+=" "+n}},function(t,n){t.exports=function(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(77),o=r(11);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(69);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(19),i=r(17),o=r(115),u=r(11);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(19),i=r(5),o=r(171),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(10).f,i=r(71),o=r(75),u=r(46),c=r(68),f=r(69),a=r(143),s=r(174),l=r(76),h=r(9),v=r(67).fastKey,p=r(83),d=h?"_s":"size",y=function(t,n){var r,e=v(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,a){var s=t(function(t,e){c(t,s,n,"_i"),t._t=n,t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&f(e,r,t[a],t)});return o(s.prototype,{clear:function(){for(var t=p(this,n),r=t._i,e=t._f;e;e=e.n)e.r=!0,e.p&&(e.p=e.p.n=void 0),delete r[e.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var r=p(this,n),e=y(r,t);if(e){var i=e.n,o=e.p;delete r._i[e.i],e.r=!0,o&&(o.n=i),i&&(i.p=o),r._f==e&&(r._f=i),r._l==e&&(r._l=o),r[d]--}return!!e},forEach:function(t){p(this,n);for(var r,e=u(t,arguments.length>1?arguments[1]:void 0,3);r=r?r.n:this._f;)for(e(r.v,r.k,this);r&&r.r;)r=r.p},has:function(t){return!!y(p(this,n),t)}}),h&&e(s.prototype,"size",{get:function(){return p(this,n)[d]}}),s},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=v(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){a(t,n,function(t,r){this._t=p(t,n),this._k=r,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?s(0,r.k):"values"==n?s(0,r.v):s(0,[r.k,r.v]):(t._t=void 0,s(1))},r?"entries":"values",!r,!0),l(n)}}},function(t,n,r){var e=r(114),i=r(163);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(75),i=r(67).getWeak,o=r(2),u=r(5),c=r(68),f=r(69),a=r(48),s=r(25),l=r(83),h=a(5),v=a(6),p=0,d=function(t){return t._l||(t._l=new y)},y=function(){this.a=[]},g=function(t,n){return h(t.a,function(t){return t[0]===n})};y.prototype={get:function(t){var n=g(this,t);if(n)return n[1]},has:function(t){return!!g(this,t)},set:function(t,n){var r=g(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=v(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._t=n,t._i=p++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var r=i(t);return!0===r?d(l(this,n)).delete(t):r&&s(r,this._i)&&delete r[this._i]},has:function(t){if(!u(t))return!1;var r=i(t);return!0===r?d(l(this,n)).has(t):r&&s(r,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?d(t).set(n,r):e[t._i]=r,t},ufstore:d}},function(t,n,r){"use strict";function e(t,n,r,a,s,l,h,v){for(var p,d,y=s,g=0,m=!!h&&c(h,v,3);g<a;){if(g in r){if(p=m?m(r[g],g,n):r[g],d=!1,o(p)&&(d=p[f],d=void 0!==d?!!d:i(p)),d&&l>0)y=e(t,n,p,u(p.length),y,l-1)-1;else{if(y>=9007199254740991)throw TypeError();t[y]=p}y++}g++}return y}var i=r(121),o=r(5),u=r(11),c=r(46),f=r(7)("isConcatSpreadable");t.exports=e},function(t,n,r){t.exports=!r(9)&&!r(4)(function(){return 7!=Object.defineProperty(r(136)("div"),"a",{get:function(){return 7}}).a})},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(5),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(145),i=Math.pow,o=i(2,-52),u=i(2,-23),c=i(2,127)*(2-u),f=i(2,-126),a=function(t){return t+1/o-1/o};t.exports=Math.fround||function(t){var n,r,i=Math.abs(t),s=e(t);return i<f?s*a(i/f/u)*f*u:(n=(1+u/o)*i,(r=n-(n-i))>c||r!=r?s*(1/0):s*r)}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n){t.exports=Math.scale||function(t,n,r,e,i){return 0===arguments.length||t!=t||n!=n||r!=r||e!=e||i!=i?NaN:t===1/0||t===-1/0?t:(t-n)*(i-e)/(r-n)+e}},function(t,n,r){"use strict";var e=r(73),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(10),i=r(2),o=r(73);t.exports=r(9)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(32),i=r(72).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(25),i=r(32),o=r(117)(!1),u=r(149)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(73),i=r(32),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(72),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(153)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(153),u=/^[-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=function(t){try{return{e:!1,v:t()}}catch(t){return{e:!0,v:t}}}},function(t,n,r){var e=r(2),i=r(5),o=r(147);t.exports=function(t,n){if(e(t),i(n)&&n.constructor===t)return n;var r=o.f(t);return(0,r.resolve)(n),r.promise}},function(t,n,r){var e=r(11),i=r(152),o=r(50);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){var e=r(52),i=r(11);t.exports=function(t){if(void 0===t)return 0;var n=e(t),r=i(n);if(n!==r)throw RangeError("Wrong length!");return r}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(166),i=r(83),o="Map";t.exports=r(118)(o,function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(i(this,o),t);return n&&n.v},set:function(t,n){return e.def(i(this,o),0===t?0:t,n)}},e,!0)},function(t,n,r){r(9)&&"g"!=/./g.flags&&r(10).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(166),i=r(83);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(i(this,"Set"),t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(27),u=r(67),c=r(178),f=r(168),a=r(5),s=r(4),l=r(83),h="WeakMap",v=u.getWeak,p=Object.isExtensible,d=f.ufstore,y={},g=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},m={get:function(t){if(a(t)){var n=v(t);return!0===n?d(l(this,h)).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(l(this,h),t,n)}},b=t.exports=r(118)(h,g,m,f,!0,!0);s(function(){return 7!=(new b).set((Object.freeze||Object)(y),7).get(y)})&&(e=f.getConstructor(g,h),c(e.prototype,m),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=b.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!p(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";t.exports={init:function(){var t=document.querySelector("#page-nav");t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&lt; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &gt;</a>'),yiliaConfig&&yiliaConfig.open_in_new&&document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")}),yiliaConfig&&yiliaConfig.toc_hide_index&&document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"});var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,l.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,h.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=e(r(159)),h=e((e(r(160)),r(410))),v=e(r(131)),p=e(r(198)),d=r(132);v.default.versions.mobile&&window.screen.width<800&&(o(),s()),(0,d.addLoadEvent)(function(){p.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(409),r(204),r(207),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},function(t,n){(function(n){!function(n){"use strict";function r(t,n,r,e){var o=n&&n.prototype instanceof i?n:i,u=Object.create(o.prototype),c=new v(e||[]);return u._invoke=a(t,r,c),u}function e(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function i(){}function o(){}function u(){}function c(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function f(t){function r(n,i,o,u){var c=e(t[n],t,i);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){r("next",t,o,u)},function(t){r("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}"object"==typeof n.process&&n.process.domain&&(r=n.process.domain.bind(r));var i;this._invoke=function(t,n){function e(){return new Promise(function(e,i){r(t,n,e,i)})}return i=i?i.then(e,e):e()}}function a(t,n,r){var i=E;return function(o,u){if(i===P)throw new Error("Generator is already running");if(i===j){if("throw"===o)throw u;return d()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=s(c,r);if(f){if(f===F)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(i===E)throw i=j,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);i=P;var a=e(t,n,r);if("normal"===a.type){if(i=r.done?j:M,a.arg===F)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(i=j,r.method="throw",r.arg=a.arg)}}}function s(t,n){var r=t.iterator[n.method];if(r===y){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=y,s(t,n),"throw"===n.method))return F;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return F}var i=e(r,t.iterator,n.arg);if("throw"===i.type)return n.method="throw",n.arg=i.arg,n.delegate=null,F;var o=i.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=y),n.delegate=null,F):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,F)}function l(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function h(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function v(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(l,this),this.reset(!0)}function p(t){if(t){var n=t[x];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=y,n.done=!0,n};return e.next=e}}return{next:d}}function d(){return{value:y,done:!0}}var y,g=Object.prototype,m=g.hasOwnProperty,b="function"==typeof Symbol?Symbol:{},x=b.iterator||"@@iterator",S=b.asyncIterator||"@@asyncIterator",w=b.toStringTag||"@@toStringTag",_="object"==typeof t,O=n.regeneratorRuntime;if(O)_&&(t.exports=O);else{(O=n.regeneratorRuntime=_?t.exports:{}).wrap=r;var E="suspendedStart",M="suspendedYield",P="executing",j="completed",F={},A={};A[x]=function(){return this};var L=Object.getPrototypeOf,N=L&&L(L(p([])));N&&N!==g&&m.call(N,x)&&(A=N);var T=u.prototype=i.prototype=Object.create(A);o.prototype=T.constructor=u,u.constructor=o,u[w]=o.displayName="GeneratorFunction",O.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===o||"GeneratorFunction"===(n.displayName||n.name))},O.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,u):(t.__proto__=u,w in t||(t[w]="GeneratorFunction")),t.prototype=Object.create(T),t},O.awrap=function(t){return{__await:t}},c(f.prototype),f.prototype[S]=function(){return this},O.AsyncIterator=f,O.async=function(t,n,e,i){var o=new f(r(t,n,e,i));return O.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},c(T),T[w]="Generator",T[x]=function(){return this},T.toString=function(){return"[object Generator]"},O.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},O.values=p,v.prototype={constructor:v,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=y,this.done=!1,this.delegate=null,this.method="next",this.arg=y,this.tryEntries.forEach(h),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=y)},stop:function(){this.done=!0;var t=this.tryEntries[0].completion;if("throw"===t.type)throw t.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=y),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,F):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),F},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),h(r),F}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;h(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:p(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=y),F}}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}())},,,function(t,n,r){r(217),t.exports=r(49).RegExp.escape},,,,function(t,n,r){var e=r(5),i=r(121),o=r(7)("species");t.exports=function(t){var n;return i(t)&&("function"!=typeof(n=t.constructor)||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){"use strict";var e=r(4),i=Date.prototype.getTime,o=Date.prototype.toISOString,u=function(t){return t>9?t:"0"+t};t.exports=e(function(){return"0385-07-25T07:06:39.999Z"!=o.call(new Date(-5e13-1))})||!e(function(){o.call(new Date(NaN))})?function(){if(!isFinite(i.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}:o},function(t,n,r){"use strict";var e=r(2),i=r(53),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(73),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(1),i=r(215)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(162)}),r(66)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(133)}),r(66)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(66)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(66)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(46),i=r(1),o=r(17),u=r(173),c=r(141),f=r(11),a=r(135),s=r(157);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,m=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==m||v==Array&&c(m))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=m.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(121)})},function(t,n,r){"use strict";var e=r(1),i=r(32),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(32),o=r(52),u=r(11),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(135);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(164);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(164);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(139),o=r(45),u=r(77),c=r(11),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(19),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(76)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){var e=r(1),i=r(212);e(e.P+e.F*(Date.prototype.toISOString!==i),"Date",{toISOString:i})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(53);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(26)(i,e,r(213))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(27)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(165)})},function(t,n,r){"use strict";var e=r(5),i=r(31),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(10).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(10).f,i=Function.prototype,o=/^\s*function ([^ (]*)/,u="name";u in i||r(9)&&e(i,u,{configurable:!0,get:function(){try{return(""+this).match(o)[1]}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(176),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(145);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(144);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1);e(e.S,"Math",{fround:r(175)})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)*Math.LOG10E}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(176)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(145)})},function(t,n,r){var e=r(1),i=r(144),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(144),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(25),o=r(45),u=r(140),c=r(53),f=r(4),a=r(72).f,s=r(30).f,l=r(10).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(71)(y))==v,m="trim"in String.prototype,b=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){var r,e,i,o=(n=m?n.trim():h(n,3)).charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(b(n)),r,p):b(n)};for(var x,S=r(9)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),w=0;S.length>w;w++)i(d,x=S[w])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(27)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(172),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(184);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(185);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(52),o=r(161),u=r(152),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",m=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),m=p()}else h(0,r),h(1<<-n,0),m=p()+u.call(l,a);return a>0?(c=m.length,m=g+(c<=a?"0."+u.call(l,a-c)+m:m.slice(0,c-a)+"."+m.slice(c-a))):m=g+m,m}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(161),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(178)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(71)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(9),"Object",{defineProperties:r(179)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(9),"Object",{defineProperty:r(10).f})},function(t,n,r){var e=r(5),i=r(67).onFreeze;r(51)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(32),i=r(30).f;r(51)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(51)("getOwnPropertyNames",function(){return r(180).f})},function(t,n,r){var e=r(17),i=r(31);r(51)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(5);r(51)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(5);r(51)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(5);r(51)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(216)})},function(t,n,r){var e=r(17),i=r(73);r(51)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(5),i=r(67).onFreeze;r(51)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(5),i=r(67).onFreeze;r(51)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(148).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(27)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(184);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(185);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u,c=r(70),f=r(3),a=r(46),s=r(114),l=r(1),h=r(5),v=r(19),p=r(68),d=r(69),y=r(129),g=r(154).set,m=r(146)(),b=r(147),x=r(186),S=r(187),w="Promise",_=f.TypeError,O=f.process,E=f[w],M="process"==s(O),P=function(){},j=i=b.f,F=!!function(){try{var t=E.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(P,P)};return(M||"function"==typeof PromiseRejectionEvent)&&t.then(P)instanceof n}catch(t){}}(),A=function(t){var n;return!(!h(t)||"function"!=typeof(n=t.then))&&n},L=function(t,n){if(!t._n){t._n=!0;var r=t._c;m(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(_("Promise-chain cycle")):(o=A(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){g.call(f,function(){var n,r,e,i=t._v,o=T(t);if(o&&(n=x(function(){M?O.emit("unhandledRejection",i,t):(r=f.onunhandledrejection)?r({promise:t,reason:i}):(e=f.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=M||T(t)?2:1),t._a=void 0,o&&n.e)throw n.v})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if((n=r[e++]).fail||!T(n.promise))return!1;return!0},I=function(t){g.call(f,function(){var n;M?O.emit("rejectionHandled",t):(n=f.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),L(n,!0))},R=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw _("Promise can't be resolved itself");(n=A(t))?m(function(){var e={_w:r,_d:!1};try{n.call(t,a(R,e,1),a(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,L(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};F||(E=function(t){p(this,E,w,"_h"),v(t),e.call(this);try{t(a(R,this,1),a(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(75)(E.prototype,{then:function(t,n){var r=j(y(this,E));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=M?O.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&L(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),o=function(){var t=new e;this.promise=t,this.resolve=a(R,t,1),this.reject=a(k,t,1)},b.f=j=function(t){return t===E||t===u?new o(t):i(t)}),l(l.G+l.W+l.F*!F,{Promise:E}),r(81)(E,w),r(76)(w),u=r(49)[w],l(l.S+l.F*!F,w,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),l(l.S+l.F*(c||!F),w,{resolve:function(t){return S(c&&this===u?E:this,t)}}),l(l.S+l.F*!(F&&r(123)(function(t){E.all(t).catch(P)})),w,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=x(function(){var r=[],o=0,u=1;d(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o.e&&i(o.v),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=x(function(){d(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i.e&&e(i.v),r.promise}})},function(t,n,r){var e=r(1),i=r(19),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(71),o=r(19),u=r(2),c=r(5),f=r(4),a=r(165),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(10),i=r(1),o=r(2),u=r(53);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(30).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(142)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(30),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(31),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(30),o=r(31),u=r(25),c=r(1),f=r(5),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(183)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(148);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(10),o=r(30),u=r(31),c=r(25),f=r(1),a=r(74),s=r(2),l=r(5);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(140),o=r(10).f,u=r(72).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(9)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(27)(e,"RegExp",a)}r(76)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,m=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+m.source+"$(?!\\s)",d));(c=m.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)m[a]===c.index&&m[a]++;return y===r[f]?!h&&m.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(192);var e=r(2),i=r(120),o=r(9),u="toString",c=/./[u],f=function(t){r(27)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(28)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(28)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(28)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(28)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(150)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(11),o=r(151),u="endsWith",c=""[u];e(e.P+e.F*r(138)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(28)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(28)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(28)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(77),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(151),o="includes";e(e.P+e.F*r(138)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(28)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(150)(!0);r(143)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(28)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(11);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(152)})},function(t,n,r){"use strict";r(28)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(11),o=r(151),u="startsWith",c=""[u];e(e.P+e.F*r(138)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(28)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(28)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(28)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(25),o=r(9),u=r(1),c=r(27),f=r(67).KEY,a=r(4),s=r(128),l=r(81),h=r(78),v=r(7),p=r(190),d=r(156),y=r(214),g=r(121),m=r(2),b=r(32),x=r(53),S=r(74),w=r(71),_=r(180),O=r(30),E=r(10),M=r(73),P=O.f,j=E.f,F=_.f,A=e.Symbol,L=e.JSON,N=L&&L.stringify,T="prototype",I=v("_hidden"),k=v("toPrimitive"),R={}.propertyIsEnumerable,C=s("symbol-registry"),D=s("symbols"),G=s("op-symbols"),W=Object[T],U="function"==typeof A,V=e.QObject,B=!V||!V[T]||!V[T].findChild,q=o&&a(function(){return 7!=w(j({},"a",{get:function(){return j(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=P(W,n);e&&delete W[n],j(t,n,r),e&&t!==W&&j(W,n,e)}:j,z=function(t){var n=D[t]=w(A[T]);return n._k=t,n},H=U&&"symbol"==typeof A.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof A},K=function(t,n,r){return t===W&&K(G,n,r),m(t),n=x(n,!0),m(r),i(D,n)?(r.enumerable?(i(t,I)&&t[I][n]&&(t[I][n]=!1),r=w(r,{enumerable:S(0,!1)})):(i(t,I)||j(t,I,S(1,{})),t[I][n]=!0),q(t,n,r)):j(t,n,r)},J=function(t,n){m(t);for(var r,e=y(n=b(n)),i=0,o=e.length;o>i;)K(t,r=e[i++],n[r]);return t},Y=function(t){var n=R.call(this,t=x(t,!0));return!(this===W&&i(D,t)&&!i(G,t))&&(!(n||!i(this,t)||!i(D,t)||i(this,I)&&this[I][t])||n)},$=function(t,n){if(t=b(t),n=x(n,!0),t!==W||!i(D,n)||i(G,n)){var r=P(t,n);return!r||!i(D,n)||i(t,I)&&t[I][n]||(r.enumerable=!0),r}},X=function(t){for(var n,r=F(b(t)),e=[],o=0;r.length>o;)i(D,n=r[o++])||n==I||n==f||e.push(n);return e},Q=function(t){for(var n,r=t===W,e=F(r?G:b(t)),o=[],u=0;e.length>u;)!i(D,n=e[u++])||r&&!i(W,n)||o.push(D[n]);return o};U||(A=function(){if(this instanceof A)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===W&&n.call(G,r),i(this,I)&&i(this[I],t)&&(this[I][t]=!1),q(this,t,S(1,r))};return o&&B&&q(W,t,{configurable:!0,set:n}),z(t)},c(A[T],"toString",function(){return this._k}),O.f=$,E.f=K,r(72).f=_.f=X,r(116).f=Y,r(125).f=Q,o&&!r(70)&&c(W,"propertyIsEnumerable",Y,!0),p.f=function(t){return z(v(t))}),u(u.G+u.W+u.F*!U,{Symbol:A});for(var Z="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),tt=0;Z.length>tt;)v(Z[tt++]);for(var nt=M(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!U,"Symbol",{for:function(t){return i(C,t+="")?C[t]:C[t]=A(t)},keyFor:function(t){if(!H(t))throw TypeError(t+" is not a symbol!");for(var n in C)if(C[n]===t)return n},useSetter:function(){B=!0},useSimple:function(){B=!1}}),u(u.S+u.F*!U,"Object",{create:function(t,n){return void 0===n?w(t):J(w(t),n)},defineProperty:K,defineProperties:J,getOwnPropertyDescriptor:$,getOwnPropertyNames:X,getOwnPropertySymbols:Q}),L&&u(u.S+u.F*(!U||a(function(){var t=A();return"[null]"!=N([t])||"{}"!=N({a:t})||"{}"!=N(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!H(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return"function"==typeof(n=e[1])&&(r=n),!r&&g(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!H(n))return n}),e[1]=n,N.apply(L,e)}}}),A[T][k]||r(26)(A[T],k,A[T].valueOf),l(A,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(130),o=r(155),u=r(2),c=r(77),f=r(11),a=r(5),s=r(3).ArrayBuffer,l=r(129),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(76)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(130).ABV,{DataView:r(155).DataView})},function(t,n,r){r(56)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(56)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(56)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(56)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(56)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(56)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(56)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(56)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(56)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(168),i=r(83),o="WeakSet";r(118)(o,function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(i(this,o),t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(169),o=r(17),u=r(11),c=r(19),f=r(134);e(e.P,"Array",{flatMap:function(t){var n,r,e=o(this);return c(t),n=u(e.length),r=f(e,0),i(r,e,e,n,0,1,t,arguments[1]),r}}),r(66)("flatMap")},function(t,n,r){"use strict";var e=r(1),i=r(169),o=r(17),u=r(11),c=r(52),f=r(134);e(e.P,"Array",{flatten:function(){var t=arguments[0],n=o(this),r=u(n.length),e=f(n,0);return i(e,n,n,r,0,void 0===t?1:c(t)),e}}),r(66)("flatten")},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(66)("includes")},function(t,n,r){var e=r(1),i=r(146)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.G,{global:r(3)})},function(t,n,r){r(126)("Map")},function(t,n,r){r(127)("Map")},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(167)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{clamp:function(t,n,r){return Math.min(r,Math.max(n,t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{DEG_PER_RAD:Math.PI/180})},function(t,n,r){var e=r(1),i=180/Math.PI;e(e.S,"Math",{degrees:function(t){return t*i}})},function(t,n,r){var e=r(1),i=r(177),o=r(175);e(e.S,"Math",{fscale:function(t,n,r,e,u){return o(i(t,n,r,e,u))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=r>>>0;return(n>>>0)+(e>>>0)+((i&o|(i|o)&~(i+o>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=r>>>0;return(n>>>0)-(e>>>0)-((~i&o|~(i^o)&i-o>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{RAD_PER_DEG:180/Math.PI})},function(t,n,r){var e=r(1),i=Math.PI/180;e(e.S,"Math",{radians:function(t){return t*i}})},function(t,n,r){var e=r(1);e(e.S,"Math",{scale:r(177)})},function(t,n,r){var e=r(1);e(e.S,"Math",{signbit:function(t){return(t=+t)!=t?t:0==t?1/t==1/0:t>0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(19),u=r(10);r(9)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(19),u=r(10);r(9)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(182)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(183),o=r(32),u=r(30),c=r(135);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r,e=o(t),f=u.f,a=i(e),s={},l=0;a.length>l;)void 0!==(r=f(e,n=a[l++]))&&c(s,n,r);return s}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(53),u=r(31),c=r(30).f;r(9)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(53),u=r(31),c=r(30).f;r(9)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(182)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(49),u=r(146)(),c=r(7)("observable"),f=r(19),a=r(2),s=r(68),l=r(75),h=r(26),v=r(69),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},m=function(t){g(t)||(t._o=void 0,y(t))},b=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};b.prototype=l({},{unsubscribe:function(){m(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{m(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var S=function(t){s(this,S,"Observable","_f")._f=f(t)};l(S.prototype,{subscribe:function(t){return new b(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(S,{from:function(t){var n="function"==typeof this?this:S,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:S)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(S.prototype,c,function(){return this}),e(e.G,{Observable:S}),r(76)("Observable")},function(t,n,r){"use strict";var e=r(1),i=r(49),o=r(3),u=r(129),c=r(187);e(e.P+e.R,"Promise",{finally:function(t){var n=u(this,i.Promise||o.Promise),r="function"==typeof t;return this.then(r?function(r){return c(n,t()).then(function(){return r})}:t,r?function(r){return c(n,t()).then(function(){throw r})}:t)}})},function(t,n,r){"use strict";var e=r(1),i=r(147),o=r(186);e(e.S,"Promise",{try:function(t){var n=i.f(this),r=o(t);return(r.e?n.reject:n.resolve)(r.v),n.promise}})},function(t,n,r){var e=r(55),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(55),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(193),i=r(163),o=r(55),u=r(2),c=r(31),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(55),i=r(2),o=r(31),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(55),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(55),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(55),i=r(2),o=r(31),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(55),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(55),i=r(2),o=r(19),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){r(126)("Set")},function(t,n,r){r(127)("Set")},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(167)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(150)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(50),o=r(11),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(142)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(188);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(188);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(156)("asyncIterator")},function(t,n,r){r(156)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){r(126)("WeakMap")},function(t,n,r){r(127)("WeakMap")},function(t,n,r){r(126)("WeakSet")},function(t,n,r){r(127)("WeakSet")},function(t,n,r){for(var e=r(158),i=r(73),o=r(27),u=r(3),c=r(26),f=r(80),a=r(7),s=a("iterator"),l=a("toStringTag"),h=f.Array,v={CSSRuleList:!0,CSSStyleDeclaration:!1,CSSValueList:!1,ClientRectList:!1,DOMRectList:!1,DOMStringList:!1,DOMTokenList:!0,DataTransferItemList:!1,FileList:!1,HTMLAllCollection:!1,HTMLCollection:!1,HTMLFormElement:!1,HTMLSelectElement:!1,MediaList:!0,MimeTypeArray:!1,NamedNodeMap:!1,NodeList:!0,PaintRequestList:!1,Plugin:!1,PluginArray:!1,SVGLengthList:!1,SVGNumberList:!1,SVGPathSegList:!1,SVGPointList:!1,SVGStringList:!1,SVGTransformList:!1,SourceBufferList:!1,StyleSheetList:!0,TextTrackCueList:!1,TextTrackList:!1,TouchList:!1},p=i(v),d=0;d<p.length;d++){var y,g=p[d],m=v[g],b=u[g],x=b&&b.prototype;if(x&&(x[s]||c(x,s,h),x[l]||c(x,l,g),f[g]=h,m))for(y in e)x[y]||o(x,y,e[y],!0)}},function(t,n,r){var e=r(1),i=r(154);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=e.navigator,u=[].slice,c=!!o&&/MSIE .\./.test(o.userAgent),f=function(t){return function(n,r){var e=arguments.length>2,i=!!e&&u.call(arguments,2);return t(e?function(){("function"==typeof n?n:Function(n)).apply(this,i)}:n,r)}};i(i.G+i.B+i.F*c,{setTimeout:f(e.setTimeout),setInterval:f(e.setInterval)})},function(t,n,r){r(337),r(276),r(278),r(277),r(280),r(282),r(287),r(281),r(279),r(289),r(288),r(284),r(285),r(283),r(275),r(286),r(290),r(291),r(243),r(245),r(244),r(293),r(292),r(263),r(273),r(274),r(264),r(265),r(266),r(267),r(268),r(269),r(270),r(271),r(272),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(256),r(257),r(258),r(259),r(260),r(261),r(262),r(324),r(329),r(336),r(327),r(319),r(320),r(325),r(330),r(332),r(315),r(316),r(317),r(318),r(321),r(322),r(323),r(326),r(328),r(331),r(333),r(334),r(335),r(238),r(240),r(239),r(242),r(241),r(227),r(225),r(231),r(228),r(234),r(236),r(224),r(230),r(221),r(235),r(219),r(233),r(232),r(226),r(229),r(218),r(220),r(223),r(222),r(237),r(158),r(309),r(314),r(192),r(310),r(311),r(312),r(313),r(294),r(191),r(193),r(194),r(349),r(338),r(339),r(344),r(347),r(348),r(342),r(345),r(343),r(346),r(340),r(341),r(295),r(296),r(297),r(298),r(299),r(302),r(300),r(301),r(303),r(304),r(305),r(306),r(308),r(307),r(352),r(350),r(351),r(393),r(396),r(395),r(397),r(398),r(394),r(399),r(400),r(374),r(377),r(373),r(371),r(372),r(375),r(376),r(358),r(392),r(357),r(391),r(403),r(405),r(356),r(390),r(402),r(404),r(355),r(401),r(354),r(359),r(360),r(361),r(362),r(363),r(365),r(364),r(366),r(367),r(368),r(370),r(369),r(379),r(380),r(381),r(382),r(384),r(383),r(386),r(385),r(387),r(388),r(389),r(353),r(378),r(408),r(407),r(406),t.exports=r(49)},function(t,n){t.exports=function(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}}])</script><script src="/./main.e8862b.js"></script><script>!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.5b7e29.js")</script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">All articles</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">Friends</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">About me</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Algorithm</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">C++</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">DS</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">Android</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Tech</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">ML</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">DL</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">English</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Essay</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">git</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">hexo</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">golang</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">HTML</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Javascript</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">CSS</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">js</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">html</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Java</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Redis</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">MYSQL</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">Spring</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">linux</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">papers</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">RL</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">k8s</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="https://leetcode-cn.com/u/louris/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>我的力扣</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.six1110.top/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>饭勺</a>
            </li>
          
            <li class="search-li">
              <a href="https://www.zjcheng.site/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>中建</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">做一个安静细微的人，&lt;br&gt; 于角落里自在开放，&lt;br&gt; 默默悦人，&lt;br&gt; 却始终不引起过分热闹的关注，&lt;br&gt; 保有独立而随意的品格，&lt;br&gt; 这就很好。&lt;br&gt;&lt;br&gt; Stick to what you insist on,&lt;br&gt; believe what you believe!&lt;br&gt; Life hastily for decades,&lt;br&gt; do what I can!</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"react":{"opacity":1},"log":false});</script></body>
</html>